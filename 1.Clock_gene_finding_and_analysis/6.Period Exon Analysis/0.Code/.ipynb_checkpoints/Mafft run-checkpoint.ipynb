{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "784b519e-5f4c-4351-a8ff-ccc6a2dc214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import io\n",
    "from Bio.Seq import Seq\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c211e13c-3c07-48b4-b394-7953bf563d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_output_location = \"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/2.Blast/1.Blast_output\"\n",
    "species = \"Pararge_aegeria\"\n",
    "\n",
    "annotated_genome_location = \"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/1.Annotated Species\"\n",
    "query_location = \"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/2.Blast/0.Query\"\n",
    "query_species = \"5.Bicyclus_anynana\"\n",
    "query_transcript = \"XM_024088150.2\"\n",
    "\n",
    "genome_location = \"/mnt/f/Genomes_2023-12-26\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d4d9b-973c-41b4-ad74-fe2e2cf96dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length,AG_GT,Spliceator_prediction\n",
      "Pararge_aegeria,NC_053208.1,16934367,16934455,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_1,1,29,29,NA,NA\n",
      "\n",
      "Pararge_aegeria,NC_053208.1,16934367,16934455,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_1,1,29,29\n",
      "\n",
      "Pararge_aegeria,NC_053208.1,16926960,16927135,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_3,1,57,58\n",
      "\n",
      "/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/1.Annotated Species\n",
      "Getting Gene\n",
      "min = set152_frame2, 0.443\n",
      "set152_frame2\n",
      "HSSKSTHSESNSSGSSGYGGKPSSSGY\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/17/2024 03:55:01\n",
      "New DB name:   /mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/1.Annotated Species/33.Pararge_aegeria/Period_gene_genomic_sequence_individual_exon/gene_sequence_all.fa\n",
      "New DB title:  gene_sequence_all.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.00189304 seconds.\n",
      "[[1, 2]]\n",
      "[[1, 2]]\n",
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length,AG_GT,Spliceator_prediction\n",
      "Pararge_aegeria,NC_053208.1,16934367,16934455,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_1,1,29,29,NA,NA\n",
      "33.Pararge_aegeria,NC_053208.1,16927542,16927625,1,N,Query_Exon_2,1,27,27,Y,Y\n",
      "\n",
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length,AG_GT,Spliceator_prediction\n",
      "Pararge_aegeria,NC_053208.1,16934367,16934455,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_1,1,29,29,NA,NA\n",
      "33.Pararge_aegeria,NC_053208.1,16927542,16927625,1,N,Query_Exon_2,1,27,27,Y,Y\n",
      "Pararge_aegeria,NC_053208.1,16926960,16927135,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_3,1,57,58,NA,NA\n",
      "\n",
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length,AG_GT,Spliceator_prediction\n",
      "Pararge_aegeria,NC_053208.1,16934367,16934455,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_1,1,29,29,NA,NA\n",
      "33.Pararge_aegeria,NC_053208.1,16927542,16927625,1,N,Query_Exon_2,1,27,27,Y,Y\n",
      "Pararge_aegeria,NC_053208.1,16926960,16927135,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_3,1,57,58,NA,NA\n",
      "Pararge_aegeria,NC_053208.1,16925888,16925976,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_4,4,28,28,NA,NA\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Previous exon coordinate\n",
      "Pararge_aegeria,NC_053208.1,16924607,16924738,1,Y,5.Bicyclus_anynana_XM_024088150.2_query_Exon_6,1,44,44\n",
      "\n",
      "Proceed? y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pararge_aegeria,NC_053208.1,16925888,16925976,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_4,4,28,28\n",
      "\n",
      "Pararge_aegeria,NC_053208.1,16924607,16924738,1,Y,5.Bicyclus_anynana_XM_024088150.2_query_Exon_6,1,44,44\n",
      "\n",
      "/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/1.Annotated Species\n",
      "Getting Gene\n",
      "min = set2_frame1, 1.268\n",
      "set2_frame1\n",
      "ITIIISLLLFQLSCPNSPVGTIQYVSSLPNQNNVS\n"
     ]
    }
   ],
   "source": [
    "output_coordinate_file = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length,\" +  \"AG_GT,\" + \"Spliceator_prediction\\n\"\n",
    "\n",
    "list_of_files_in_species_folder = os.listdir(f\"{blast_output_location}/{species}\")\n",
    "coordinate_file_name = ''\n",
    "for file_names in list_of_files_in_species_folder:\n",
    "    if file_names.endswith(\"_coordinates.csv\"):\n",
    "        coordinate_file_name = file_names\n",
    "if coordinate_file_name =='':\n",
    "    print(f\"Coordinate file error\")\n",
    "    assert False\n",
    "\n",
    "with io.open(f\"{blast_output_location}/{species}/{coordinate_file_name}\", 'r') as temp_file_open:\n",
    "    coordinate_file_lines = temp_file_open.readlines()\n",
    "# print(coordinate_file_lines[0])\n",
    "\n",
    "for i in range(1,len(coordinate_file_lines)):\n",
    "    coordinate_file_lines_split = coordinate_file_lines[i].split(\",\")\n",
    "    current_exon_coordinates = coordinate_file_lines[i].split(\",\")\n",
    "    if coordinate_file_lines_split[5] == \"Y\":\n",
    "        if i == 1:\n",
    "            print(f'First Exon has errors\\n{coordinate_file_lines[i]}')\n",
    "            assert False\n",
    "        previous_exon_number = i-1\n",
    "        next_exon_number = i+1\n",
    "        previous_exon_coordinates = ''\n",
    "        next_exon_coordinates = ''\n",
    "        while True:\n",
    "            if coordinate_file_lines[previous_exon_number].split(\",\")[5] == \"N\":\n",
    "                previous_exon_coordinates = coordinate_file_lines[previous_exon_number]\n",
    "                break\n",
    "            else:\n",
    "                proceed_prompt = input(f\"Previous exon coordinate\\n{coordinate_file_lines[previous_exon_number]}\\nProceed?\")\n",
    "                if proceed_prompt.lower()[0] == \"y\":\n",
    "                    previous_exon_coordinates = coordinate_file_lines[previous_exon_number]\n",
    "                    break\n",
    "            previous_exon_number -= 1\n",
    "        while True:\n",
    "            if coordinate_file_lines[next_exon_number].split(\",\")[5] == \"N\":\n",
    "                next_exon_coordinates = coordinate_file_lines[next_exon_number]\n",
    "                break\n",
    "            else:\n",
    "                proceed_prompt = input(f\"Previous exon coordinate\\n{coordinate_file_lines[next_exon_number]}\\nProceed?\")\n",
    "                if proceed_prompt.lower()[0] == \"y\":\n",
    "                    next_exon_coordinates = coordinate_file_lines[next_exon_number]\n",
    "                    break\n",
    "            next_exon_number += 1\n",
    "\n",
    "        \n",
    "        print(previous_exon_coordinates)\n",
    "        print(next_exon_coordinates)\n",
    "        annotated_species_name, error_exon, species, genome_file, gene_sequence,left_overhang,right_overhang,scaffold = mafft_process(previous_exon_coordinates,\n",
    "                                                                                                          next_exon_coordinates,\n",
    "                                                                                                          current_exon_coordinates,\n",
    "                                                                                                          query_species,\n",
    "                                                                                                          query_transcript,\n",
    "                                                                                                          query_location,\n",
    "                                                                                                          annotated_genome_location,\n",
    "                                                                                                             genome_location)\n",
    "\n",
    "        mafft_run_folder = run_mafft(annotated_genome_location,annotated_species_name,error_exon)\n",
    "\n",
    "        mafft_run_folder = f'{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment'\n",
    "        possible_gene_sequence = process_mafft_output(mafft_run_folder)\n",
    "\n",
    "        run_blast_with_new_query(annotated_genome_location,annotated_species_name,error_exon,possible_gene_sequence,genome_location,species, genome_file, gene_sequence)\n",
    "        start_coordinate,stop_coordinate,gt_ag, splice_prediction = process_genome_fragment_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold )\n",
    "        new_coordinate_file_line = process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold, gt_ag, splice_prediction )    \n",
    "        output_coordinate_file += new_coordinate_file_line\n",
    "        # break\n",
    "    else:\n",
    "        output_coordinate_file +=coordinate_file_lines[i].rstrip()+\",NA,NA\\n\"\n",
    "        # break\n",
    "        # print(coordinate_file_lines[i])\n",
    "    print(output_coordinate_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b1284f75-c797-4e4a-9bae-5ad351ae0b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length,AG_GT,Spliceator_prediction\n",
      "Pararge_aegeria,NC_053208.1,16934367,16934455,1,N,5.Bicyclus_anynana_XM_024088150.2_query_Exon_1,1,29,29,NA,NA\n",
      "33.Pararge_aegeria,NC_053208.1,16927542,16927625,1,N,Query_Exon_2,1,27,27,Y,Y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output_coordinate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2a08f218-a9ae-4594-bda1-334e35040180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min = set152_frame2, 0.443\n",
      "set152_frame2\n",
      "HSSKSTHSESNSSGSSGYGGKPSSSGY\n",
      "/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/1.Annotated Species/33.Pararge_aegeria/Period_gene_genomic_sequence_individual_exon\n",
      "Exon_2\n",
      "Spliceator_results(1).csv\n",
      "all temp\n",
      "desktop.ini\n",
      "gene_sequence_all.fa\n",
      "gene_sequence_all.fa.nhr\n",
      "gene_sequence_all.fa.nin\n",
      "gene_sequence_all.fa.nsq\n",
      "temp\n",
      "\n",
      "\n",
      "Building a new DB, current time: 02/17/2024 03:20:35\n",
      "New DB name:   /mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/1.Annotated Species/33.Pararge_aegeria/Period_gene_genomic_sequence_individual_exon/gene_sequence_all.fa\n",
      "New DB title:  gene_sequence_all.fa\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.00960398 seconds.\n"
     ]
    }
   ],
   "source": [
    "possible_gene_sequence = process_mafft_output(mafft_run_folder)\n",
    "check_gene_sequence = input(\"is the query sequence ok?\")\n",
    "if check_gene_sequence == \"n\":\n",
    "    gene_sequence = input(\"Enter the desired query sequence :\")\n",
    "\n",
    "\n",
    "run_blast_with_new_query(annotated_genome_location,annotated_species_name,error_exon,possible_gene_sequence,genome_location,species, genome_file, gene_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f71d98e5-50e4-43f5-97a3-ab5e5fb71cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2]]\n",
      "[[1, 2]]\n",
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length,AG_GT,Spliceator_prediction\n",
      "\n",
      "33.Pararge_aegeria,NC_053208.1,16927542,16927625,1,N,Query_Exon_2,1,27,27,Y,Y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_coordinate,stop_coordinate,gt_ag, splice_prediction = process_genome_fragment_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold )\n",
    "process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold, gt_ag, splice_prediction )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2130d492-411e-4eca-af06-218e8bebbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mafft_process(previous_exon_coordinates,\n",
    "                  next_exon_coordinates,\n",
    "                  current_exon_coordinates,\n",
    "                  query_species,\n",
    "                  query_transcript,\n",
    "                  query_location,\n",
    "                  annotated_genome_location,\n",
    "                 genome_location):\n",
    "    query_exon = current_exon_coordinates[6].split(\"query\")[-1][1:]\n",
    "    error_exon = query_exon\n",
    "    # print(\"AA\")\n",
    "    genome_file = get_genome_file(genome_location,species)\n",
    "    \n",
    "    upstream_exon_line, downstream_exon_line = previous_exon_coordinates.split(\",\"),next_exon_coordinates.split(\",\")\n",
    "    complement,scaffold = upstream_exon_line[4], upstream_exon_line[1]\n",
    "\n",
    "    if complement == \"0\":\n",
    "        gene_start = max(int(upstream_exon_line[2]),int(upstream_exon_line[3]))\n",
    "        gene_end = min(int(downstream_exon_line[2]),int(downstream_exon_line[3]))\n",
    "    \n",
    "    if complement == \"1\":\n",
    "        gene_start = max(int(downstream_exon_line[2]),int(downstream_exon_line[3]))\n",
    "        gene_end = min(int(upstream_exon_line[2]),int(upstream_exon_line[3]))\n",
    "    # print(\"BB\")\n",
    "\n",
    "    # print(gene_sequence)\n",
    "    # gene_sequence = Seq(\"GGTAAggacattataatttttaatgcatTCCCTCGAAACTTGAAATCTTCTAATCCACTAgagtttctataaaaaaaaatatggcataTTATGCCGTCATGCCAATCCATTATGGCggatatccatactaatattatgctTGTGAAATTGTttctgtttgtttctttgtttgttacctatgaaCAGCTAAACCGTTgaatcgattttcatgaaatttgacACACACGTAGTTTGCATCTTTAGTACAGTGAtttcattataacatttatattggcTGTAATATAAAAAGCGTTAACCATCTGATTTGTGAGATGGTGGAGCTAAGGCTAAAAATTCAGTATGTAACtattttaagttaaatgtaTAGCATCATTTGCATCTGAAGCCGTTTCATCATATAGATTGATTagcgttttttattatatttggtcGGAGTAATACTAATAATCTATTAGCGTGAGCAACATTAATTAATCTGTTTGacagattttattaaaatttactttcatGATATTGAACTATAGAAAGAGTAAAGGTGAAATAGAGAAGTTAGTAATACAAAGTGAATTCACAAAAccgttttattttacaaaaaattgaatgaaattataatttattttcatatttacagGATCGCAAAACCTTTGCATCCCAAATCACTAGCGGGCTTTTAGCTCCGAAATCAACTAGCGGTGAACAACCTCAAGGTAATTTCGATTGATTTAATGATCCATGCTTCCAAtagatttaatttgaaaatttgtcgTTTGTATTAGCTTCAATACATCACATTCTCAAACATGACTTCATACAACCAAACTTATCCgctacaattttataattgagATAGTGAAAAAGTTAATAGCTTCAAGATACAAATTTTACAGGGTTCTTTCATACAAACGTGTAATTAATTCTAAATGTTAtaactaagtataaaaataatgtttcctTTAAAGTGAACTGTCTTCTTGCTGATTCTAGTACTAGTATCaataatttcaattaataagTACCTCAATAAGATAAACCGCCATATTTTATTGCCGGCTGTTTCATgtaaaattatcttatttaaaaacatttaaaagacAAATTTACAAAATGTATTAAGCTTCTGTGAGAATTATGTGCACTATGTTTCATACATAGCAAAAGTTGTATTTCATTATTTGagatgaaattgaaaatttaatgttaataatttttgttttataatgcaTTTAAAGTAATCATCAACACATAACCTAACTTTTGGGATAGTTAAAATTTGTGTCGCAACTTCAATAAGAGCTTGTCCAC\")\n",
    "\n",
    "    with open(f\"{query_location}/{query_species}/{query_transcript}/query_{query_exon}.fa\", 'r') as query_file:\n",
    "        query_file_list = query_file.readlines()\n",
    "        query_fasta_sequence = \"\".join(query_file_list)\n",
    "        left_overhang = query_file_list[0].split(\"Frame\")[1][1]\n",
    "        right_overhang = query_file_list[0].split(\"rightoh\")[1][1]\n",
    "        \n",
    "    query_length = len(query_fasta_sequence.split(\"\\n\")[1])\n",
    "    \n",
    "    annotated_species_name = get_annotated_genome_name(annotated_genome_location, species)\n",
    "    # print(annotated_species_name)\n",
    "\n",
    "    # print(annotated_genome_location)\n",
    "    gene_sequence = get_gene_sequence(genome_location, species, genome_file, scaffold,gene_start,gene_end,complement,annotated_genome_location,annotated_species_name)\n",
    "    # assert False\n",
    "    check_and_make_folders(annotated_genome_location,annotated_species_name,error_exon)\n",
    "    \n",
    "    \n",
    "    make_raw_files_for_alignment(gene_sequence,annotated_genome_location,annotated_species_name,error_exon,query_fasta_sequence,query_length)\n",
    "    \n",
    "    return(annotated_species_name, error_exon,species, genome_file,gene_sequence,left_overhang,right_overhang,scaffold )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a3dd53c5-035a-44cf-b8a9-2b3e69f1bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genome_file(genome_location,species):\n",
    "    list_of_files_in_genome_folder = os.listdir(f\"{genome_location}/{species}\")\n",
    "    for file in list_of_files_in_genome_folder:\n",
    "        if file.endswith(\"_genomic.fna\"):\n",
    "            genome_file = file\n",
    "    return(genome_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "19786644-19a4-4b97-a714-bcdc9a955198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_gene_sequence(genome_location, species, genome_file, scaffold,gene_start,gene_end,complement):\n",
    "#     from Bio import SeqIO\n",
    "#     genome = SeqIO.parse(f\"{genome_location}/{species}/{genome_file}\", \"fasta\")\n",
    "#     for entries in genome:\n",
    "#         # print(scaffold)\n",
    "#         if scaffold == entries.id:\n",
    "#             print(scaffold)\n",
    "#             gene_sequence = entries.seq[gene_start-1:gene_end]\n",
    "#             if complement == \"1\":\n",
    "#                 gene_sequence = gene_sequence.reverse_complement()\n",
    "#             break\n",
    "#     return (gene_sequence)\n",
    "\n",
    "def get_gene_sequence(genome_location, species, genome_file, scaffold,gene_start,gene_end,complement,annotated_genome_location,annotated_species_name):\n",
    "    from Bio import SeqIO\n",
    "    print(\"Getting Gene\")\n",
    "    list_of_files_inside_annotated_species_folder = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}\")\n",
    "\n",
    "    if \"Period_gene_genomic_sequence_individual_exon\" not in list_of_files_inside_annotated_species_folder:\n",
    "        os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon\")\n",
    "\n",
    "    list_of_files_inside_indiv_exon_folder = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon\")\n",
    "    if \"temp\" not in list_of_files_inside_indiv_exon_folder:\n",
    "         os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/temp\")\n",
    "\n",
    "    # os.system(f'samtools faidx \"{genome_location}/{species}/{genome_file}\"')\n",
    "    # subprocess.run(\"pwd\")\n",
    "    subprocess.run(f'samtools faidx \"{genome_location}/{species}/{genome_file}\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "    # os.system(f'samtools faidx \"{genome_location}/{species}/{genome_file}\" {scaffold}:{gene_start}-{gene_end} > \"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/temp/temp_genome.fa\"')\n",
    "    subprocess.run(f'samtools faidx \"{genome_location}/{species}/{genome_file}\" {scaffold}:{gene_start}-{gene_end} > \"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/temp/temp_genome.fa\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "    genome = SeqIO.parse(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/temp/temp_genome.fa\", \"fasta\")\n",
    "    for entries in genome:\n",
    "        gene_sequence = entries.seq\n",
    "        if complement == \"1\":\n",
    "            gene_sequence = gene_sequence.reverse_complement()\n",
    "        break\n",
    "    return (gene_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "890fbadd-cf94-416d-ab5c-9bf001ade5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotated_genome_name(annotated_genome_location, species):\n",
    "    list_of_annotated_genomes = os.listdir(annotated_genome_location)\n",
    "  \n",
    "    # print(annotated_species)\n",
    "    for annotated_species in list_of_annotated_genomes:\n",
    "        if annotated_species.endswith(species):\n",
    "            return(annotated_species)\n",
    "             \n",
    "    if annotated_species_name == '':\n",
    "        print(f\"Error with annotated species name\")\n",
    "        assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4820999e-23de-4f59-8e55-e7ba54b9223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_make_folders(annotated_genome_location,annotated_species_name,error_exon):\n",
    "    list_of_files_inside_annotated_species_folder = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}\")\n",
    "\n",
    "    if \"Period_gene_genomic_sequence_individual_exon\" not in list_of_files_inside_annotated_species_folder:\n",
    "        os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon\")\n",
    "    \n",
    "    list_of_exon_directories = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/\")\n",
    "    \n",
    "    if error_exon not in list_of_exon_directories:\n",
    "        os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}\")\n",
    "        os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment\")\n",
    "    elif error_exon in list_of_exon_directories:\n",
    "        list_of_folders_1 = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}\")\n",
    "        if \"for_alignment\" not in list_of_folders_1:\n",
    "            os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment\")\n",
    "        list_of_files = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment\")\n",
    "        for file in list_of_files:\n",
    "            os.remove(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment/{file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "76a82e10-276a-4c87-a2f4-2278e953386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_files_for_alignment(gene_sequence,annotated_genome_location,annotated_species_name,error_exon,query_fasta_sequence,query_length):\n",
    "    for offset in range(3):\n",
    "        translated_sequence = str(gene_sequence[offset:].translate()).split(\"*\")\n",
    "        for i in range(len(translated_sequence)):\n",
    "            if len(translated_sequence[i])> 0.8*query_length:\n",
    "                sequence_set = f\">set{i+1}_frame{offset}\\n{translated_sequence[i]}\\n\\n\"\n",
    "                # print(i+1, offset)\n",
    "                \n",
    "                with open(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment/{error_exon}_translated_genomic_sequence_{i+1}_frame{offset}.fa\",'w') as out_file:\n",
    "                    output = f\"{query_fasta_sequence}\\n\\n{sequence_set}\"\n",
    "                    out_file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9a3ca856-17d5-42f5-9b1d-ef0046613beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mafft(annotated_genome_location,annotated_species_name,error_exon):\n",
    "    location = f'{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_alignment'\n",
    "    list_of_files_to_run_mafft_on = os.listdir(location)\n",
    "    for file in list_of_files_to_run_mafft_on:\n",
    "        if file.endswith(\".fa\"):\n",
    "            command = f'\"/home/saurav/miniconda3/envs/ncbi_datasets/bin/mafft\" --localpair --maxiterate 16 --reorder --distout \"{location}/{file}\" > \"{location}/alignment_{file}.txt\"'\n",
    "            # print(command)\n",
    "            subprocess.run(f'{command}', shell=True, stderr = subprocess.DEVNULL) \n",
    "            # os.system(f'{command}')\n",
    "            command = f'\"/home/saurav/miniconda3/envs/ncbi_datasets/bin/mafft\" --localpair --clustalout --maxiterate 16 --reorder \"{location}/{file}\" > \"{location}/alignment_clustal_{file}.txt\"'\n",
    "            subprocess.run(f'{command}', shell=True, stderr = subprocess.DEVNULL) \n",
    "            \n",
    "            # os.system(f'{command}')\n",
    "    return(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b0e7c6a2-54e8-404a-95d6-a4dc4fef0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mafft_output(mafft_run_folder):\n",
    "    list_of_files_in_mafft_run_folder = os.listdir(mafft_run_folder)\n",
    "    score_output = ''\n",
    "    score = 99\n",
    "    min_score_sequence = ''\n",
    "    alignment_file = ''\n",
    "    for file in list_of_files_in_mafft_run_folder:\n",
    "        if file.endswith(\".fa.hat2\"):\n",
    "            with io.open(f\"{mafft_run_folder}/{file}\", 'r') as dist_matrix_file:\n",
    "                dist_matrix_list = dist_matrix_file.readlines()\n",
    "            \n",
    "            sequence_name = dist_matrix_list[-2].rstrip().split(\"=\")[1]\n",
    "            distance_score = float(dist_matrix_list[-1].rstrip())\n",
    "            score_output += f\"{sequence_name} =  {distance_score}\\n\"\n",
    "            if distance_score < score:\n",
    "                score = distance_score\n",
    "                min_score_sequence = sequence_name\n",
    "                alignment_file = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "    # print(score_output)\n",
    "    print(f\"min = {min_score_sequence}, {score}\" )\n",
    "    \n",
    "    alignment_file = SeqIO.parse(f\"{mafft_run_folder}/{alignment_file}\", 'fasta')\n",
    "    # print (records.id)\n",
    "    fasta_start_position = 0\n",
    "    fasta_end_position = 0\n",
    "    start_switch = 0\n",
    "    end_switch = 0\n",
    "    for records in alignment_file:\n",
    "        \n",
    "        if start_switch == 1 and end_switch == 1:\n",
    "            gene_sequence = records.seq[fasta_start_position:fasta_end_position]\n",
    "            print(f\"{records.id}\\n{gene_sequence}\")\n",
    "        if error_exon in records.id:\n",
    "            for current_position in range(len(records.seq)):\n",
    "                # print(records.seq[current_position])\n",
    "                if \"-\" not in records.seq[current_position] and start_switch == 0:\n",
    "                    fasta_start_position = current_position\n",
    "                    start_switch = 1\n",
    "                if end_switch == 1 and \"-\" not in records.seq[current_position]:\n",
    "                    end_switch = 0\n",
    "                    \n",
    "                if start_switch == 1 and records.seq[current_position] == \"-\" and end_switch == 0:\n",
    "                    fasta_end_position = current_position\n",
    "                    end_switch = 1\n",
    "    return(gene_sequence)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "36049d04-90d2-4f19-be98-d3344e80e44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blast_with_new_query(annotated_genome_location,annotated_species_name,error_exon, possible_gene_sequence,genome_location, species, genome_file, gene_sequence):\n",
    "    list_of_folders_inside_exon_folder = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}\")\n",
    "    if \"for_blast\" not in list_of_folders_inside_exon_folder:\n",
    "        os.mkdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast\")\n",
    "    else:\n",
    "        list_of_files = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast\")\n",
    "        for file in list_of_files:\n",
    "            os.remove(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast/{file}\")\n",
    "\n",
    "\n",
    "    \n",
    "    with open(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast/new_query.txt\",'w') as query_file:\n",
    "        query = f\">Query_{error_exon}\\n{possible_gene_sequence}\"\n",
    "        query_file.write(query)\n",
    "\n",
    "    query_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast/new_query.txt\"\n",
    "    genome = f\"{genome_location}/{species}/{genome_file}\"\n",
    "    out_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast\"\n",
    "    blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.htm\" -html'\n",
    "    os.system(f'{blast_command}')\n",
    "    blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.txt\"'\n",
    "    os.system(f'{blast_command}')\n",
    "\n",
    "    genome_fragment_out = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast/local_genomic_fragment.fa\"\n",
    "    with io.open(genome_fragment_out,'w') as out_file:\n",
    "        output = f\">Genome_fragment_{error_exon}\\n{gene_sequence}\"\n",
    "        out_file.write(output)\n",
    "\n",
    "    local_genomic_fragment_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/\"\n",
    "    cd_command = f'cd \"{local_genomic_fragment_location}\"\\nmakeblastdb -in gene_sequence_all.fa -dbtype nucl\\n'\n",
    "    # os.system(f'{cd_command}')\n",
    "    subprocess.run(f'{cd_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    # print(mkdb_command)\n",
    "    # os.system(f'{mkdb_command}')\n",
    "    blast_command = f'cd \"{out_location}\"\\ntblastn -seg no -query new_query.txt -db ../../gene_sequence_all.fa -num_alignments 3 -out blast_out_genome_fragment.htm -html'\n",
    "    # os.system(f'{blast_command}')\n",
    "    subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    blast_command = f'cd \"{out_location}\"\\ntblastn -seg no -query new_query.txt -db ../../gene_sequence_all.fa -num_alignments 3 -out blast_out_genome_fragment.txt'\n",
    "    # os.system(f'{blast_command}')\n",
    "    subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "\n",
    "    \n",
    "        \n",
    "# run_blast_with_new_query(annotated_genome_location,annotated_species_name,error_exon,possible_gene_sequence,genome_location,species, genome_file, gene_sequence)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "73f41ded-1ae5-4410-b2ed-55a753a18e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# query_file_list = [\">5.Bicyclus_anynana_XM_024088150.2_Frame_1_rightoh_2_query_Exon_2\"]\n",
    "\n",
    "# left_overhang = query_file_list[0].split(\"Frame\")[1][1]\n",
    "# right_overhang = query_file_list[0].split(\"rightoh\")[1][1]\n",
    "\n",
    "# print(left_overhang, right_overhang)\n",
    "# scaffold = \"NC_053208.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "ab7bdec2-c59f-4ddf-9bd9-dd37db416e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_coordinate,stop_coordinate,gt_ag, splice_prediction = process_genome_fragment_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold )\n",
    "# print(start_coordinate, stop_coordinate,gt_ag, splice_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e00dea7b-dacf-4dc8-975a-fffdd4ef245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceptor, donor, don_line, acc_line = process_spiceator_result(start_coordinate, stop_coordinate,annotated_genome_location,annotated_species_name)\n",
    "# print(acceptor, donor, don_line, acc_line)\n",
    "# if acceptor == \"Y\" and donor  == \"Y\":\n",
    "#     splice_prediction = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "04bba6b5-e23e-47b8-a7bd-81faecd2aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold, gt_ag, splice_prediction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "21dc4815-5293-4272-9b74-1b3f729c99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spiceator_result(start_coordinate, stop_coordinate,annotated_genome_location,annotated_species_name):\n",
    "    results_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/\"\n",
    "    list_of_files_here = os.listdir(results_location)\n",
    "    spliceator_results_file = ''\n",
    "    for files in list_of_files_here:\n",
    "        if files.startswith(\"Spliceator_results\"):\n",
    "            spliceator_results_file = files\n",
    "    if spliceator_results_file == '':\n",
    "        print(\"Splice file missing\")\n",
    "        assert False\n",
    "\n",
    "    with open(f\"{results_location}/{spliceator_results_file}\", 'r') as splice_file:\n",
    "        splice_file_content = splice_file.readlines()\n",
    "\n",
    "    splice_acceptor_presence = \"N\"\n",
    "    splice_donor_presence = \"N\"\n",
    "    splice_donor = ''\n",
    "    splice_acceptor = ''\n",
    "    for lines in splice_file_content:\n",
    "        line_split = lines.split(\";\")\n",
    "        if line_split[0]==\"Acceptor\" and splice_acceptor_presence == \"N\":\n",
    "            acceptor_start = int(line_split[1])\n",
    "            acceptor_end = acceptor_start + len(line_split[3])\n",
    "            if start_coordinate >=acceptor_start and start_coordinate <=acceptor_end:\n",
    "                splice_acceptor_presence = \"Y\"\n",
    "                splice_acceptor = lines\n",
    "        if line_split[0]==\"Donor\" and splice_donor_presence == \"N\":\n",
    "            donor_start = int(line_split[1])\n",
    "            donor_end = donor_start + len(line_split[3])\n",
    "            if stop_coordinate >=donor_start and stop_coordinate <=donor_end:\n",
    "                splice_donor_presence = \"Y\"\n",
    "                splice_donor = lines\n",
    "\n",
    "    return(splice_acceptor_presence, splice_donor_presence, splice_donor, splice_acceptor)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f3141fd1-3f84-4a54-b029-b329a43448f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_genome_fragment_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold  ):\n",
    "    blast_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast\"\n",
    "    with open(f\"{blast_location}/new_query.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_overhang),int(right_overhang)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    species_name = annotated_species_name\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out_genome_fragment.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "        genome_file = SeqIO.parse(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/gene_sequence_all.fa\", 'fasta')\n",
    "        for records in genome_file:\n",
    "            \n",
    "            while True:\n",
    "                print(f\"left = {records.seq[start-3:start-1]}, right ={(records.seq[stop:stop + 2])}\"  ), \n",
    "                if (records.seq[start-3:start-1]).lower() == \"ag\" and (records.seq[stop:stop + 2]).lower() == \"gt\":\n",
    "                    \n",
    "                    gt_ag = \"Y\"\n",
    "                    break\n",
    "                start -= 1\n",
    "                stop += 1\n",
    "                \n",
    "        acceptor, donor, don_line, acc_line = process_spiceator_result(start, stop,annotated_genome_location,annotated_species_name)\n",
    "\n",
    "        if acceptor == \"Y\" and donor  == \"Y\":\n",
    "            splice_prediction = \"Y\"\n",
    "            \n",
    "        return(start,stop,gt_ag, splice_prediction) \n",
    "        # output_format = str(species_name.split(\"\\n\")[0])+\",\" + str(scaffold) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        # print(output_format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2b1a29c8-3ef0-437f-a22a-e757d687c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_extractor(Species, Scaff, reverse_c, start, end, frame = 1, trans = 1 ):\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    import os\n",
    "    \n",
    "    out_Seq = ''\n",
    "    \n",
    "    \n",
    "    #Genome folder\n",
    "    entries = os.listdir(\"F:/Genomes_2023-12-26/\"+Species)\n",
    "    \n",
    "    #Get genome file from Genome folder\n",
    "    for file_names  in entries:\n",
    "        if \".nhr\" in file_names:\n",
    "            Genome_name = file_names[:-4]\n",
    "            break\n",
    "    \n",
    "    #Read the genome file\n",
    "    fasta_file = open((\"F:/Genomes_2023-12-26/\"+Species+\"/\"+Genome_name),'r')\n",
    "    \n",
    "    #Extract the sequence \n",
    "    for record in SeqIO.parse(fasta_file,\"fasta\"):\n",
    "        if record.id == Scaff:\n",
    "            sequence = str(record.seq)\n",
    "            out_Seq = Seq(sequence[start-1:end])\n",
    "            if reverse_c == 1:\n",
    "                out_Seq = out_Seq.reverse_complement()\n",
    "                \n",
    "    if len(out_Seq) < 10000: #fixing error due to mistake in typing the coordinate, change this for longer sequence\n",
    "#        print (out_Seq)\n",
    "        if frame == 1 :\n",
    "            out_trans = out_Seq[0:]\n",
    "        if frame == 2 :\n",
    "            out_trans = out_Seq[1:]\n",
    "        if frame == 3 :\n",
    "            out_trans = out_Seq[2:]\n",
    "    else:\n",
    "        print (\"too long\")\n",
    "        assert(False)\n",
    "        \n",
    "        \n",
    "    #    break\n",
    "    fasta_file.close()\n",
    "    if trans == 1:\n",
    "        return (out_trans.translate())\n",
    "    else:\n",
    "        return(out_Seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a0944f04-1e77-4b67-a8a9-d6347cf39d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang,scaffold, ag_gt, splice_prediction ):\n",
    "    blast_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/{error_exon}/for_blast\"\n",
    "    with open(f\"{blast_location}/new_query.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_overhang),int(right_overhang)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length,\" +  \"AG_GT,\" + \"Spliceator_prediction\\n\"\n",
    "    \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    species_name = annotated_species_name\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "            \n",
    "        output_format = str(species_name.split(\".\")[1])+\",\" + str(scaffold) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \",\" + ag_gt + \",\" + splice_prediction +\"\\n\"  \n",
    "        # print(Output_Sequence)\n",
    "        return(output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc26e6b-86c9-469f-8fa6-ae97ff9f97cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64e720-04ee-4a68-960e-2b0ea8af6a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
