{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d321c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_error_exon(output_location,species, error_exon):\n",
    "    import subprocess\n",
    "    list_of_folders = os.listdir(f\"{output_location}/1.Blast_result/{species}\")\n",
    "    if \"Error_exon_processing\" not in list_of_folders:\n",
    "        os.mkdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing\")\n",
    "        \n",
    "    list_of_folder_2 = os.listdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing\")\n",
    "    if error_exon in list_of_folder_2:\n",
    "        subprocess.run(f'rm -r \"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "    os.mkdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\")\n",
    "    \n",
    "    list_of_folders_3 = os.listdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\")\n",
    "    if \"Temp_query\" not in list_of_folders_3:\n",
    "        os.mkdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}/Temp_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8456dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query(output_location,error_exon,species):\n",
    "    from Bio import SeqIO\n",
    "    import random\n",
    "    exon = error_exon.split(\"Error\")[1][1:]\n",
    "\n",
    "    list_of_species = os.listdir(f\"{output_location}/2.Final_output\")\n",
    "    try:\n",
    "        list_of_species.remove(\"desktop.ini\")\n",
    "    except:\n",
    "        pass\n",
    "    if len(list_of_species) > 6:\n",
    "        list_of_species = random.sample(list_of_species, 5)\n",
    "    \n",
    "    for query_species in list_of_species:\n",
    "        list_of_exons = os.listdir(f\"{output_location}/2.Final_output/{query_species}\")\n",
    "        try:\n",
    "            list_of_exons.remove(\"desktop.ini\")\n",
    "        except:\n",
    "            pass\n",
    "#         print(query_species,list_of_exons)\n",
    "        if f\"{exon}.fa\" in list_of_exons:\n",
    "            print (f\"{exon}.fa\")\n",
    "            exon_file = SeqIO.parse(f\"{output_location}/2.Final_output/{query_species}/{exon}.fa\", 'fasta')\n",
    "            for records in exon_file:\n",
    "                print(records.id)\n",
    "                print(records.seq[int(records.id.split(\"_\")[-3]):].translate())\n",
    "                left_oh = records.id.split(\"_\")[-3]\n",
    "                right_oh = records.id.split(\"_\")[-1]\n",
    "    #             print(left_oh)\n",
    "                query_sequence = records.seq[int(records.id.split(\"_\")[-3]):].translate()\n",
    "            with open(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}/Temp_query/{query_species}_{exon}.fa\", \"w\") as out_file:\n",
    "                output = f\">{records.id}\\n{query_sequence}\"\n",
    "                out_file.write(output)\n",
    "    return(left_oh,right_oh)\n",
    "# left_oh,right_oh = make_query(output_location,error_exon,species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7aff1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genomic_coordinates(output_location,error_exon,species):\n",
    "    error_exon_number = error_exon.split(\"_\")[-1]\n",
    "#     print(error_exon_number)\n",
    "#     return\n",
    "    with open(f\"{output_location}/1.Blast_result/{species}/final_coordinates.csv\", 'r') as final_coordinate_file:\n",
    "        final_coordinate_file_lines = final_coordinate_file.readlines()\n",
    "    for i in range(1, len(final_coordinate_file_lines)):\n",
    "#         print(final_coordinate_file_lines[i])\n",
    "        current_position = i\n",
    "        next_position = i\n",
    "#         print(final_coordinate_file_lines[i].split(\",\")[6].split(\"Exon\")[1][1:].strip())\n",
    "#         print(error_exon_number)\n",
    "        scaffold = final_coordinate_file_lines[current_position-1].split(\",\")[1]\n",
    "\n",
    "        original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position-1].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "        \n",
    "        \n",
    "        if final_coordinate_file_lines[i].split(\",\")[6].split(\"Exon\")[1][1:].strip() == error_exon_number:\n",
    "#             print(current_position, next_position)\n",
    "    \n",
    "            if error_exon_number == \"1\":\n",
    "                current_position = current_position\n",
    "                while final_coordinate_file_lines[next_position+1].split(\",\")[5] == \"Y\":\n",
    "                        next_position += 1\n",
    "                complement = final_coordinate_file_lines[current_position].split(\",\")[4]\n",
    "                \n",
    "                if complement == \"0\":\n",
    "                    fragment_start = int(final_coordinate_file_lines[current_position].split(\",\")[3])-1000\n",
    "                    fragment_end = final_coordinate_file_lines[next_position+1].split(\",\")[2]\n",
    "                if complement == \"1\":\n",
    "                    fragment_start = final_coordinate_file_lines[next_position+1].split(\",\")[3]\n",
    "                    fragment_end = int(final_coordinate_file_lines[current_position].split(\",\")[2]) + 1000\n",
    "\n",
    "                scaffold = final_coordinate_file_lines[current_position].split(\",\")[1]\n",
    "                \n",
    "                \n",
    "                \n",
    "            elif error_exon_number == \"25\":\n",
    "                next_position = next_position\n",
    "                while final_coordinate_file_lines[current_position-1].split(\",\")[5] == \"Y\":\n",
    "                    current_position = current_position-1\n",
    "                complement = final_coordinate_file_lines[current_position].split(\",\")[4]\n",
    "                \n",
    "                if complement == \"0\":\n",
    "                    fragment_start = int(final_coordinate_file_lines[current_position-1].split(\",\")[3])\n",
    "                    fragment_end = int(final_coordinate_file_lines[next_position].split(\",\")[2])+1000\n",
    "                if complement == \"1\":\n",
    "                    fragment_start = int(final_coordinate_file_lines[next_position].split(\",\")[3])-1000\n",
    "                    fragment_end = final_coordinate_file_lines[current_position-1].split(\",\")[2] \n",
    "                \n",
    "                scaffold = final_coordinate_file_lines[current_position].split(\",\")[1]\n",
    "                original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "                \n",
    "            else: \n",
    "                while final_coordinate_file_lines[current_position-1].split(\",\")[5] == \"Y\":\n",
    "                    current_position = current_position-1\n",
    "                while final_coordinate_file_lines[next_position+1].split(\",\")[5] == \"Y\":\n",
    "                    next_position += 1\n",
    "\n",
    "                complement = final_coordinate_file_lines[current_position-1].split(\",\")[4]\n",
    "                original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position-1].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "\n",
    "                if complement == \"0\":\n",
    "                    fragment_start = final_coordinate_file_lines[current_position-1].split(\",\")[3]\n",
    "                    fragment_end = final_coordinate_file_lines[next_position+1].split(\",\")[2]\n",
    "                if complement == \"1\":\n",
    "                    fragment_start = final_coordinate_file_lines[next_position+1].split(\",\")[3]\n",
    "                    fragment_end = final_coordinate_file_lines[current_position-1].split(\",\")[2]\n",
    "            \n",
    "                scaffold = final_coordinate_file_lines[current_position-1].split(\",\")[1]\n",
    "\n",
    "                original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position-1].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "                \n",
    "    #             query_name =f\"{''.join(final_coordinate_file_lines[current_position-1].split(''))}\"\n",
    "    #             print(query_name)                       \n",
    "                                   \n",
    "            return(fragment_start, fragment_end, scaffold,complement,original_query_name)\n",
    "# print(get_genomic_coordinates(output_location,error_exon,species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09eaa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genome_file(genome_location,species):\n",
    "    list_of_files_in_genome_folder = os.listdir(f\"{genome_location}/{species}\")\n",
    "    for file in list_of_files_in_genome_folder:\n",
    "        if file.endswith(\"_genomic.fna\"):\n",
    "            genome_file = file\n",
    "    return(genome_file) \n",
    "\n",
    "def get_gene_sequence(genome_location, \n",
    "                      species,                       \n",
    "                      scaffold,\n",
    "                      gene_start,\n",
    "                      gene_end,\n",
    "                      complement,\n",
    "                      output_location):\n",
    "\n",
    "    \n",
    "    print(\"Getting Gene\")\n",
    "    \n",
    "    genome_file = get_genome_file(genome_location,species)\n",
    "    print(genome_file)\n",
    "    list_of_folders = os.listdir(output_location)\n",
    "    print(list_of_folders)\n",
    "    if f\"0.Temp\" not in list_of_folders:\n",
    "        os.mkdir(f\"{output_location}/0.Temp\")\n",
    "\n",
    "#     subprocess.run(f'samtools faidx \"{genome_location}/{species}/{genome_file}\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "#     print(f'samtools faidx \"{genome_location}/{species}/{genome_file}\" {scaffold}:{gene_start}-{gene_end}')\n",
    "    subprocess.run(f'samtools faidx \"{genome_location}/{species}/{genome_file}\" {scaffold}:{gene_start}-{gene_end} > \"{output_location}/0.Temp/temp_genome.fa\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "    genome = SeqIO.parse(f\"{output_location}/0.Temp/temp_genome.fa\", \"fasta\")\n",
    "    for entries in genome:\n",
    "        gene_sequence = entries.seq\n",
    "        if complement == \"1\":\n",
    "            gene_sequence = gene_sequence.reverse_complement()\n",
    "        break\n",
    "    # print(gene_sequence)\n",
    "    return (gene_sequence)\n",
    "# get_gene_sequence(genome_location, \n",
    "#                           species,                       \n",
    "#                           scaffold,\n",
    "#                           fragment_start,\n",
    "#                           fragment_end,\n",
    "#                           complement,\n",
    "#                           output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36f8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_files_for_alignment(gene_sequence,output_location,species,error_exon):\n",
    "    \n",
    "    \n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    list_of_folders = os.listdir(error_exon_location)\n",
    "    if \"for_alignment\" not in list_of_folders:\n",
    "        \n",
    "        os.mkdir(f\"{error_exon_location}/for_alignment\")\n",
    "    \n",
    "    list_of_files = os.listdir(f\"{error_exon_location}/for_alignment\")\n",
    "    for file in list_of_files:\n",
    "        os.remove(f\"{error_exon_location}/for_alignment/{file}\")\n",
    "\n",
    "    \n",
    "    query_location = f\"{error_exon_location}/Temp_query/\"\n",
    "    list_of_queries = os.listdir(query_location)\n",
    "    print(list_of_queries)\n",
    "#     return\n",
    "    query_fasta_sequence = ''\n",
    "    query_length = 0\n",
    "    \n",
    "    for query in list_of_queries:\n",
    "        \n",
    "        query_fasta_file = SeqIO.parse(f\"{query_location}/{query}\", 'fasta')\n",
    "        for records in query_fasta_file:\n",
    "            \n",
    "            query_fasta_sequence = f\">{records.id}\\n{records.seq}\\n\\n\"\n",
    "            query_length_new = len(records.seq)\n",
    "            if query_length == 0:\n",
    "                query_length = len(records.seq)\n",
    "            if query_length_new < query_length:\n",
    "                query_length = query_length_new\n",
    "                \n",
    "            query_species = \"_\".join(records.id.split(\"_\")[:2])\n",
    "#             print(query_species)\n",
    "#             return\n",
    "            print(error_exon)\n",
    "        #     return\n",
    "\n",
    "        #     query_length = query_length/3\n",
    "            for offset in range(3):\n",
    "                translated_sequence = str(gene_sequence[offset:].translate()).split(\"*\")\n",
    "                for i in range(len(translated_sequence)):\n",
    "\n",
    "                    if len(translated_sequence[i])> 0.8*query_length and  str(translated_sequence[i]).count(\"X\") < 5:\n",
    "                        sequence_set = f\">set{i+1}_frame{offset}_{query_species}\\n{translated_sequence[i]}\\n\\n\"\n",
    "        #                 print(i+1, offset)\n",
    "\n",
    "                        with open(f\"{error_exon_location}/for_alignment/{error_exon}_query_{query_species}_translated_genomic_sequence_{i+1}_frame{offset}.fa\",'w') as out_file:\n",
    "                            output = f\"{query_fasta_sequence}\\n\\n{sequence_set}\"\n",
    "                            out_file.write(output)\n",
    "\n",
    "# make_raw_files_for_alignment(gene_sequence,output_location,species,error_exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730727e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mafft(output_location,species,error_exon):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    location = f'{error_exon_location}/for_alignment/'\n",
    "    list_of_files_to_run_mafft_on = os.listdir(location)\n",
    "    for file in list_of_files_to_run_mafft_on:\n",
    "        if file.endswith(\".fa\"):\n",
    "            command = f'\"mafft\" --localpair --maxiterate 16 --reorder --distout \"{location}/{file}\" > \"{location}/alignment_{file}.txt\"'\n",
    "            # print(command)\n",
    "            subprocess.run(f'{command}', shell=True, stderr = subprocess.DEVNULL) \n",
    "            # os.system(f'{command}')\n",
    "            command = f'\"mafft\" --localpair --clustalout --maxiterate 16 --reorder \"{location}/{file}\" > \"{location}/alignment_clustal_{file}.txt\"'\n",
    "            subprocess.run(f'{command}', shell=True, stderr = subprocess.DEVNULL) \n",
    "            \n",
    "            # os.system(f'{command}')\n",
    "    return(location)\n",
    "# run_mafft(output_location,species,error_exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78e0d08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_mafft_output(mafft_run_location, error_exon):\n",
    "    error_exon = error_exon.split(\"Error\")[1][1:]\n",
    "    list_of_files_in_mafft_run_folder = os.listdir(mafft_run_location)\n",
    "    score_output = []\n",
    "    score = 99\n",
    "    min_score_sequence = ''\n",
    "    alignment_file = ''\n",
    "    for file in list_of_files_in_mafft_run_folder:\n",
    "        if file.endswith(\".fa.hat2\"):\n",
    "            with open(f\"{mafft_run_location}/{file}\", 'r') as dist_matrix_file:\n",
    "                dist_matrix_list = dist_matrix_file.readlines()\n",
    "            \n",
    "            sequence_name = f'set{file.split(\"_\")[-2]}_{file.split(\"_\")[-1].split(\".\")[0]}'\n",
    "            query_species_name =f'{file.split(\"_\")[4]}_{file.split(\"_\")[5]}'\n",
    "            distance_score = float(dist_matrix_list[2].strip())\n",
    "            if len(score_output) < 10:\n",
    "                alignment_file_now = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "                score_output.append( [sequence_name,distance_score,alignment_file_now])\n",
    "            else:\n",
    "                for i in range(len(score_output)):\n",
    "                    score_at_this_index = score_output[i][1]\n",
    "                    if distance_score < score_at_this_index:\n",
    "                        alignment_file_now = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "                        score_output[i] = [sequence_name,distance_score,alignment_file_now]\n",
    "                        break\n",
    "            if distance_score < score:\n",
    "                score = distance_score\n",
    "                min_score_sequence = sequence_name\n",
    "                alignment_file = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "#     print(score_output)\n",
    "    print(f\"min = {min_score_sequence}, {score}\" )\n",
    "    \n",
    "    # score_out_merged = '\\n'.join(score_output)\n",
    "    print(f\"5 top scores:\\n{score_output}\")\n",
    "    \n",
    "    for i in range(len(score_output)):\n",
    "        temp_align_file = score_output[i][2]\n",
    "        clustal_alignment_file = temp_align_file.replace(\"alignment_\",\"alignment_clustal_\")\n",
    "        with open(f\"{mafft_run_location}{clustal_alignment_file}\", 'r') as clustal_file_open:\n",
    "            print(\"\".join(clustal_file_open.readlines()))\n",
    "    \n",
    "    print(f\"{mafft_run_location}/{alignment_file}\")\n",
    "#     return\n",
    "    \n",
    "    print(f\"Alignmnet file: {alignment_file}\")\n",
    "    clustal_alignment_file = alignment_file.replace(\"alignment_\",\"alignment_clustal_\")\n",
    "    print(clustal_alignment_file)\n",
    "    alignment_file = SeqIO.parse(f\"{mafft_run_location}/{alignment_file}\", 'fasta')\n",
    "    # print (records.id)\n",
    "    fasta_start_position = 0\n",
    "    fasta_end_position = 0\n",
    "    start_switch = 0\n",
    "    end_switch = 0\n",
    "    alignment_name = ''\n",
    "    for records in alignment_file:\n",
    "        \n",
    "        if start_switch == 0 and end_switch == 0:\n",
    "            print(error_exon)\n",
    "            if error_exon in records.id:\n",
    "                print(records.id)\n",
    "                gap_counter = 0\n",
    "                base_counter = 0\n",
    "                for current_position in range(len(records.seq)):\n",
    "                    sequence_length = len(records.seq) - records.seq.count('-')\n",
    "#                     print(f\"fasta_end_position {fasta_end_position} fasta_start_position {fasta_start_position}\")\n",
    "                    # print(f\"current_position = {current_position}, {len(records.seq)}\")\n",
    "                    # print(records.seq[current_position])\n",
    "                    # print(\"fasta_start_position\",fasta_start_position)\n",
    "#                     print(\"start_switch\",start_switch)\n",
    "\n",
    "                    # print(gap_counter, base_counter)\n",
    "                    # print(5,0.2*sequence_length)\n",
    "#                     print((len(records.seq[:current_position]) - records.seq[:current_position].count('-')), 0.1*sequence_length)\n",
    "                    if start_switch == 1 and records.seq[current_position] == \"-\" and gap_counter > 3 and (len(records.seq[:current_position]) - records.seq[:current_position].count('-')) < 0.1*sequence_length:\n",
    "                        # print(\"\\n\\nhere\\n\\n\")\n",
    "                        start_switch = 0\n",
    "                        gap_counter = 0\n",
    "                    \n",
    "                    if \"-\" not in records.seq[current_position] and start_switch == 0 :\n",
    "                        \n",
    "                        fasta_start_position = current_position\n",
    "                        start_switch = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if end_switch == 1 and \"-\" not in records.seq[current_position] :\n",
    "                        end_switch = 0\n",
    "                        gap_counter = 0\n",
    "\n",
    "#                     print((len(records.seq[current_position:]) - records.seq[current_position:].count('-')), 0.1*sequence_length) \n",
    "#                     print((start_switch == 1),records.seq[current_position],(len(records.seq[current_position:]) - records.seq[current_position:].count('-')) < 0.1*sequence_length)\n",
    "                    if start_switch == 1 and records.seq[current_position] == \"-\" and end_switch == 0 and (len(records.seq[current_position:]) - records.seq[current_position:].count('-')) < 0.1*sequence_length:\n",
    "                        # print(f\"base_counter {base_counter}\")\n",
    "                        # print(f\"fasta_end_position {fasta_end_position}\")\n",
    "\n",
    "                        # print(f\"fasta_end_position {fasta_end_position}\")\n",
    "\n",
    "                        fasta_end_position = current_position\n",
    "                        end_switch = 1\n",
    "                    if \"-\" in records.seq[current_position]:\n",
    "                        gap_counter += 1\n",
    "                    else:\n",
    "                        gap_counter = 0\n",
    "                        base_counter += 1\n",
    "        else:\n",
    "            if end_switch == 0:\n",
    "                end_switch = 1\n",
    "                fasta_end_position = current_position\n",
    "            start_switch = 1\n",
    "    #         break\n",
    "        print(\"here here\", start_switch,end_switch,min_score_sequence,records.id,fasta_start_position, fasta_end_position )\n",
    "        if start_switch == 1 and end_switch == 1 and min_score_sequence in records.id :\n",
    "            alignment_name = records.id\n",
    "#             print(fasta_start_position, fasta_end_position)\n",
    "            gene_sequence = records.seq[fasta_start_position:fasta_end_position]\n",
    "            print(f\"{records.id}\\n{gene_sequence}\")\n",
    "#     print(\"_\".join(alignment_name.split(\"_\")[:2]).replace(\"set\", \"sequence\"))\n",
    "#     clustal_alignment_file = f'alignment_clustal_Error_{error_exon}_translated_genomic_{(\"_\".join(alignment_name.split(\"_\")[:2]).replace(\"set\", \"sequence_\"))}.fa.txt'\n",
    "    print(clustal_alignment_file)\n",
    "    with open(f\"{mafft_run_location}{clustal_alignment_file}\", 'r') as clustal_file_open:\n",
    "        return(gene_sequence, alignment_name,clustal_file_open.readlines() )\n",
    "\n",
    "# query_sequence, alignment_name, alignment_file = process_mafft_output(mafft_run_location, error_exon)\n",
    "# print(query_sequence, alignment_name)\n",
    "# print(\"\".join(alignment_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78ed650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blast(gene_sequence,query_sequence,alignment_name,output_location,species, error_exon):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    list_of_folders = os.listdir(error_exon_location)\n",
    "    if \"Run_Blast\" not in list_of_folders:\n",
    "        os.mkdir(f\"{error_exon_location}/Run_Blast\")\n",
    "    \n",
    "    with open(f\"{error_exon_location}/Run_Blast/local_db.txt\",'w') as db_file:\n",
    "        output = f\">genome_fragment\\n{gene_sequence}\"\n",
    "        db_file.write(output)\n",
    "        \n",
    "    with open(f\"{error_exon_location}/Run_Blast/query.txt\",'w') as query_file:\n",
    "        output = f\">{alignment_name}\\n{query_sequence}\"\n",
    "        query_file.write(output)\n",
    "    \n",
    "    makeblast_command = f'cd \"{error_exon_location}/Run_Blast/\"\\nmakeblastdb -in local_db.txt -dbtype nucl'\n",
    "    subprocess.run(f'{makeblast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "    blast_command = f'cd \"{error_exon_location}/Run_Blast/\"\\ntblastn -seg no -query query.txt -db local_db.txt -num_alignments 3 -out blast_out_genome_fragment.htm -html\\ntblastn -seg no -query query.txt -db local_db.txt -num_alignments 3 -out blast_out_genome_fragment.txt'\n",
    "    subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "# run_blast(gene_sequence,query_sequence,alignment_name,output_location,species, error_exon)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae0d3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_genome_fragment_blast_file(output_location,\n",
    "#                                         annotated_genome_location, \n",
    "#                                        species_name,\n",
    "#                                        error_exon,\n",
    "#                                        left_oh,right_oh,\n",
    "                                                                                                                                      \n",
    "#                                        original_query_name,\n",
    "# #                                       query_species_original ):\n",
    "    \n",
    "def process_genome_fragment_blast_file(output_location,left_oh,right_oh,species,genome_location):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    blast_location = f\"{error_exon_location}/Run_Blast\"\n",
    "    \n",
    "    with open(f\"{blast_location}/query.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_oh),int(right_oh)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "#     species_name = annotated_species_name\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        print(query_name)\n",
    "#         return\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out_genome_fragment.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "        print(start_coor,stop_coor)\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "        genome_file = SeqIO.parse(f\"{blast_location}/local_db.txt\", 'fasta')\n",
    "        print(\"reached here\")\n",
    "        \n",
    "        for records in genome_file:\n",
    "            old_start = start\n",
    "            old_stop = stop\n",
    "            ag = \"N\"\n",
    "            gt = \"N\"\n",
    "            stop_counter = 0\n",
    "            while True:\n",
    "                print(f\"sequence:\\n{records.seq[start+start_modifier-1:stop]}\")\n",
    "                translated_sequence = records.seq[start+start_modifier-1:stop].translate()\n",
    "                print(f\"sequence:\\n{translated_sequence}\")\n",
    "                if \"*\" in translated_sequence:\n",
    "                    stop_counter +=1\n",
    "                    if ag == \"N\":\n",
    "                        start = old_start + 3*stop_counter\n",
    "                    if gt ==\"N\":\n",
    "                        stop = old_stop - 3*stop_counter\n",
    "                if stop_counter > 10:\n",
    "                    return (\"Error!! Too many stops\")\n",
    "                print(f\"left = {records.seq[start-3:start-1]}, right ={(records.seq[stop:stop + 2])}\"  ), \n",
    "                if (records.seq[start-3:start-1]).lower() == \"ag\" and ag != \"Y\":\n",
    "                    \n",
    "                    ag = \"Y\"\n",
    "                    \n",
    "                elif ag != \"Y\":\n",
    "                    start -= 3\n",
    "                    \n",
    "                if (records.seq[stop:stop + 2]).lower() == \"gt\" and gt != \"Y\":\n",
    "                    gt = \"Y\"\n",
    "                elif gt != \"Y\":\n",
    "                    stop +=3\n",
    "                if old_start - start > 1000 or stop - old_stop > 1000:\n",
    "                    break\n",
    "                if gt == \"Y\" and ag == \"Y\":\n",
    "                    gt_ag = \"Y\"\n",
    "                    break\n",
    "        \n",
    "        query_location = f\"{blast_location}/new_query_spliced.txt\"\n",
    "        with open(query_location , 'w') as query_file_new:\n",
    "\n",
    "            sequence_translated = records.seq[start+start_modifier-1:stop].translate()\n",
    "            print(sequence_translated)\n",
    "            # proceed_test = input(\"Proceed with this?\")\n",
    "            # while True:\n",
    "            #     if proceed_test.lower()[0] == \"n\":\n",
    "            #         assert False\n",
    "            #     elif proceed_test.lower()[0] == \"y\":\n",
    "            #         break\n",
    "            if \"*\" in sequence_translated:\n",
    "                print(\"Errror in Spliced query\")\n",
    "                assert False\n",
    "            \n",
    "            output = f\">{query_name}\\n{sequence_translated}\"\n",
    "            query_file_new.write(output)\n",
    "\n",
    "        genome_file = get_genome_file(genome_location,species)\n",
    "        genome = f\"{genome_location}/{species}/{genome_file}\"\n",
    "        out_location = f\"{blast_location}\"\n",
    "    \n",
    "        \n",
    "        blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.htm\" -html'\n",
    "        # print(blast_command)\n",
    "        # subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "        subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "        blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.txt\"'\n",
    "        subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "\n",
    "                \n",
    "        # acceptor, donor, don_line, acc_line = process_spiceator_result(start, stop,annotated_genome_location,annotated_species_name)\n",
    "\n",
    "#         if acceptor == \"Y\" and donor  == \"Y\":\n",
    "#             splice_prediction = \"Y\"\n",
    "#         else:\n",
    "#             splice_prediction = \"N\"\n",
    "            \n",
    "        return(gt_ag) \n",
    "        # output_format = str(species_name.split(\"\\n\")[0])+\",\" + str(scaffold) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        # print(output_format)\n",
    "\n",
    "# ag_gt = process_genome_fragment_blast_file(output_location,left_oh,right_oh,species,genome_location)\n",
    "# print(ag_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf3f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang, ag_gt, splice_prediction,original_query_name, query_species ): ):\n",
    "def process_genome_blast_file(output_location,left_oh,right_oh,species,genome_location,ag_gt,query_name_original):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    blast_location = f\"{error_exon_location}/Run_Blast\"\n",
    "\n",
    "    with open(f\"{blast_location}/new_query_spliced.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_oh),int(right_oh)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length,\" +  \"AG_GT,\" + \"Spliceator_prediction\\n\"\n",
    "    \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    species_name = species\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "            # print(lines)\n",
    "            # print(query_name)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "        \n",
    "        print(f\"start_coordinate : {start_coor},stop_coordinate : {stop_coor}\")\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "        splice_prediction = \"Y\"   \n",
    "        output_format = str(species_name)+\",\" + str(scaff) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name_original)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \",\" + ag_gt + \",\" + splice_prediction +\"\\n\"  \n",
    "        # print(Output_Sequence)\n",
    "        return(output_format)\n",
    "# process_genome_blast_file(output_location,left_oh,right_oh,species,genome_location,ag_gt,query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b515e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lycaena_phlaeas,HG995168.1,000,000,0,Y,Error_Exon_12,00,00,00\n",
      "\n",
      "Exon_12.fa\n",
      "Lysandra_bellargus_Exon_12_HG995319.1_9990345_9990476_left_0_right_0\n",
      "VLSKPTKLAKQQMTKRCQEIAAFMETFIGKITVDPCIPFKNTKC\n",
      "Exon_12.fa\n",
      "Glaucopsyche_alexis_Exon_12_FR990042.1_17909094_17909234_left_0_right_0\n",
      "LLNQVLAKPIKLAKQQMTKRCQEIAAFMESFIDKTNIDNCMALKDKC\n",
      "Exon_12.fa\n",
      "Helleia_helle_Exon_12_OY971420.1_9152620_9152754_left_0_right_0\n",
      "AVIKPKLLAKEQMSKRSRDIAAYMDYYIYKVKTVPKADEREDMKT\n",
      "Exon_12.fa\n",
      "Cyaniris_semiargus_Exon_12_LR994547.1_15925862_15925993_left_0_right_0\n",
      "VLSKPTKLAKQQMTKRCQEIAAFMETFIDKTTVNPCIPFKDTKC\n",
      "Exon_12.fa\n",
      "Polyommatus_iphigenia_Exon_12_OY730178.1_31375005_31375136_left_0_right_0\n",
      "VLSKPTKLAKQQMTKRCQEIAAFMESFIDKTNINSAMPFKDKKC\n",
      "Gene_start = 7223925, Gene_end = 7225492\n",
      "Getting Gene\n",
      "GCA_905333005.2_ilLycPhla1.2_genomic.fna\n",
      "['1.Query', '1.Blast_result', 'tblastnAricia_agestis.sh', 'temp', '0.Temp', 'error_exons.txt', '2.Final_output', '3.Test_alignment', 'desktop.ini']\n",
      "['Lysandra_bellargus_Exon_12.fa', 'Glaucopsyche_alexis_Exon_12.fa', 'Helleia_helle_Exon_12.fa', 'Cyaniris_semiargus_Exon_12.fa', 'Polyommatus_iphigenia_Exon_12.fa']\n",
      "Error_Exon_12\n",
      "Error_Exon_12\n",
      "Error_Exon_12\n",
      "Error_Exon_12\n",
      "Error_Exon_12\n",
      "min = set13_frame0, 2.346\n",
      "5 top scores:\n",
      "[['set13_frame0', 2.346, 'alignment_Error_Exon_12_query_Helleia_helle_translated_genomic_sequence_13_frame0.fa.txt'], ['set13_frame0', 2.475, 'alignment_Error_Exon_12_query_Polyommatus_iphigenia_translated_genomic_sequence_13_frame0.fa.txt'], ['set28_frame1', 4.396, 'alignment_Error_Exon_12_query_Cyaniris_semiargus_translated_genomic_sequence_28_frame1.fa.txt'], ['set45_frame2', 4.418, 'alignment_Error_Exon_12_query_Cyaniris_semiargus_translated_genomic_sequence_45_frame2.fa.txt'], ['set45_frame2', 4.427, 'alignment_Error_Exon_12_query_Polyommatus_iphigenia_translated_genomic_sequence_45_frame2.fa.txt'], ['set28_frame1', 4.411, 'alignment_Error_Exon_12_query_Lysandra_bellargus_translated_genomic_sequence_28_frame1.fa.txt'], ['set28_frame1', 4.488, 'alignment_Error_Exon_12_query_Polyommatus_iphigenia_translated_genomic_sequence_28_frame1.fa.txt'], ['set31_frame0', 4.542, 'alignment_Error_Exon_12_query_Polyommatus_iphigenia_translated_genomic_sequence_31_frame0.fa.txt'], ['set45_frame2', 4.477, 'alignment_Error_Exon_12_query_Lysandra_bellargus_translated_genomic_sequence_45_frame2.fa.txt'], ['set11_frame0', 4.407, 'alignment_Error_Exon_12_query_Glaucopsyche_alexis_translated_genomic_sequence_11_frame0.fa.txt']]\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Helleia_helle_E ------------------------------------------AVIKPKLLAKEQMSKRSR\n",
      "set13_frame0_He FLRYIYYELSFQNQINLKINFEFEVKITFELKVRIIHIPIHQAVTKPTQLANEQMTKKCQ\n",
      "                                                          ** **. **:***:*:.:\n",
      "\n",
      "Helleia_helle_E DIAAYMDYYIYKVKTVPKADEREDMKT----\n",
      "set13_frame0_He DIAAFMDLFIDMTKTEIKEEEVEEIKTVSII\n",
      "                ****:** :*  .**  * :* *::**    \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Polyommatus_iph ------------------------------------------VLSKPTKLAKQQMTKRCQ\n",
      "set13_frame0_Po FLRYIYYELSFQNQINLKINFEFEVKITFELKVRIIHIPIHQAVTKPTQLANEQMTKKCQ\n",
      "                                                          .::***:**::****:**\n",
      "\n",
      "Polyommatus_iph EIAAFMESFIDKTNINSAMPFKDKKC---------\n",
      "set13_frame0_Po DIAAFMDLFIDMTKTE----IKEEEVEEIKTVSII\n",
      "                :*****: *** *: :    :*:::          \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Cyaniris_semiar VL------SKPTKLAKQQMTKRCQEIAAFMETFIDKTTVNPCIPFKDTKC-\n",
      "set28_frame1_Cy LIGERNTPSKTSNLIRH---------AGFLTTFSFTDERATCL-----GCT\n",
      "                ::      **.::* ::         *.*: **  .    .*:      * \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Cyaniris_semiar VLSKPTKLAKQQMTKRCQEIAAFMETFIDKTTVNPCIPFKDTK-----------------\n",
      "set45_frame2_Cy N------------------------------------PFKDATEIRIEYDPATKEGEPIK\n",
      "                                                     ****:.                 \n",
      "\n",
      "Cyaniris_semiar ---------C----\n",
      "set45_frame2_Cy KNLYVPIEICVYFR\n",
      "                         *    \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Polyommatus_iph VLSKPTKLAKQQMTKRCQEIAAFMESFIDKTNINSAMPFKD------------------K\n",
      "set45_frame2_Po ------------------------------------NPFKDATEIRIEYDPATKEGEPIK\n",
      "                                                     ****                  *\n",
      "\n",
      "Polyommatus_iph K--------C----\n",
      "set45_frame2_Po KNLYVPIEICVYFR\n",
      "                *        *    \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Lysandra_bellar VL------SKPTKLAKQQMTKRCQEIAAFMETFIGKITVDPCIPFKNTKC-\n",
      "set28_frame1_Ly LIGERNTPSKTSNLIRH---------AGFLTTFSFTDERATCL-----GCT\n",
      "                ::      **.::* ::         *.*: **  .    .*:      * \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Polyommatus_iph VL------SKPTKLAKQQMTKRCQEIAAFMESFIDKTNINSAMPFKDKKC------\n",
      "set28_frame1_Po LIGERNTPSKTSNLIRH---------AGFLTTF----------SFTDERATCLGCT\n",
      "                ::      **.::* ::         *.*: :*          .*.*::.      \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Polyommatus_iph V-------------------------------------LSKPTKLAKQQMTKRCQEIAAF\n",
      "set31_frame0_Po VAFENLNVRATIVLNGPGNSLKIKIKTHLKTPQRSGSNMILPLKRASQ-----LKKIYMY\n",
      "                *                                     :  * * *.*      ::*  :\n",
      "\n",
      "Polyommatus_iph MESFIDKTNINSAMPFKDKKC\n",
      "set31_frame0_Po LLKFVYIS-------------\n",
      "                : .*:  :             \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Lysandra_bellar VLSKPTKLAKQ------QMTKRCQEIAAFMETFIGKITVDPCIPFKNTKC\n",
      "set45_frame2_Ly ---NPFKDATEIRIEYDPATKEGEPIKKNL-----YVPIEICVYFR----\n",
      "                   :* * *.:        **. : *   :      :.:: *: *:    \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Glaucopsyche_al LLNQVLAKPIKLAKQQMTKRCQEIAAFMESFIDKTNIDNCMALK-DKC\n",
      "set11_frame0_Gl F-------KILTSKEFLNNTC--IAKHFNVFFLFTDFDKKKHIHINSI\n",
      "                :        *  :*: :.: *  ** .:: *:  *::*:   :: :. \n",
      "\n",
      "/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/10.Lycaenidae/1.Blast_result/Lycaena_phlaeas/Error_exon_processing/Error_Exon_12/for_alignment//alignment_Error_Exon_12_query_Helleia_helle_translated_genomic_sequence_13_frame0.fa.txt\n",
      "Alignmnet file: alignment_Error_Exon_12_query_Helleia_helle_translated_genomic_sequence_13_frame0.fa.txt\n",
      "alignment_clustal_Error_Exon_12_query_Helleia_helle_translated_genomic_sequence_13_frame0.fa.txt\n",
      "Exon_12\n",
      "Helleia_helle_Exon_12_OY971420.1_9152620_9152754_left_0_right_0\n",
      "here here 1 1 set13_frame0 Helleia_helle_Exon_12_OY971420.1_9152620_9152754_left_0_right_0 42 87\n",
      "here here 1 1 set13_frame0 set13_frame0_Helleia_helle 42 87\n",
      "set13_frame0_Helleia_helle\n",
      "AVTKPTQLANEQMTKKCQDIAAFMDLFIDMTKTEIKEEEVEEIKT\n",
      "alignment_clustal_Error_Exon_12_query_Helleia_helle_translated_genomic_sequence_13_frame0.fa.txt\n",
      "Alignment File: CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Helleia_helle_E ------------------------------------------AVIKPKLLAKEQMSKRSR\n",
      "set13_frame0_He FLRYIYYELSFQNQINLKINFEFEVKITFELKVRIIHIPIHQAVTKPTQLANEQMTKKCQ\n",
      "                                                          ** **. **:***:*:.:\n",
      "\n",
      "Helleia_helle_E DIAAYMDYYIYKVKTVPKADEREDMKT----\n",
      "set13_frame0_He DIAAFMDLFIDMTKTEIKEEEVEEIKTVSII\n",
      "                ****:** :*  .**  * :* *::**    \n",
      "\n",
      "Query OK?VTKPTQLANEQMTKKCQDIAAFMDLFIDMTKTEIKEEEVEE\n",
      "\n",
      "\n",
      "Building a new DB, current time: 05/05/2024 22:08:51\n",
      "New DB name:   /mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/10.Lycaenidae/1.Blast_result/Lycaena_phlaeas/Error_exon_processing/Error_Exon_12/Run_Blast/local_db.txt\n",
      "New DB title:  local_db.txt\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.00145483 seconds.\n",
      "[[0, 0]]\n",
      "set13_frame0_Helleia_helle\n",
      "580 714\n",
      "reached here\n",
      "sequence:\n",
      "GCCGTGACAAAACCAACTCAATTAGCCAATGAGCAGATGACTAAAAAGTGTCAGGACATAGCTGCGTTCATGGATTTGTTCATTGATATGACGAAGACGGAAATCAAGGAAGAGGAAGTTGAGGAGATTAAGact\n",
      "sequence:\n",
      "AVTKPTQLANEQMTKKCQDIAAFMDLFIDMTKTEIKEEEVEEIKT\n",
      "left = AG, right =gt\n",
      "AVTKPTQLANEQMTKKCQDIAAFMDLFIDMTKTEIKEEEVEEIKT\n",
      "[[0, 0]]\n",
      "start_coordinate : 7224504,stop_coordinate : 7224638\n",
      "Lycaena_phlaeas,HG995168.1,7224504,7224638,0,N,Aricia_agestis_XM_042131467.1_Frame_0_rightoh_0_query_Exon_12,1,45,45,Y,Y\n",
      "\n",
      "Fix Overhang!! Proceed?y\n",
      "Eumaeus_atala,JAFELO010001018.1,000,000,0,Y,Error_Exon_15,00,00,00\n",
      "\n",
      "Exon_15.fa\n",
      "Lysandra_coridon_Exon_15_HG992055.1_23645666_23645797_left_1_right_2\n",
      "VASTTNAKASPLSSEQTTASTSSSPNSTVLQNKTVWLTESLLN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exon_15.fa\n",
      "Polyommatus_iphigenia_Exon_15_OY730178.1_31373552_31373683_left_1_right_2\n",
      "VAPTRNAKVSPMPSEQTTTSTNSSPNSTILQNKTVWLTESLLN\n",
      "Exon_15.fa\n",
      "Phengaris_arion_Exon_15_OY751437.1_16886185_16886313_left_1_right_2\n",
      "VASTTNANVSPVPSDQTTASSSSSPESTAQNQTVWLTESLLN\n",
      "Exon_15.fa\n",
      "Aricia_artaxerxes_Exon_15_OW569310.1_36530174_36530305_left_1_right_2\n",
      "VAPTTNAKVSPIPSEQTTTSTSSSPNSTVLQNKTVWLTESLLN\n",
      "Exon_15.fa\n",
      "Cyaniris_semiargus_Exon_15_LR994547.1_15924018_15924149_left_1_right_2\n",
      "GAPTTSVKVSPIASEQTTASTSSSPNSTVLQNKTVRLTESLLN\n",
      "Gene_start = 337893, Gene_end = 339195\n",
      "Getting Gene\n",
      "GCA_017140195.1_ASM1714019v1_genomic.fna\n",
      "['1.Query', '1.Blast_result', 'tblastnAricia_agestis.sh', 'temp', '0.Temp', 'error_exons.txt', '2.Final_output', '3.Test_alignment', 'desktop.ini']\n",
      "['Calycopis_cecrops_Exon_15.fa', 'Lycaena_phlaeas_Exon_15.fa', 'Plebejus_argus_Exon_15.fa', 'Polyommatus_icarus_Exon_15.fa', 'Polyommatus_iphigenia_Exon_15.fa', 'Lysandra_coridon_Exon_15.fa', 'Phengaris_arion_Exon_15.fa', 'Aricia_artaxerxes_Exon_15.fa', 'Cyaniris_semiargus_Exon_15.fa', 'desktop.ini']\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "Error_Exon_15\n",
      "min = set15_frame1, 2.359\n",
      "5 top scores:\n",
      "[['set15_frame1', 2.8, 'alignment_Error_Exon_15_query_Lysandra_coridon_translated_genomic_sequence_15_frame1.fa.txt'], ['set15_frame1', 3.087, 'alignment_Error_Exon_15_query_Aricia_artaxerxes_translated_genomic_sequence_15_frame1.fa.txt'], ['set15_frame1', 2.359, 'alignment_Error_Exon_15_query_Calycopis_cecrops_translated_genomic_sequence_15_frame1.fa.txt'], ['set15_frame1', 3.175, 'alignment_Error_Exon_15_query_Cyaniris_semiargus_translated_genomic_sequence_15_frame1.fa.txt'], ['set15_frame2', 4.142, 'alignment_Error_Exon_15_query_Phengaris_arion_translated_genomic_sequence_15_frame2.fa.txt'], ['set22_frame1', 4.247, 'alignment_Error_Exon_15_query_Aricia_artaxerxes_translated_genomic_sequence_22_frame1.fa.txt'], ['set22_frame1', 4.277, 'alignment_Error_Exon_15_query_Cyaniris_semiargus_translated_genomic_sequence_22_frame1.fa.txt'], ['set15_frame2', 4.261, 'alignment_Error_Exon_15_query_Calycopis_cecrops_translated_genomic_sequence_15_frame2.fa.txt'], ['set12_frame0', 4.383, 'alignment_Error_Exon_15_query_Cyaniris_semiargus_translated_genomic_sequence_12_frame0.fa.txt'], ['set15_frame2', 4.418, 'alignment_Error_Exon_15_query_Cyaniris_semiargus_translated_genomic_sequence_15_frame2.fa.txt']]\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Lysandra_corido VASTTNAKA--------SPLSSEQTTASTSSSPNSTVLQNKTVWLTESLLN-\n",
      "set15_frame1_Ly FTILSIYAVLKIFLFIYSSRSNQDSDASTSSSPVLTPPNNQTVWLTEAMINK\n",
      "                .:  :   .        *. *.::: *******  *  :*:******:::* \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Aricia_artaxerx VAPTTNAKV--------SPIPSEQTTTSTSSSPNSTVLQNKTVWLTESLLN-\n",
      "set15_frame1_Ar FTILSIYAVLKIFLFIYSSRSNQDSDASTSSSPVLTPPNNQTVWLTEAMINK\n",
      "                .:  :   *        *. ..::: :******  *  :*:******:::* \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Calycopis_cecro ----------SKNYYFYSVRAKEKVDGPATSSPVVTSASTQTVWLTEALIN-\n",
      "set15_frame1_Ca FTILSIYAVLKIFLFIYSSRSNQDSDASTSSSPVLTPPNNQTVWLTEAMINK\n",
      "                          .   ::** *:::. *..::****:*....********:** \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Cyaniris_semiar GAPTTSVKV--------SPIASEQTTASTSSSPNSTVLQNKTVRLTESLLN-\n",
      "set15_frame1_Cy FTILSIYAVLKIFLFIYSSRSNQDSDASTSSSPVLTPPNNQTVWLTEAMINK\n",
      "                 :  :   *        *. :.::: *******  *  :*:** ***:::* \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Phengaris_arion VASTTNANVSPVPSDQTTASSSSSP------ESTAQNQTVWLTES---------------\n",
      "set15_frame2_Ph ------GTLRATPTDHVVACDSDGPFRVLGERGQEQNRTSSFVDGNGVSSRQNTPAAHFR\n",
      "                      ..: ..*:*:..*..*..*      ..  **:*  :.:.               \n",
      "\n",
      "Phengaris_arion -----------------------LLN\n",
      "set15_frame2_Ph RCPIKKYWKKTIGYIQNSSRHTYINS\n",
      "                                       : .\n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Aricia_artaxerx VAPTTNAKVSPIPSEQTTTSTSSSPNSTVLQNKTVWLTESLLN\n",
      "set22_frame1_Ar FRGWQWRQQSP---KHTSCTLSTLSNKKVLE-KNYWIYPKFV-\n",
      "                .      : **   ::*: : *: .*..**: *. *:  .:: \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Cyaniris_semiar GAPTTSVKVSPIASEQTTASTSSSPNSTVLQNKTVRLTESLLN\n",
      "set22_frame1_Cy FRGWQWRQQSP---KHTSCTLSTLSNKKVLEKNYWIYPKFV--\n",
      "                       : **   ::*:.: *: .*..**:::    .: :  \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Calycopis_cecro ----------------------------SKNYYFYSVRAKEKVDGPATSSPVVTSAS---\n",
      "set15_frame2_Ca GTLRATPTDHVVACDSDGPFRVLGERGQEQN------RTSSFVDGNGVSSRQNTPAAHFR\n",
      "                                            .:*      *:.. *** ..**   *.*:   \n",
      "\n",
      "Calycopis_cecro ---TQTVWLT----------EALIN-\n",
      "set15_frame2_Ca RCPIKKYWKKTIGYIQNSSRHTYINS\n",
      "                    :. * .          .: ** \n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Cyaniris_semiar GAPTTSVKV-SPIASEQTTASTSSSPNSTVLQNKTVRLTESLLN\n",
      "set12_frame0_Cy -----SQRIHNGLYMVHENVSGRLKINDTCTRDKVV-------G\n",
      "                     * :: . :   : ..*   . *.*  ::*.*       .\n",
      "\n",
      "CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Cyaniris_semiar G----------------------------------------------APTTSVKVSPIAS\n",
      "set15_frame2_Cy GTLRATPTDHVVACDSDGPFRVLGERGQEQNRTSSFVDGNGVSSRQNTPAAHFRRCPIKK\n",
      "                *                                              :*:: .: .** .\n",
      "\n",
      "Cyaniris_semiar --EQTTASTSSSPNSTVLQNKTVRLTESLLN\n",
      "set15_frame2_Cy YWKKTIGYIQNSSRHTYINS-----------\n",
      "                  ::* .  ..*.. * ::.           \n",
      "\n",
      "/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/10.Lycaenidae/1.Blast_result/Eumaeus_atala/Error_exon_processing/Error_Exon_15/for_alignment//alignment_Error_Exon_15_query_Calycopis_cecrops_translated_genomic_sequence_15_frame1.fa.txt\n",
      "Alignmnet file: alignment_Error_Exon_15_query_Calycopis_cecrops_translated_genomic_sequence_15_frame1.fa.txt\n",
      "alignment_clustal_Error_Exon_15_query_Calycopis_cecrops_translated_genomic_sequence_15_frame1.fa.txt\n",
      "Exon_15\n",
      "Calycopis_cecrops_Exon_15_LUGF01041786.1_141977_142102_left_1_right_2\n",
      "here here 1 1 set15_frame1 Calycopis_cecrops_Exon_15_LUGF01041786.1_141977_142102_left_1_right_2 10 51\n",
      "here here 1 1 set15_frame1 set15_frame1_Calycopis_cecrops 10 51\n",
      "set15_frame1_Calycopis_cecrops\n",
      "KIFLFIYSSRSNQDSDASTSSSPVLTPPNNQTVWLTEAMIN\n",
      "alignment_clustal_Error_Exon_15_query_Calycopis_cecrops_translated_genomic_sequence_15_frame1.fa.txt\n",
      "Alignment File: CLUSTAL format alignment by MAFFT L-INS-i (v7.525)\n",
      "\n",
      "\n",
      "Calycopis_cecro ----------SKNYYFYSVRAKEKVDGPATSSPVVTSASTQTVWLTEALIN-\n",
      "set15_frame1_Ca FTILSIYAVLKIFLFIYSSRSNQDSDASTSSSPVLTPPNNQTVWLTEAMINK\n",
      "                          .   ::** *:::. *..::****:*....********:** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "\n",
    "family_group = \"10.Lycaenidae\"\n",
    "\n",
    "output_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/{family_group}\"\n",
    "genome_location = \"/mnt/f/Genomes_2023-12-26\"\n",
    "\n",
    "with open(f\"{output_location}/error_exons.txt\",'r') as error_file:\n",
    "    error_file_lines = error_file.readlines()\n",
    "    \n",
    "for line in error_file_lines:\n",
    "    if len(line) != 1:\n",
    "        print(line)\n",
    "        line_split = line.split(\",\")\n",
    "        species = line_split[0]\n",
    "        error_exon = line_split[6]\n",
    "        \n",
    "        make_folder_error_exon(output_location,species,error_exon)\n",
    "        left_oh,right_oh = make_query(output_location,error_exon,species)\n",
    "        fragment_start, fragment_end, scaffold, complement,query_name = get_genomic_coordinates(output_location,error_exon,species)\n",
    "        print(f\"Gene_start = {fragment_start}, Gene_end = {fragment_end}\")\n",
    "        gene_sequence = get_gene_sequence(genome_location, \n",
    "                          species,                       \n",
    "                          scaffold,\n",
    "                          fragment_start,\n",
    "                          fragment_end,\n",
    "                          complement,\n",
    "                          output_location)\n",
    "        \n",
    "        make_raw_files_for_alignment(gene_sequence,output_location,species,error_exon)\n",
    "        mafft_run_location = run_mafft(output_location,species,error_exon)\n",
    "        \n",
    "        query_sequence, alignment_name,alignment_file = process_mafft_output(mafft_run_location, error_exon)\n",
    "        \n",
    "        print(f'Alignment File: {\"\".join(alignment_file)}')\n",
    "        query_check = input(\"Query OK?\")\n",
    "        if query_check[0].lower() == 'n':\n",
    "            query_sequence = input(\"Add new query :\")\n",
    "            if query_sequence == '':\n",
    "                print(species, error_exon)\n",
    "                assert False\n",
    "        run_blast(gene_sequence,query_sequence,alignment_name,output_location,species, error_exon)\n",
    "        ag_gt = process_genome_fragment_blast_file(output_location,left_oh,right_oh,species,genome_location)\n",
    "        if ag_gt != \"Error!! Too many stops\":\n",
    "            coordinate_output = process_genome_blast_file(output_location,left_oh,right_oh,species,genome_location,ag_gt,query_name)\n",
    "            print(coordinate_output)\n",
    "        else:\n",
    "            print(ag_gt)\n",
    "        input(\"Fix Overhang!! Proceed?\")\n",
    "#         print(gene_sequence)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mafft_run_location = run_mafft(output_location,species,error_exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#         print()\n",
    "        \n",
    "get_genomic_coordinates(output_location,error_exon,species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12854358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_files_for_alignment(gene_sequence,annotated_genome_location,annotated_species_name,error_exon,query_fasta_sequence,query_length):\n",
    "    for offset in range(3):\n",
    "        translated_sequence = str(gene_sequence[offset:].translate()).split(\"*\")\n",
    "        for i in range(len(translated_sequence)):\n",
    "            if len(translated_sequence[i])> 0.8*query_length:\n",
    "                sequence_set = f\">set{i+1}_frame{offset}\\n{translated_sequence[i]}\\n\\n\"\n",
    "                # print(i+1, offset)\n",
    "                \n",
    "                with open(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}/{error_exon}/for_alignment/{error_exon}_translated_genomic_sequence_{i+1}_frame{offset}.fa\",'w') as out_file:\n",
    "                    output = f\"{query_fasta_sequence}\\n\\n{sequence_set}\"\n",
    "                    out_file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba374ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
