{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d22ad3-a85e-44b3-85e6-fc9cb5b48684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blast_with_new_query(annotated_genome_location,\n",
    "                             annotated_species_name,\n",
    "                             error_exon, \n",
    "                            query_species,\n",
    "                             genome_location, \n",
    "                             species):\n",
    "    \n",
    "    genome_file = get_genome_file(genome_location,species)\n",
    "    query_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}/{error_exon}/for_blast/new_query.txt\"\n",
    "    genome = f\"{genome_location}/{species}/{genome_file}\"\n",
    "    out_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}/{error_exon}/for_blast\"\n",
    "\n",
    "    with open(f\"{out_location}/new_query.txt\", 'r') as query_file_open:\n",
    "        query_file_lines = query_file_open.readlines()\n",
    "    if (len(query_file_lines)) == 1:\n",
    "        return (\"Query_error\")\n",
    "    print(len(query_file_lines[1])) \n",
    "    if (len(query_file_lines[1])) < 5:\n",
    "        return (\"Query_error\")\n",
    "    # print(len(query_file_lines[1]))\n",
    "    # genome_fragment_out = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}/{error_exon}/for_blast/local_genomic_fragment.fa\"\n",
    "    # with io.open(genome_fragment_out,'w') as out_file:\n",
    "    #     output = f\">Genome_fragment_{error_exon}\\n{gene_sequence}\"\n",
    "    #     out_file.write(output)\n",
    "\n",
    "    local_genomic_fragment_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/\"\n",
    "    # cd_command = f'cd \"{local_genomic_fragment_location}\"\\nmakeblastdb -in gene_sequence_all.fa -dbtype nucl\\n'\n",
    "    # # os.system(f'{cd_command}')\n",
    "    # subprocess.run(f'{cd_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    # # print(mkdb_command)\n",
    "    # # os.system(f'{mkdb_command}')\n",
    "    blast_command = f'cd \"{out_location}\"\\ntblastn -seg no -query new_query.txt -db ../../../Period_gene_genomic_sequence_individual_exon/gene_sequence_all.fa -num_alignments 3 -out blast_out_genome_fragment.htm -html'\n",
    "    # print(blast_command)\n",
    "    # os.system(f'{blast_command}')\n",
    "    subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    # subprocess.run(f'{blast_command}', shell = True)\n",
    "    blast_command = f'cd \"{out_location}\"\\ntblastn -seg no -query new_query.txt -db ../../../Period_gene_genomic_sequence_individual_exon/gene_sequence_all.fa -num_alignments 3 -out blast_out_genome_fragment.txt'\n",
    "    # os.system(f'{blast_command}')\n",
    "    subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e7d0eb2-6d4d-44b8-90ab-76c864362837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genome_file(genome_location,species):\n",
    "    list_of_files_in_genome_folder = os.listdir(f\"{genome_location}/{species}\")\n",
    "    for file in list_of_files_in_genome_folder:\n",
    "        if file.endswith(\"_genomic.fna\"):\n",
    "            genome_file = file\n",
    "    return(genome_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd69b123-ff19-4205-83ee-039f63b0fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_info(query_location,query_species,query_transcript,query_exon):\n",
    "    with open(f\"{query_location}/{query_species}/{query_transcript}/query_{query_exon}.fa\", 'r') as query_file:\n",
    "        query_file_list = query_file.readlines()\n",
    "        query_fasta_sequence = \"\".join(query_file_list)\n",
    "        left_overhang = query_file_list[0].split(\"Frame\")[1][1]\n",
    "        right_overhang = query_file_list[0].split(\"rightoh\")[1][1]\n",
    "        original_query_name = query_file_list[0]\n",
    "    return(left_overhang,right_overhang,original_query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37864dc3-b190-4ffc-bd3c-ec61c8d7d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_genome_fragment_blast_file(annotated_genome_location, \n",
    "                                       annotated_species_name,\n",
    "                                       error_exon,\n",
    "                                       left_overhang,\n",
    "                                       right_overhang,                                                                                               \n",
    "                                       original_query_name,\n",
    "                                      query_species_original ):\n",
    "    blast_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species_original}/{error_exon}/for_blast\"\n",
    "    \n",
    "    with open(f\"{blast_location}/new_query.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_overhang),int(right_overhang)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    species_name = annotated_species_name\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out_genome_fragment.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "        \n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "        genome_file = SeqIO.parse(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon/gene_sequence_all.fa\", 'fasta')\n",
    "        print(\"reached here\")\n",
    "        print(f\"Before splice: {start},{stop}\")\n",
    "        acceptor, donor, don_line, acc_line = process_spiceator_result(start, stop,annotated_genome_location,annotated_species_name,query_species_original)\n",
    "        print(f\"after splice: {start},{stop}\")\n",
    "        for records in genome_file:\n",
    "            old_start = start\n",
    "            old_stop = stop\n",
    "            ag = \"N\"\n",
    "            gt = \"N\"\n",
    "            stop_counter = 0\n",
    "            while True:\n",
    "                print(f\"sequence:\\n{records.seq[start+start_modifier-1:stop]}\")\n",
    "                translated_sequence = records.seq[start+start_modifier-1:stop].translate()\n",
    "                print(f\"sequence:\\n{translated_sequence}\")\n",
    "                if \"*\" in translated_sequence:\n",
    "                    stop_counter +=1\n",
    "                    if ag == \"N\":\n",
    "                        start = old_start + 3*stop_counter\n",
    "                    if gt ==\"N\":\n",
    "                        stop = old_stop - 3*stop_counter\n",
    "                print(f\"left = {records.seq[start-3:start-1]}, right ={(records.seq[stop:stop + 2])}, stop_counter = {stop_counter}\"  ), \n",
    "                if (records.seq[start-3:start-1]).lower() == \"ag\" and ag != \"Y\":\n",
    "                    \n",
    "                    ag = \"Y\"\n",
    "                    \n",
    "                elif ag != \"Y\":\n",
    "                    start -= 3\n",
    "                    \n",
    "                if (records.seq[stop:stop + 2]).lower() == \"gt\" and gt != \"Y\":\n",
    "                    gt = \"Y\"\n",
    "                elif gt != \"Y\":\n",
    "                    stop +=3\n",
    "                if old_start - start > 1000 or stop - old_stop > 1000:\n",
    "                    break\n",
    "                if gt == \"Y\" and ag == \"Y\":\n",
    "                    gt_ag = \"Y\"\n",
    "                    break\n",
    "                if stop_counter > 10:\n",
    "                    gt = \"Y\"\n",
    "                    ag = \"Y\"\n",
    "                \n",
    "        \n",
    "        query_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species_original}/{error_exon}/for_blast/new_query_spliced.txt\"\n",
    "        with open(query_location , 'w') as query_file_new:\n",
    "            # sequence_translated = records.seq[start+start_modifier-1:stop]\n",
    "            # print(sequence_translated)\n",
    "            \n",
    "            sequence_translated = records.seq[start+start_modifier-1:stop].translate()\n",
    "            print(sequence_translated)\n",
    "            # proceed_test = input(\"Proceed with this?\")\n",
    "            # while True:\n",
    "            #     if proceed_test.lower()[0] == \"n\":\n",
    "            #         assert False\n",
    "            #     elif proceed_test.lower()[0] == \"y\":\n",
    "            #         break\n",
    "            if \"*\" in sequence_translated:\n",
    "                print(\"Errror in Spliced query\")\n",
    "                assert False\n",
    "            \n",
    "            output = f\">{original_query_name[1:]}\\n{sequence_translated}\"\n",
    "            query_file_new.write(output)\n",
    "\n",
    "        genome_file = get_genome_file(genome_location,species)\n",
    "        genome = f\"{genome_location}/{species}/{genome_file}\"\n",
    "        out_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species_original}/{error_exon}/for_blast\"\n",
    "    \n",
    "        \n",
    "        blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.htm\" -html'\n",
    "        # print(blast_command)\n",
    "        # subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "        subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "        blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.txt\"'\n",
    "        subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "\n",
    "                \n",
    "        # acceptor, donor, don_line, acc_line = process_spiceator_result(start, stop,annotated_genome_location,annotated_species_name)\n",
    "\n",
    "        if acceptor == \"Y\" and donor  == \"Y\":\n",
    "            splice_prediction = \"Y\"\n",
    "        else:\n",
    "            splice_prediction = \"N\"\n",
    "            \n",
    "        return(start,stop,gt_ag, splice_prediction) \n",
    "        # output_format = str(species_name.split(\"\\n\")[0])+\",\" + str(scaffold) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        # print(output_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27f9cc5-c2a8-4cb7-83e1-7104ee982cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spiceator_result(start_coordinate, stop_coordinate,annotated_genome_location,annotated_species_name,query_species_original):\n",
    "    results_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species_original}/\"\n",
    "#     list_of_files_here = os.listdir(results_location)\n",
    "#     spliceator_results_file = ''\n",
    "#     for files in list_of_files_here:\n",
    "#         if files.startswith(\"Spliceator_results\"):\n",
    "#             spliceator_results_file = files\n",
    "#     if spliceator_results_file == '':\n",
    "#         print(\"Splice file missing\")\n",
    "#         assert False\n",
    "\n",
    "#     with open(f\"{results_location}/{spliceator_results_file}\", 'r') as splice_file:\n",
    "#         splice_file_content = splice_file.readlines()\n",
    "\n",
    "    splice_acceptor_presence = \"N\"\n",
    "    splice_donor_presence = \"N\"\n",
    "    splice_donor = ''\n",
    "    splice_acceptor = ''\n",
    "    start_coordinate = 0\n",
    "    stop_coordinate = 0\n",
    "#     for lines in splice_file_content:\n",
    "#         line_split = lines.split(\";\")\n",
    "#         if line_split[0]==\"Acceptor\" and splice_acceptor_presence == \"N\":\n",
    "#             acceptor_start = int(line_split[1])\n",
    "#             acceptor_end = acceptor_start + len(line_split[3])\n",
    "            \n",
    "#             if start_coordinate >=acceptor_start and start_coordinate <=acceptor_end:\n",
    "#                 splice_acceptor_presence = \"Y\"\n",
    "#                 # while True:\n",
    "#                 #     if start_coordinate >= acceptor_start:\n",
    "#                 #         start_coordinate -= 3\n",
    "#                 #     else:\n",
    "#                 #         break\n",
    "#                 splice_acceptor = lines\n",
    "#         if line_split[0]==\"Donor\" and splice_donor_presence == \"N\":\n",
    "#             donor_start = int(line_split[1])\n",
    "#             donor_end = donor_start + len(line_split[3])\n",
    "#             if stop_coordinate >=donor_start and stop_coordinate <=donor_end:\n",
    "#                 splice_donor_presence = \"Y\"\n",
    "#                 # while True:\n",
    "#                 #     if stop_coordinate >=donor_start:\n",
    "#                 #         stop_coordinate -= 3\n",
    "#                 #     else:\n",
    "#                 #         break\n",
    "#                 splice_donor = lines\n",
    "\n",
    "    return(splice_acceptor_presence, splice_donor_presence, splice_donor, splice_acceptor)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c956e3-7a49-4f1f-b0e6-bac420e663ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang, ag_gt, splice_prediction,original_query_name, query_species ):\n",
    "    blast_location = f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}/{error_exon}/for_blast\"\n",
    "    with open(f\"{blast_location}/new_query_spliced.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_overhang),int(right_overhang)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length,\" +  \"AG_GT,\" + \"Spliceator_prediction\\n\"\n",
    "    \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    species_name = annotated_species_name\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "            # print(lines)\n",
    "            # print(query_name)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "        \n",
    "        print(f\"start_coordinate : {start_coor},stop_coordinate : {stop_coor}\")\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "            \n",
    "        output_format = str(species_name)+\",\" + str(scaff) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \",\" + ag_gt + \",\" + splice_prediction +\"\\n\"  \n",
    "        # print(Output_Sequence)\n",
    "        return(output_format)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79568c-ea02-45a4-88d2-b10f23f091e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Exon_2', 'Exon_3', 'Exon_4', 'Exon_5', 'Exon_6', 'Exon_7', 'Exon_8', 'Exon_9', 'Exon_10', 'Exon_11', 'Exon_12', 'Exon_13', 'Exon_14', 'Exon_15', 'Exon_16', 'Exon_17', 'Exon_18', 'Exon_19', 'Exon_20', 'Exon_21', 'Exon_22', 'Exon_23', 'Exon_24']\n",
      "Aricia_agestis\n",
      "Processing Exon_2\n",
      "0 query coordinate\n",
      "desktop.ini\n",
      "24\n",
      "[[1, 2]]\n",
      "reached here\n",
      "Before splice: 13118,13192\n",
      "after splice: 13118,13192\n",
      "sequence:\n",
      "TCAAAATCTACGTCAGAGAGTAACTCGAGCGGCAGCAGTGGCTACCGAGGGAAACGCACTGATGCTGATTACAT\n",
      "sequence:\n",
      "SKSTSESNSSGSSGYRGKRTDADY\n",
      "left = AG, right =GT, stop_counter = 0\n",
      "SKSTSESNSSGSSGYRGKRTDADY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurav/.local/lib/python3.8/site-packages/Bio/Seq.py:2880: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import io\n",
    "from Bio.Seq import Seq\n",
    "import subprocess\n",
    "family_group = \"10.Lycaenidae\"\n",
    "annotated_genome_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/{family_group}/1.Blast_result\"\n",
    "# annotated_genome_location = \"/mnt/j/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/3.Satyrine/1.Blast_result\"\n",
    "# species_list = [\"Coenonympha_glycerion\",\"Elymnias_hypermnestra\",\"Erebia_aethiops\",\"Erebia_ligea\",\"Hipparchia_semele\",\"Lasiommata_megera\",\"Maniola_hyperantus\",\"Maniola_jurtina\",\"Melanargia_galathea\",\"Oeneis_ivallda\",\"Pararge_aegeria\"]\n",
    "# species_list = [\"Bicyclus_anynana\"]\n",
    "# species_list = [\"Parnassius_glacialis\",\"Sericinus_montela\",\"Teinopalpus_imperialis\",\"Troides_aeacus\",\"Troides_oblongomaculatus\"]\n",
    "\n",
    "\n",
    "species_list = os.listdir(annotated_genome_location)\n",
    "if \"desktop.ini\" in species_list:\n",
    "    species_list.remove(\"desktop.ini\")\n",
    "# species_list = [\"Troides_oblongomaculatus\"]\n",
    "blast_error = []\n",
    "# query_species = \n",
    "for annotated_species_name in species_list:\n",
    "    # annotated_species_name = \"Lasiommata_megera\"\n",
    "    species = annotated_species_name\n",
    "    query_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/{family_group}/1.Query\"\n",
    "#     query_location = \"/mnt/j/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/3.Satyrine/1.Query\"\n",
    "#     query_species = \"00.Heliconius_melpomene0\" 4\n",
    "    list_of_query_species = os.listdir(query_location)\n",
    "    if \"desktop.ini\" in list_of_query_species:\n",
    "        list_of_query_species.remove(\"desktop.ini\")\n",
    "#     list_of_query_species = [\"Papilio_xuthus\"]\n",
    "    for query_species in list_of_query_species:\n",
    "    \n",
    "        query_transcript_list = os.listdir(f\"{query_location}/{query_species}\")\n",
    "        if \"desktop.ini\" in query_transcript_list:\n",
    "            query_transcript_list.remove(\"desktop.ini\")\n",
    "\n",
    "        query_transcript = query_transcript_list[0]\n",
    "\n",
    "        genome_location = \"/mnt/f/Genomes_2023-12-26\"\n",
    "        # genome_location = \"/mnt/g/Genomes_2023-12-26\"\n",
    "        list_of_exons_folders = os.listdir(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}\")\n",
    "        # print(list_of_exons_folders)\n",
    "        error_exon_list = []\n",
    "        for folders in list_of_exons_folders:\n",
    "\n",
    "            if folders.startswith(\"Exon\"):\n",
    "                if int(folders.split(\"_\")[1]) > 1:\n",
    "                    error_exon_list.append(folders)\n",
    "        print(error_exon_list)\n",
    "        # break\n",
    "\n",
    "\n",
    "    #     error_exon_list = [\"Exon_5\"]\n",
    "        for error_exon in error_exon_list:\n",
    "            print(annotated_species_name)\n",
    "            print(f\"Processing {error_exon}\")\n",
    "            coordinate_location = f\"{annotated_genome_location}/{species}\"\n",
    "            files_in_coordinate_location = os.listdir(coordinate_location)\n",
    "            coordinate_backup = 0\n",
    "            query_coordinate = 0\n",
    "            # print(files_in_coordinate_location)\n",
    "            for file_names in files_in_coordinate_location:\n",
    "                if file_names.endswith(\"_coordinates_old.csv\"):\n",
    "                    coordinate_backup = 1\n",
    "                if file_names.endswith(f\"_coordinates_{query_species}.csv\"):\n",
    "                    print(file_names)\n",
    "                    query_coordinate = 1\n",
    "            print(query_coordinate, \"query coordinate\")\n",
    "            if query_coordinate == 0:\n",
    "                print(file_names)\n",
    "                copy_command = f'cp \"{coordinate_location}/{species}_coordinates_old.csv\" \"{coordinate_location}/{species}_coordinates_{query_species}.csv\"'\n",
    "                subprocess.run(f'{copy_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "            if coordinate_backup == 0:\n",
    "                copy_command = f'cp \"{coordinate_location}/{species}_coordinates.csv\" \"{coordinate_location}/{species}_coordinates_old.csv\"'\n",
    "                subprocess.run(f'{copy_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "\n",
    "            query_error = run_blast_with_new_query(annotated_genome_location,\n",
    "                                         annotated_species_name,\n",
    "                                         error_exon, \n",
    "                                         query_species,\n",
    "                                         genome_location, \n",
    "                                         species )\n",
    "\n",
    "            if query_error == \"Query_error\":\n",
    "                print(query_error)\n",
    "                blast_error.append(f\"{annotated_species_name},{error_exon}\")\n",
    "                continue\n",
    "\n",
    "            left_overhang,right_overhang,original_query_name = get_query_info(query_location,query_species,query_transcript,error_exon)\n",
    "\n",
    "            try:\n",
    "                start_coordinate,stop_coordinate,gt_ag, splice_prediction = process_genome_fragment_blast_file(annotated_genome_location, \n",
    "                                                                                                           annotated_species_name,\n",
    "                                                                                                           error_exon,\n",
    "                                                                                                           left_overhang,\n",
    "                                                                                                           right_overhang,                                                                                               \n",
    "                                                                                                           original_query_name,\n",
    "                                                                                                          query_species)\n",
    "\n",
    "                new_coordinate_file_line = process_genome_blast_file(annotated_genome_location, \n",
    "                                                             annotated_species_name,\n",
    "                                                             error_exon,\n",
    "                                                             left_overhang,\n",
    "                                                             right_overhang,\n",
    "                                                             gt_ag, \n",
    "                                                             splice_prediction,\n",
    "                                                             original_query_name,\n",
    "                                                                query_species)\n",
    "            except:\n",
    "                print(\"Error in Blast\")\n",
    "                blast_error.append(f\"{annotated_species_name},{error_exon}\")\n",
    "                continue\n",
    "\n",
    "            print(start_coordinate,stop_coordinate,gt_ag, splice_prediction)\n",
    "            print(new_coordinate_file_line)\n",
    "            output = ''\n",
    "            with open(f\"{coordinate_location}/{species}_coordinates_{query_species}.csv\", 'r') as open_coordinate_file:\n",
    "                coordinate_file_list = open_coordinate_file.readlines()\n",
    "                # print(coordinate_file_list)\n",
    "                # assert False\n",
    "            for lines in coordinate_file_list:\n",
    "                if lines.split(\",\")[6].endswith(error_exon):\n",
    "                    lines = new_coordinate_file_line\n",
    "                output += lines\n",
    "\n",
    "            with open(f\"{coordinate_location}/{species}_coordinates_{query_species}.csv\", 'w') as out_coordinate_file:\n",
    "                out_coordinate_file.write(output)\n",
    "\n",
    "\n",
    "print(\"\\n\".join(blast_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c490af29-b58c-4481-8429-8779374d7ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang, \"1\", splice_prediction,original_query_name, query_species )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fff37c-451f-48f4-8a15-eba962efc380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
