{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef3edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process_genome_name(genome_location):\n",
    "    genome  = SeqIO.parse(genome_location, 'fasta')\n",
    "    output = ''\n",
    "    for record in genome:\n",
    "        output+=f\">{record.id.split('.')[0]}\\n{record.seq}\"\n",
    "    \n",
    "    with open(genome_location, 'w') as out_file:\n",
    "        out_file.write(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d42e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Make Lastz Chains #\n",
      "Version 2.0.8\n",
      "Commit: 187e313afc10382fe44c96e47f27c4466d63e114\n",
      "Branch: main\n",
      "\n",
      "* found run_lastz.py at /mnt/f/make_lastz_chains/standalone_scripts/run_lastz.py\n",
      "* found run_lastz_intermediate_layer.py at /mnt/f/make_lastz_chains/standalone_scripts/run_lastz_intermediate_layer.py\n",
      "* found chain_gap_filler.py at /mnt/f/make_lastz_chains/standalone_scripts/chain_gap_filler.py\n",
      "* found faToTwoBit at /mnt/f/make_lastz_chains/HL_kent_binaries/faToTwoBit\n",
      "* found twoBitToFa at /mnt/f/make_lastz_chains/HL_kent_binaries/twoBitToFa\n",
      "* found pslSortAcc at /mnt/f/make_lastz_chains/HL_kent_binaries/pslSortAcc\n",
      "* found axtChain at /mnt/f/make_lastz_chains/HL_kent_binaries/axtChain\n",
      "* found axtToPsl at /mnt/f/make_lastz_chains/HL_kent_binaries/axtToPsl\n",
      "* found chainAntiRepeat at /mnt/f/make_lastz_chains/HL_kent_binaries/chainAntiRepeat\n",
      "* found chainMergeSort at /mnt/f/make_lastz_chains/HL_kent_binaries/chainMergeSort\n",
      "* found chainCleaner at /mnt/f/make_lastz_chains/HL_kent_binaries/chainCleaner\n",
      "* found chainSort at /mnt/f/make_lastz_chains/HL_kent_binaries/chainSort\n",
      "* found chainScore at /mnt/f/make_lastz_chains/HL_kent_binaries/chainScore\n",
      "* found chainNet at /mnt/f/make_lastz_chains/HL_kent_binaries/chainNet\n",
      "* found chainFilter at /mnt/f/make_lastz_chains/HL_kent_binaries/chainFilter\n",
      "* found lastz at /home/saurav/miniconda3/envs/ncbi_datasets/bin/lastz\n",
      "* found nextflow at /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow\n",
      "All necessary executables found.\n",
      "Making chains for /mnt/f/temp_folder/query_genome.fa and /mnt/f/temp_folder/target_genome.fa files, saving results to /mnt/f/temp_folder/out\n",
      "Pipeline started at 2024-04-08 15:20:28.969425\n",
      "* Setting up genome sequences for target\n",
      "genomeID: target\n",
      "input sequence file: /mnt/f/temp_folder/query_genome.fa\n",
      "is 2bit: False\n",
      "planned genome dir location: /mnt/f/temp_folder/out/target.2bit\n",
      "Initial fasta file /mnt/f/temp_folder/query_genome.fa saved to /mnt/f/temp_folder/out/target.2bit\n",
      "For target (target) sequence file: /mnt/f/temp_folder/out/target.2bit; chrom sizes saved to: /mnt/f/temp_folder/out/target.chrom.sizes\n",
      "* Setting up genome sequences for query\n",
      "genomeID: query\n",
      "input sequence file: /mnt/f/temp_folder/target_genome.fa\n",
      "is 2bit: False\n",
      "planned genome dir location: /mnt/f/temp_folder/out/query.2bit\n",
      "Initial fasta file /mnt/f/temp_folder/target_genome.fa saved to /mnt/f/temp_folder/out/query.2bit\n",
      "For query (query) sequence file: /mnt/f/temp_folder/out/query.2bit; chrom sizes saved to: /mnt/f/temp_folder/out/query.chrom.sizes\n",
      "\n",
      "### Partition Step ###\n",
      "\n",
      "# Partitioning for target\n",
      "Saving partitions and creating 1 buckets for lastz output\n",
      "In particular, 0 partitions for bigger chromosomes\n",
      "And 1 buckets for smaller scaffolds\n",
      "Saving target partitions to: /mnt/f/temp_folder/out/target_partitions.txt\n",
      "# Partitioning for query\n",
      "Saving partitions and creating 1 buckets for lastz output\n",
      "In particular, 0 partitions for bigger chromosomes\n",
      "And 1 buckets for smaller scaffolds\n",
      "Saving query partitions to: /mnt/f/temp_folder/out/query_partitions.txt\n",
      "Num. target partitions: 0\n",
      "Num. query partitions: 0\n",
      "Num. lastz jobs: 0\n",
      "\n",
      "### Lastz Alignment Step ###\n",
      "\n",
      "LASTZ: making jobs\n",
      "LASTZ: saved 1 jobs to /mnt/f/temp_folder/out/temp_lastz_run/lastz_joblist.txt\n",
      "Parallel manager: pushing job /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow /mnt/f/make_lastz_chains/parallelization/execute_joblist.nf --joblist /mnt/f/temp_folder/out/temp_lastz_run/lastz_joblist.txt -c /mnt/f/temp_folder/out/temp_lastz_run/lastz_config.nf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 23.10.1\n",
      "Launching `/mnt/f/make_lastz_chains/parallelization/execute_joblist.nf` [reverent_hoover] DSL2 - revision: 0483b29723\n",
      "[-        ] process > execute_jobs -\n",
      "\n",
      "executor >  local (1)\n",
      "[ba/296f21] process > execute_jobs (1) [  0%] 0 of 1\n",
      "\n",
      "executor >  local (1)\n",
      "[ba/296f21] process > execute_jobs (1) [100%] 1 of 1 ✔\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "### Nextflow process lastz finished successfully\n",
      "Found 1 output files from the LASTZ step\n",
      "Please note that lastz_step.py does not produce output in case LASTZ could not find any alignment\n",
      "\n",
      "### Concatenating Lastz Results (Cat) Step ###\n",
      "\n",
      "Concatenating LASTZ output from 1 buckets\n",
      "* concatenated bucket bucket_ref_bulk_1 to /mnt/f/temp_folder/out/temp_concat_lastz_output/concat_0.psl.gz\n",
      "Concatenated 1 files in total into 1 files\n",
      "\n",
      "### Build Chains Step ###\n",
      "\n",
      "Sorting PSL files, saving the results to /mnt/f/temp_folder/out/temp_chain_run/sorted_psl\n",
      "/mnt/f/make_lastz_chains/HL_kent_binaries/pslSortAcc nohead /mnt/f/temp_folder/out/temp_chain_run/sorted_psl /mnt/f/temp_folder/out/temp_kent /mnt/f/temp_folder/out/temp_concat_lastz_output/concat_0.psl.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /mnt/f/temp_folder/out/temp_concat_lastz_output/concat_0.psl.gz\n",
      "Processed 85 lines into 1 temp files\n",
      "writing /mnt/f/temp_folder/out/temp_chain_run/sorted_psl\n",
      "Cleaning up temp files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bundling psl files with the following arguments:\n",
      "* input_dir: /mnt/f/temp_folder/out/temp_chain_run/sorted_psl\n",
      "* chrom_sizes: /mnt/f/temp_folder/out/target.chrom.sizes\n",
      "* output_dir: /mnt/f/temp_folder/out/temp_chain_run/split_psl\n",
      "* max_bases: 1000000\n",
      "* warning_only: False\n",
      "* verbose: False\n",
      "Saving results to: /mnt/f/temp_folder/out/temp_chain_run/split_psl\n",
      "Bundling 1 psl files in total\n",
      "Written to /mnt/f/temp_folder/out/temp_chain_run/split_psl/bundle.0.psl\n",
      "DONE. Produced 1 files\n",
      "PSL bundle sub-step done\n",
      "Building axtChain joblist for 1 bundled psl files\n",
      "Saving 1 axtChain jobs to /mnt/f/temp_folder/out/temp_chain_run/chains_joblist\n",
      "Parallel manager: pushing job /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow /mnt/f/make_lastz_chains/parallelization/execute_joblist.nf --joblist /mnt/f/temp_folder/out/temp_chain_run/chains_joblist -c /mnt/f/temp_folder/out/temp_chain_run/chain_run_config.nf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 23.10.1\n",
      "Launching `/mnt/f/make_lastz_chains/parallelization/execute_joblist.nf` [distracted_miescher] DSL2 - revision: 0483b29723\n",
      "[-        ] process > execute_jobs -\n",
      "\n",
      "executor >  local (1)\n",
      "[19/e96884] process > execute_jobs (1) [  0%] 0 of 1\n",
      "\n",
      "executor >  local (1)\n",
      "[19/e96884] process > execute_jobs (1) [  0%] 0 of 1\n",
      "\n",
      "executor >  local (1)\n",
      "[19/e96884] process > execute_jobs (1) [100%] 1 of 1 ✔\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "### Nextflow process chain_run finished successfully\n",
      "Chain run output files saved to /mnt/f/temp_folder/out/temp_chain_run/chain\n",
      "\n",
      "### Merge Chains Step ###\n",
      "\n",
      "Executing the following sequence of piped commands:\n",
      "['find', '/mnt/f/temp_folder/out/temp_chain_run/chain', '-name', '*chain']\n",
      "['/mnt/f/make_lastz_chains/HL_kent_binaries/chainMergeSort', '-inputList=stdin', '-tempDir=/mnt/f/temp_folder/out/temp_kent']\n",
      "['gzip', '-c']\n",
      "\n",
      "Saved merged results to: /mnt/f/temp_folder/out/temp_chain_run/target.query.all.chain.gz\n",
      "\n",
      "### Fill Chains Step ###\n",
      "\n",
      "Preparing fill jobs\n",
      "gunzip -c /mnt/f/temp_folder/out/temp_chain_run/target.query.all.chain.gz > /mnt/f/temp_folder/out/temp_fill_chain/temp.all.chain\n",
      "Found 10 chain IDs\n",
      "Wrote output to 10 files starting with '/mnt/f/temp_folder/out/temp_fill_chain/fill_chain_chunks/infill_chain_'.\n",
      "Creating repeat filler jobs list\n",
      "fGot 10 chain files to fill\n",
      "Adding --unmask flag\n",
      "Saved 10 chain fill jobs to /mnt/f/temp_folder/out/temp_fill_chain/repeat_filler_joblist.txt\n",
      "Parallel manager: pushing job /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow /mnt/f/make_lastz_chains/parallelization/execute_joblist.nf --joblist /mnt/f/temp_folder/out/temp_fill_chain/repeat_filler_joblist.txt -c /mnt/f/temp_folder/out/temp_fill_chain/fill_chain_config.nf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 23.10.1\n",
      "Launching `/mnt/f/make_lastz_chains/parallelization/execute_joblist.nf` [friendly_sanger] DSL2 - revision: 0483b29723\n",
      "[-        ] process > execute_jobs -\n",
      "\n",
      "executor >  local (1)\n",
      "[27/99bec9] process > execute_jobs (1) [  0%] 0 of 10\n",
      "\n",
      "executor >  local (2)\n",
      "[27/99bec9] process > execute_jobs (1) [ 10%] 1 of 10\n",
      "\n",
      "executor >  local (3)\n",
      "[46/9dbf84] process > execute_jobs (2) [ 20%] 2 of 10\n",
      "\n",
      "executor >  local (4)\n",
      "[60/882db7] process > execute_jobs (3) [ 30%] 3 of 10\n",
      "\n",
      "executor >  local (5)\n",
      "[64/bc833c] process > execute_jobs (6) [ 40%] 4 of 10\n",
      "\n",
      "executor >  local (5)\n",
      "[64/bc833c] process > execute_jobs (6) [ 40%] 4 of 10\n",
      "\n",
      "executor >  local (6)\n",
      "[be/2bff22] process > execute_jobs (5) [ 50%] 5 of 10\n",
      "\n",
      "executor >  local (7)\n",
      "[1b/e51d6e] process > execute_jobs (7) [ 60%] 6 of 10\n",
      "\n",
      "executor >  local (7)\n",
      "[1b/e51d6e] process > execute_jobs (7) [ 60%] 6 of 10\n",
      "\n",
      "executor >  local (8)\n",
      "[4c/cc91c0] process > execute_jobs (8) [ 70%] 7 of 10\n",
      "\n",
      "executor >  local (8)\n",
      "[4c/cc91c0] process > execute_jobs (8) [ 70%] 7 of 10\n",
      "\n",
      "executor >  local (9)\n",
      "[0a/7d9f2c] process > execute_jobs (9) [ 80%] 8 of 10\n",
      "\n",
      "executor >  local (10)\n",
      "[dd/58651b] process > execute_jobs (10) [ 90%] 9 of 10\n",
      "\n",
      "executor >  local (10)\n",
      "[dd/58651b] process > execute_jobs (10) [ 90%] 9 of 10\n",
      "\n",
      "executor >  local (10)\n",
      "[dd/58651b] process > execute_jobs (10) [100%] 10 of 10 ✔\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "### Nextflow process fill_chain finished successfully\n",
      "Merging filled chains\n",
      "Executing the following sequence of commands in a pipe:\n",
      "['find', '/mnt/f/temp_folder/out/temp_fill_chain/filled_chain_files', '-type', 'f', '-name', '*.chain', '-print']\n",
      "['/mnt/f/make_lastz_chains/HL_kent_binaries/chainMergeSort', '-inputList=stdin', '-tempDir=/mnt/f/temp_folder/out/temp_kent']\n",
      "['gzip', '-c']\n",
      "\n",
      "Merging filled chains done\n",
      "Fill chains step complete\n",
      "\n",
      "### Clean Chains Step ###\n",
      "\n",
      "Chains were filled: using /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain.gz as input\n",
      "Chain to be cleaned saved to: /mnt/f/temp_folder/out/temp_chain_run/target.query.before_cleaning.chain.gz\n",
      "Executing the following chain cleaner command:\n",
      "/mnt/f/make_lastz_chains/HL_kent_binaries/chainCleaner /mnt/f/temp_folder/out/temp_chain_run/target.query.before_cleaning.chain.gz /mnt/f/temp_folder/out/target.2bit /mnt/f/temp_folder/out/query.2bit /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain__temp /mnt/f/temp_folder/out/temp_chain_run/removed_suspects.bed -linearGap=loose -tSizes=/mnt/f/temp_folder/out/target.chrom.sizes -qSizes=/mnt/f/temp_folder/out/query.chrom.sizes -LRfoldThreshold=2.5 -doPairs -LRfoldThresholdPairs=10 -maxPairDistance=10000 -maxSuspectScore=100000 -minBrokenChainScore=75000\n",
      "Not filtered by score chains temporary saved to /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain__temp\n",
      "Chain clean results saved to: /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain\n",
      "Chain clean DONE\n",
      "\n",
      "### All core pipeline steps done ###\n",
      "\n",
      "Chains were filled, using /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain.gz as the last output file.\n",
      "Saved final chains file to /mnt/f/temp_folder/out/target.query.final.chain.gz\n",
      "Cleaning up the following directories\n",
      "x /mnt/f/temp_folder/out/temp_chain_run\n",
      "x /mnt/f/temp_folder/out/temp_concat_lastz_output\n",
      "x /mnt/f/temp_folder/out/temp_lastz_psl_output\n",
      "x /mnt/f/temp_folder/out/temp_lastz_run\n",
      "x /mnt/f/temp_folder/out/temp_fill_chain\n",
      "x /mnt/f/temp_folder/out/temp_kent\n",
      "And the following files:\n",
      "x /mnt/f/temp_folder/out/target.2bit\n",
      "x /mnt/f/temp_folder/out/query.2bit\n",
      "x /mnt/f/temp_folder/out/target_partitions.txt\n",
      "x /mnt/f/temp_folder/out/query_partitions.txt\n",
      "x /mnt/f/temp_folder/out/target.chrom.sizes\n",
      "x /mnt/f/temp_folder/out/query.chrom.sizes\n",
      "make_lastz_chains run done in 0:00:29.585949\n",
      "#### Initiating TOGA class ####\n",
      "# python interpreter path: /usr/bin/python3.11\n",
      "# python interpreter version: 3.11.9 (main, Apr  6 2024, 17:59:24) [GCC 9.4.0]\n",
      "Version 1.1.8.dev\n",
      "Commit: 97eb5a17ce76fccd9858b2ed738c51cd661292aa\n",
      "Branch: master\n",
      "\n",
      "# Python package versions\n",
      "* twobitreader: unknown version\n",
      "* networkx: 3.2.1\n",
      "* pandas: 2.1.2\n",
      "* numpy: 1.26.1\n",
      "* xgboost: 2.0.1\n",
      "! scikit-learn: Not installed - will try to install\n",
      "* joblib: 1.3.2\n",
      "* h5py: 3.10.0\n",
      "Calling cmd:\n",
      "/mnt/f/TOGA/configure.sh\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling C code...\n",
      "XGBoost model not found\n",
      "Training...\n",
      "Model created\n",
      "No git repo detected, downloading CESAR using wget...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/mnt/f/temp_folder/train_model.py': [Errno 2] No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Fasta.o src/Fasta.c\n",
      "gcc -O3 -std=c11   -c -o src/State.o src/State.c\n",
      "gcc -O3 -std=c11   -c -o src/Params.o src/Params.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from src/Params.c:10:\n",
      "src/Params.c: In function ‘Params__set_via_str’:\n",
      "src/Logging.h:33:19: warning: format ‘%u’ expects argument of type ‘unsigned int’, but argument 8 has type ‘size_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Params.c:414:7: note: in expansion of macro ‘logv’\n",
      "  414 |       logv(1, \"Setting %s := %u\", string, *((size_t*) INT_DICT[i][1]));\n",
      "      |       ^~~~\n",
      "src/Params.c:414:31: note: format string is defined here\n",
      "  414 |       logv(1, \"Setting %s := %u\", string, *((size_t*) INT_DICT[i][1]));\n",
      "      |                              ~^\n",
      "      |                               |\n",
      "      |                               unsigned int\n",
      "      |                              %lu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Literal.o src/Literal.c\n",
      "gcc -O3 -std=c11   -c -o src/Arguments.o src/Arguments.c\n",
      "gcc -O3 -std=c11   -c -o src/Alignment.o src/Alignment.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from src/Alignment.c:13:\n",
      "src/Alignment.c: In function ‘find_best_deletion’:\n",
      "src/Logging.h:33:19: warning: format ‘%u’ expects argument of type ‘unsigned int’, but argument 17 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Alignment.c:55:7: note: in expansion of macro ‘logv’\n",
      "   55 |       logv(6, \"lookup_query: %c%c%c (%c%c/%c%c)\\tprob (highest): %E (%E)\\tbest deletion: '%s' at pos=%u\\n\",\n",
      "      |       ^~~~\n",
      "src/Alignment.c:55:103: note: format string is defined here\n",
      "   55 |       logv(6, \"lookup_query: %c%c%c (%c%c/%c%c)\\tprob (highest): %E (%E)\\tbest deletion: '%s' at pos=%u\\n\",\n",
      "      |                                                                                                      ~^\n",
      "      |                                                                                                       |\n",
      "      |                                                                                                       unsigned int\n",
      "      |                                                                                                      %lu\n",
      "In file included from src/Alignment.c:13:\n",
      "src/Logging.h:33:19: warning: format ‘%u’ expects argument of type ‘unsigned int’, but argument 17 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Alignment.c:78:7: note: in expansion of macro ‘logv’\n",
      "   78 |       logv(6, \"lookup_query: %c%c%c (%c%c%c/%c)\\tprob (highest): %E (%E)\\tbest deletion: '%s' at pos=%u\\n\",\n",
      "      |       ^~~~\n",
      "src/Alignment.c:78:103: note: format string is defined here\n",
      "   78 |       logv(6, \"lookup_query: %c%c%c (%c%c%c/%c)\\tprob (highest): %E (%E)\\tbest deletion: '%s' at pos=%u\\n\",\n",
      "      |                                                                                                      ~^\n",
      "      |                                                                                                       |\n",
      "      |                                                                                                       unsigned int\n",
      "      |                                                                                                      %lu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Cesar.o src/Cesar.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "src/Cesar.c: In function ‘main’:\n",
      "src/Cesar.c:52:45: warning: ‘/extra/tables/’ directive output may be truncated writing 14 bytes into a region of size between 0 and 1023 [-Wformat-truncation=]\n",
      "   52 |   snprintf(prefix, PATH_STRING_LENGTH-1, \"%s/extra/tables/\", BaseDir);\n",
      "      |                                             ^~~~~~~~~~~~~~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Cesar.c:6:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:67:10: note: ‘__builtin___snprintf_chk’ output between 15 and 1038 bytes into a destination of size 1023\n",
      "   67 |   return __builtin___snprintf_chk (__s, __n, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   68 |        __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Cesar.c:66:42: warning: ‘%s’ directive writing up to 1023 bytes into a region of size 256 [-Wformat-overflow=]\n",
      "   66 |       sprintf(fileInsideBinaryLocation, \"%s%s/%s\", prefix, parameters.clade, reference->acceptor);\n",
      "      |                                          ^~        ~~~~~~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Cesar.c:6:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:36:10: note: ‘__builtin___sprintf_chk’ output between 2 and 2303 bytes into a destination of size 256\n",
      "   36 |   return __builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   37 |       __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Cesar.c:68:42: warning: ‘%s’ directive writing up to 1023 bytes into a region of size 256 [-Wformat-overflow=]\n",
      "   68 |       sprintf(pathInsideBinaryLocation, \"%s/%s\", BaseDir, reference->acceptor);\n",
      "      |                                          ^~      ~~~~~~~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Cesar.c:6:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:36:10: note: ‘__builtin___sprintf_chk’ output between 2 and 1280 bytes into a destination of size 256\n",
      "   36 |   return __builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   37 |       __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Cesar.c:116:42: warning: ‘%s’ directive writing up to 1023 bytes into a region of size 256 [-Wformat-overflow=]\n",
      "  116 |       sprintf(fileInsideBinaryLocation, \"%s%s/%s\", prefix, parameters.clade, reference->donor);\n",
      "      |                                          ^~        ~~~~~~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Cesar.c:6:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:36:10: note: ‘__builtin___sprintf_chk’ output between 2 and 2303 bytes into a destination of size 256\n",
      "   36 |   return __builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   37 |       __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Cesar.c:118:42: warning: ‘%s’ directive writing up to 1023 bytes into a region of size 256 [-Wformat-overflow=]\n",
      "  118 |       sprintf(pathInsideBinaryLocation, \"%s/%s\", BaseDir, reference->donor);\n",
      "      |                                          ^~      ~~~~~~~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Cesar.c:6:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:36:10: note: ‘__builtin___sprintf_chk’ output between 2 and 1280 bytes into a destination of size 256\n",
      "   36 |   return __builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   37 |       __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Model.o src/Model.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from src/Model.c:14:\n",
      "src/Model.c: In function ‘multi_exon’:\n",
      "src/Logging.h:33:19: warning: format ‘%i’ expects argument of type ‘int’, but argument 8 has type ‘size_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Model.c:243:13: note: in expansion of macro ‘logv’\n",
      "  243 |             logv(1, \"reference[%i]->sequence[%i-3-%i] == params->stop-codons[3*%i+%i]: %c == %c\", i,\n",
      "      |             ^~~~\n",
      "src/Model.c:243:47: note: format string is defined here\n",
      "  243 |             logv(1, \"reference[%i]->sequence[%i-3-%i] == params->stop-codons[3*%i+%i]: %c == %c\", i,\n",
      "      |                                              ~^\n",
      "      |                                               |\n",
      "      |                                               int\n",
      "      |                                              %li\n",
      "In file included from src/Model.c:14:\n",
      "src/Logging.h:39:19: warning: format ‘%u’ expects argument of type ‘unsigned int’, but argument 7 has type ‘size_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   39 |   fprintf(stderr, \"\\x1B[31mCRITICAL %s:%d %s():\\t\\x1B[0m\" format \"\\n\", __FILE__, __LINE__, __func__, ##__VA_ARGS__); exit(FAIL_EXIT);\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Logging.h:39:19: note: in definition of macro ‘die’\n",
      "   39 |   fprintf(stderr, \"\\x1B[31mCRITICAL %s:%d %s():\\t\\x1B[0m\" format \"\\n\", __FILE__, __LINE__, __func__, ##__VA_ARGS__); exit(FAIL_EXIT);\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Model.c:370:71: note: format string is defined here\n",
      "  370 |           die(\"Invalid number of split codon nucleotides in file %s: %u\", params->fasta_file, params->split_emissions_donor);\n",
      "      |                                                                      ~^\n",
      "      |                                                                       |\n",
      "      |                                                                       unsigned int\n",
      "      |                                                                      %lu\n",
      "src/Model.c: In function ‘create_profile_chain’:\n",
      "src/Model.c:36:26: warning: ‘%s’ directive writing up to 19 bytes into a region of size 14 [-Wformat-overflow=]\n",
      "   36 |     sprintf(name, \"match_%s\", profile->name);\n",
      "      |                          ^~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Model.c:11:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:36:10: note: ‘__builtin___sprintf_chk’ output between 7 and 26 bytes into a destination of size 20\n",
      "   36 |   return __builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   37 |       __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Model.c:36:26: warning: ‘%s’ directive writing up to 19 bytes into a region of size 14 [-Wformat-overflow=]\n",
      "   36 |     sprintf(name, \"match_%s\", profile->name);\n",
      "      |                          ^~\n",
      "In file included from /usr/include/stdio.h:867,\n",
      "                 from src/Model.c:11:\n",
      "/usr/include/x86_64-linux-gnu/bits/stdio2.h:36:10: note: ‘__builtin___sprintf_chk’ output between 7 and 26 bytes into a destination of size 20\n",
      "   36 |   return __builtin___sprintf_chk (__s, __USE_FORTIFY_LEVEL - 1,\n",
      "      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "   37 |       __bos (__s), __fmt, __va_arg_pack ());\n",
      "      |       ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Profile.o src/Profile.c\n",
      "gcc -O3 -std=c11   -c -o src/EmissionTable.o src/EmissionTable.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from src/EmissionTable.c:12:\n",
      "src/EmissionTable.c: In function ‘EmissionTable__read’:\n",
      "src/Logging.h:39:19: warning: format ‘%u’ expects argument of type ‘unsigned int’, but argument 9 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   39 |   fprintf(stderr, \"\\x1B[31mCRITICAL %s:%d %s():\\t\\x1B[0m\" format \"\\n\", __FILE__, __LINE__, __func__, ##__VA_ARGS__); exit(FAIL_EXIT);\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Logging.h:39:19: note: in definition of macro ‘die’\n",
      "   39 |   fprintf(stderr, \"\\x1B[31mCRITICAL %s:%d %s():\\t\\x1B[0m\" format \"\\n\", __FILE__, __LINE__, __func__, ##__VA_ARGS__); exit(FAIL_EXIT);\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/EmissionTable.c:94:83: note: format string is defined here\n",
      "   94 |           die(\"Unsupported order of oligomers found in %s:%lu: Expected %lu, got %u (%s)\", filename, lineno+1, expected, index, token);\n",
      "      |                                                                                  ~^\n",
      "      |                                                                                   |\n",
      "      |                                                                                   unsigned int\n",
      "      |                                                                                  %lu\n",
      "In file included from src/EmissionTable.c:12:\n",
      "src/EmissionTable.c: In function ‘EmissionTable__by_literals’:\n",
      "src/Logging.h:33:19: warning: format ‘%i’ expects argument of type ‘int’, but argument 8 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/EmissionTable.c:193:7: note: in expansion of macro ‘logv’\n",
      "  193 |       logv(7, \"    by literals: qry=%s=%i x ref=%s=%i\", qry, column, ref, row);\n",
      "      |       ^~~~\n",
      "src/EmissionTable.c:193:41: note: format string is defined here\n",
      "  193 |       logv(7, \"    by literals: qry=%s=%i x ref=%s=%i\", qry, column, ref, row);\n",
      "      |                                        ~^\n",
      "      |                                         |\n",
      "      |                                         int\n",
      "      |                                        %li\n",
      "In file included from src/EmissionTable.c:12:\n",
      "src/Logging.h:33:19: warning: format ‘%i’ expects argument of type ‘int’, but argument 10 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/EmissionTable.c:193:7: note: in expansion of macro ‘logv’\n",
      "  193 |       logv(7, \"    by literals: qry=%s=%i x ref=%s=%i\", qry, column, ref, row);\n",
      "      |       ^~~~\n",
      "src/EmissionTable.c:193:53: note: format string is defined here\n",
      "  193 |       logv(7, \"    by literals: qry=%s=%i x ref=%s=%i\", qry, column, ref, row);\n",
      "      |                                                    ~^\n",
      "      |                                                     |\n",
      "      |                                                     int\n",
      "      |                                                    %li\n",
      "In file included from src/EmissionTable.c:12:\n",
      "src/Logging.h:33:19: warning: format ‘%x’ expects argument of type ‘unsigned int’, but argument 7 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/EmissionTable.c:223:7: note: in expansion of macro ‘logv’\n",
      "  223 |       logv(7, \"Visit: %02x\", column);\n",
      "      |       ^~~~\n",
      "src/EmissionTable.c:223:26: note: format string is defined here\n",
      "  223 |       logv(7, \"Visit: %02x\", column);\n",
      "      |                       ~~~^\n",
      "      |                          |\n",
      "      |                          unsigned int\n",
      "      |                       %02lx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Matrix.o src/Matrix.c\n",
      "gcc -O3 -std=c11   -c -o src/Viterbi.o src/Viterbi.c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In file included from src/Viterbi.c:15:\n",
      "src/Viterbi.c: In function ‘Viterbi__step’:\n",
      "src/Logging.h:33:19: warning: format ‘%i’ expects argument of type ‘int’, but argument 11 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Viterbi.c:151:9: note: in expansion of macro ‘logv’\n",
      "  151 |         logv(6, \"t=%lu\\ti=%s=\"SID\"\\tqry=%s=%i\\tref=%s=%i\\temission_logodd=%E\",\n",
      "      |         ^~~~\n",
      "src/Viterbi.c:151:45: note: format string is defined here\n",
      "  151 |         logv(6, \"t=%lu\\ti=%s=\"SID\"\\tqry=%s=%i\\tref=%s=%i\\temission_logodd=%E\",\n",
      "      |                                            ~^\n",
      "      |                                             |\n",
      "      |                                             int\n",
      "      |                                            %li\n",
      "In file included from src/Viterbi.c:15:\n",
      "src/Logging.h:33:19: warning: format ‘%i’ expects argument of type ‘int’, but argument 13 has type ‘uint_fast16_t’ {aka ‘long unsigned int’} [-Wformat=]\n",
      "   33 |   fprintf(stderr, \"VERBOSE%i %s:%d %s():\\t\" format \"\\n\", level, __FILE__, __LINE__, __func__, ##__VA_ARGS__);\\\n",
      "      |                   ^~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "src/Viterbi.c:151:9: note: in expansion of macro ‘logv’\n",
      "  151 |         logv(6, \"t=%lu\\ti=%s=\"SID\"\\tqry=%s=%i\\tref=%s=%i\\temission_logodd=%E\",\n",
      "      |         ^~~~\n",
      "src/Viterbi.c:151:56: note: format string is defined here\n",
      "  151 |         logv(6, \"t=%lu\\ti=%s=\"SID\"\\tqry=%s=%i\\tref=%s=%i\\temission_logodd=%E\",\n",
      "      |                                                       ~^\n",
      "      |                                                        |\n",
      "      |                                                        int\n",
      "      |                                                       %li\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc -O3 -std=c11   -c -o src/Sequence.o src/Sequence.c\n",
      "gcc -O3 -std=c11   -c -o src/HMM.o src/HMM.c\n",
      "gcc -O3 -std=c11   -c -o src/Logodd.o src/Logodd.c\n",
      "gcc -O3 -std=c11 -o CESAR src/Fasta.o src/State.o src/Params.o src/Literal.o src/Arguments.o src/Alignment.o src/Cesar.o src/Model.o src/Profile.o src/EmissionTable.o src/Matrix.o src/Viterbi.o src/Sequence.o src/HMM.o src/Logodd.o -lm -lc\n",
      "mv CESAR cesar\n",
      "Don't worry about '*** are the same file' message if you see it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mv: 'CESAR' and 'cesar' are the same file\n",
      "make: *** [Makefile:19: cesar] Error 1\n",
      "Command finished with exit code 0.\n",
      "Does it work?\n",
      "Calling cmd:\n",
      "/mnt/f/TOGA/modules/chain_score_filter /mnt/f/temp_folder/out/target.query.final.chain 15000 > /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain\n",
      "\n",
      "Command finished with exit code 0.\n",
      "Continue without isoforms file: not provided\n",
      "Found 1 sequences in /mnt/f/temp_folder/query_genome.2bit\n",
      "Found 1 sequences in /mnt/f/temp_folder/query_genome.2bit\n",
      "Found 1 sequences in /mnt/f/temp_folder/target_genome.2bit\n",
      "Saving output to /mnt/f/temp_folder/toga_out\n",
      "Arguments stored in /mnt/f/temp_folder/toga_out/project_args.json\n",
      "\n",
      "\n",
      "#### STEP 0: making chain and bed file indexes\n",
      "\n",
      "Started chain indexing...\n",
      "chain_bst_index: indexing 2 chains\n",
      "chain_bst_index: Saved chain /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain index to /mnt/f/temp_folder/toga_out/temp/genome_alignment.bst\n",
      "Started bed file indexing...\n",
      "bed_hdf5_index: indexed 1 transcripts\n",
      "\n",
      "\n",
      "#### STEP 1: Generate extract chain features jobs\n",
      "\n",
      "Calling cmd:\n",
      "/mnt/f/TOGA/split_chain_jobs.py /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.hdf5 --log_file /mnt/f/temp_folder/toga_out/toga_2024_04_08_at_15_21.log --parallel_logs_dir /mnt/f/temp_folder/toga_out/temp_logs --jobs_num 100 --jobs /mnt/f/temp_folder/toga_out/temp/chain_classification_jobs --jobs_file /mnt/f/temp_folder/toga_out/temp/chain_class_jobs_combined --results_dir /mnt/f/temp_folder/toga_out/temp/chain_classification_results --rejected /mnt/f/temp_folder/toga_out/temp/rejected/SPLIT_CHAIN_REJ.txt \n",
      "\n",
      "split_chain_jobs: Use bed file /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed and chain file /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain\n",
      "split_chain jobs: the run data overview is:\n",
      "\n",
      "* vv: False\n",
      "* jobs: /mnt/f/temp_folder/toga_out/temp/chain_classification_jobs\n",
      "* results_dir: /mnt/f/temp_folder/toga_out/temp/chain_classification_results\n",
      "* errors_dir: None\n",
      "* chain_file: /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain\n",
      "* bed_file: /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed\n",
      "* index_file: /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain_ID_position\n",
      "* job_size: None\n",
      "* jobs_num: 100\n",
      "* bed_index: /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.hdf5\n",
      "* jobs_file: /mnt/f/temp_folder/toga_out/temp/chain_class_jobs_combined\n",
      "* ref: hg38\n",
      "* on_cluster: True\n",
      "split_chain_jobs: searching for intersections between reference transcripts and chains\n",
      "split_chain_jobs: chains-to-transcripts dict contains 1 records\n",
      "split_chain_jobs: skipped 0 transcripts that do not intersect any chain\n",
      "split_chain_jobs: preparing 1 commands\n",
      "split_chain_jobs: command size of 1 for each cluster job\n",
      "split_chain_jobs: results in 1 cluster jobs\n",
      "split_chain_jobs: estimated time: 0:00:00.087640\n",
      "Command finished with exit code 0.\n",
      "\n",
      "\n",
      "#### STEP 2: Extract chain features: parallel step\n",
      "\n",
      "Extracting chain features, project name: chain_feats__mntftemp_foldertoga_out_at_1712568983\n",
      "Project path: /mnt/f/TOGA/nextflow_logs/chain_feats__mntftemp_foldertoga_out_at_1712568983\n",
      "Selected parallelization strategy: nextflow\n",
      "Parallel manager: pushing job nextflow /mnt/f/TOGA/execute_joblist.nf --joblist /mnt/f/temp_folder/toga_out/temp/chain_class_jobs_combined\n",
      "Logs from individual chain runner jobs are show below\n",
      "\n",
      "\n",
      "#### STEP 3: Merge step 2 output\n",
      "\n",
      "Reading /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed\n",
      "merge_chains_output: got data for 1 transcripts\n",
      "merge_chains_output: Loading the results...\n",
      "merge_chains_output: There are 1 result files to combine\n",
      "merge_chains_output: got 1 keys in chain_genes_data\n",
      "merge_chains_output: got 1 keys in chain_raw_data\n",
      "merge_chains_output: There were 1 transcript lines and 1 chain lines\n",
      "merge_chains_output: chain_genes_data dict reverted, there are 1 keys now\n",
      "merge_chains_output: Combining the data...\n",
      "merge_chains_output: got combined dict with 1 keys\n",
      "merge_chains_output: Writing output to /mnt/f/temp_folder/toga_out/temp/chain_results_df.tsv\n",
      "merge_chains_output: total runtime: 0:00:28.253387\n",
      "\n",
      "\n",
      "#### STEP 4: Classify chains using gradient boosting model\n",
      "\n",
      "Classifying chains\n",
      "classify_chains: loaded dataframe of size 1\n",
      "classify_chains: total number of transcripts: 1\n",
      "classify_chains: 0 rows with spanning chains\n",
      "classify_chains: filtered dataset contains 1 records\n",
      "classify_chains: omputing additional features...\n",
      "classify_chains: df for single-exon model contains 0 records\n",
      "classify_chains: df for multi-exon model contains 1 records\n",
      "classify_chains: loading models at /mnt/f/TOGA/models/se_model.dat (SE) and /mnt/f/TOGA/models/me_model.dat (ME)\n",
      "classify_chains: applying models to SE and ME datasets...\n",
      "classify_chains: applying -1.0 score to the spanning chains\n",
      "classify_chains: applying -2.0 score to the processed pseudogene alignments\n",
      "classify_chains: number of processed pseudogene alignments: 0\n",
      "classify_chains: arranging the final output\n",
      "/mnt/f/TOGA/modules/classify_chains.py:209: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  overall_result = pd.concat([df_se_result, df_me_result, spanning_chains_result])\n",
      "classify_chains: classification result stats:\n",
      "* orthologs: 1\n",
      "* paralogs: 0\n",
      "* spanning chains: 0\n",
      "* processed pseudogenes: 0\n",
      "classify_chains: using 0.5 as a threshold to separate orthologs from paralogs\n",
      "classify_chains: combining results for 1 individual transcripts\n",
      "classify_chains: saving the classification to /mnt/f/temp_folder/toga_out/temp/trans_to_chain_classes.tsv\n",
      "classify_chains: found no classifiable chains for 0 transcripts\n",
      "classify_chains: saving these transcripts to: /mnt/f/temp_folder/toga_out/temp/rejected/classify_chains_rejected.txt\n",
      "\n",
      "\n",
      "#### STEP 5: Generate CESAR jobs\n",
      "Detecting fragmented transcripts\n",
      "stitch_fragments: started stitching fragmented orthologous loci (if any)\n",
      "stitch fragments: processing 1 transcripts with scores >= 0.5\n",
      "stitch fragments: processing total of 1 chains with scores\n",
      "stitch fragments: parsing chain file /mnt/f/temp_folder/toga_out/temp/genome_alignment.chain to get a mapping between chain ID and coordinates in the query genome\n",
      "stitch fragments: parsed 1 chains\n",
      "stitch fragments: processing 1 transcripts\n",
      "stitch fragments: identified 0 fragmented transcripts\n",
      "Fragments data saved to /mnt/f/temp_folder/toga_out/temp/gene_fragments.txt\n",
      "Setting up creating CESAR jobs\n",
      "Calling cmd:\n",
      "/mnt/f/TOGA/split_exon_realign_jobs.py /mnt/f/temp_folder/toga_out/temp/trans_to_chain_classes.tsv /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.hdf5 /mnt/f/temp_folder/toga_out/temp/genome_alignment.bst /mnt/f/temp_folder/query_genome.2bit /mnt/f/temp_folder/target_genome.2bit /mnt/f/temp_folder/toga_out --jobs_dir /mnt/f/temp_folder/toga_out/temp/cesar_jobs --jobs_num 500 --combined /mnt/f/temp_folder/toga_out/temp/cesar_combined --results /mnt/f/temp_folder/toga_out/temp/cesar_results --buckets 0 --mem_limit 16 --chains_limit 100 --skipped_genes /mnt/f/temp_folder/toga_out/temp/rejected/SPLIT_CESAR.txt --rejected_log /mnt/f/temp_folder/toga_out/temp/rejected --cesar_binary /mnt/f/TOGA/CESAR2.0/cesar --paralogs_log /mnt/f/temp_folder/toga_out/temp/paralogs.txt --uhq_flank 50 --predefined_glp_class_path /mnt/f/temp_folder/toga_out/temp/predefined_glp_cesar_split.tsv --unprocessed_log /mnt/f/temp_folder/toga_out/temp/technical_cesar_err --log_file /mnt/f/temp_folder/toga_out/toga_2024_04_08_at_15_21.log --cesar_logs_dir /mnt/f/temp_folder/toga_out/temp_logs  --mask_stops --check_loss /mnt/f/temp_folder/toga_out/temp/inact_mut_data --fragments_data /mnt/f/temp_folder/toga_out/temp/gene_fragments.txt\n",
      "\n",
      "split_cesar_jobs: the arguments list is:\n",
      "* orthologs_file: /mnt/f/temp_folder/toga_out/temp/trans_to_chain_classes.tsv\n",
      "* bed_file: /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed\n",
      "* bdb_bed_file: /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.hdf5\n",
      "* bdb_chain_file: /mnt/f/temp_folder/toga_out/temp/genome_alignment.bst\n",
      "* tDB: /mnt/f/temp_folder/query_genome.2bit\n",
      "* qDB: /mnt/f/temp_folder/target_genome.2bit\n",
      "* toga_out_dir: /mnt/f/temp_folder/toga_out\n",
      "* cesar_binary: /mnt/f/TOGA/CESAR2.0/cesar\n",
      "* jobs_num: 500\n",
      "* buckets: 0\n",
      "* mask_stops: True\n",
      "* chains_limit: 100\n",
      "* skipped_genes: /mnt/f/temp_folder/toga_out/temp/rejected/SPLIT_CESAR.txt\n",
      "* mem_limit: 16.0\n",
      "* jobs_dir: /mnt/f/temp_folder/toga_out/temp/cesar_jobs\n",
      "* combined: /mnt/f/temp_folder/toga_out/temp/cesar_combined\n",
      "* results: /mnt/f/temp_folder/toga_out/temp/cesar_results\n",
      "* check_loss: /mnt/f/temp_folder/toga_out/temp/inact_mut_data\n",
      "* u12: None\n",
      "* rejected_log: /mnt/f/temp_folder/toga_out/temp/rejected\n",
      "* paralogs_log: /mnt/f/temp_folder/toga_out/temp/paralogs.txt\n",
      "* uhq_flank: 50\n",
      "* o2o_only: False\n",
      "* no_fpi: False\n",
      "* annotate_paralogs: False\n",
      "* fragments_data: /mnt/f/temp_folder/toga_out/temp/gene_fragments.txt\n",
      "* predefined_glp_class_path: /mnt/f/temp_folder/toga_out/temp/predefined_glp_cesar_split.tsv\n",
      "* unprocessed_log: /mnt/f/temp_folder/toga_out/temp/technical_cesar_err\n",
      "* cesar_logs_dir: /mnt/f/temp_folder/toga_out/temp_logs\n",
      "* debug: False\n",
      "* mask_all_first_10p: False\n",
      "* log_file: /mnt/f/temp_folder/toga_out/toga_2024_04_08_at_15_21.log\n",
      "* quiet: False\n",
      "split_cesar_jobs: reading U12 data from None\n",
      "split_cesar_jobs: not U12 file provided: skip\n",
      "split_cesar_jobs: reading orthology data...\n",
      "split_cesar_jobs: for each transcript, find chains to produce annotations\n",
      "* selected chain class to annotate transcript Period: ORTH\n",
      "split_cesar_jobs: number of transcripts to create CESAR jobs: 1\n",
      "split_cesar_jobs: total number of 1 transcript/chain pairs\n",
      "split_cesar_jobs: skipped total of 0 transcripts\n",
      "split_cesar_jobs: out of them, transcripts not intersected by chains: 0\n",
      "split_cesar_jobs: assigning MISSING class to 0 transcripts not intersected by any chain\n",
      "split_cesar_jobs: creating a list of RAM-limit buckets based on user arguments\n",
      "split_cesar_jobs: split into buckets is not required, using only the limit 16.0\n",
      "split_cesar_jobs: reading bed file /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed\n",
      "split_cesar_jobs: got data for 1 transcripts\n",
      "split_cesar_jobs: reading transcript fragments data from /mnt/f/temp_folder/toga_out/temp/gene_fragments.txt\n",
      "split_cesar_jobs: got data for 0 transcripts potentially fragmented in the query genome\n",
      "split_cesar_jobs: precomputing query regions for each transcript/chain pair\n",
      "split_cesar_jobs: batch size: 1\n",
      "split_cesar_jobs: first, invert gene-to-chains dict to chain-to-genes\n",
      "split_cesar_jobs: for each of 1 involved chains, precompute regions\n",
      "split_cesar_jobs: precomputed regions for 1 transcripts\n",
      "split_cesar_jobs: skipped 0 projections\n",
      "split_cesar_jobs: predefined classification for 0 projections\n",
      "split_cesar_jobs: building commands for 1 transcripts\n",
      "split_cesar_jobs: some transcripts can be omitted (see above)\n",
      " * added job for transcript Period, chains: dict_keys(['1']), memory_requirements: 2.25, u12_data: None\n",
      "split_cesar_jobs: created 1 jobs in total\n",
      "split_cesar_jobs: filling the following RAM limit buckets: [0]\n",
      "No buckets to split, saving 1 jobs into the same queue\n",
      "split_cesar_jobs: defining number of cluster jobs for each bucket\n",
      "split_cesar_jobs: based on memory, the estimated runtime proportions are:\n",
      "* bucket 0Gb: 1.0\n",
      "Final numbers of cluster jobs per bucket are:\n",
      " * bucket 0Gb: 500 jobs\n",
      "split_cesar_jobs: saving CESAR job queues to /mnt/f/temp_folder/toga_out/temp/cesar_jobs\n",
      "# split_cesar_jobs: saved part  of bucket 0 to /mnt/f/temp_folder/toga_out/temp/cesar_jobs/cesar_job_1_0 with 1 commands\n",
      "split_cesar_jobs: saving combined CESAR jobs to /mnt/f/temp_folder/toga_out/temp/cesar_combined\n",
      "split_cesar_jobs: saving 0 skipped transcripts to /mnt/f/temp_folder/toga_out/temp/rejected/SPLIT_CESAR.txt\n",
      "split_cesar_jobs: precomputed gene loss classes for 0 items are saved to /mnt/f/temp_folder/toga_out/temp/predefined_glp_cesar_split.tsv\n",
      "split_cesar_jobs: potentially, for some transcripts, no orthologous chains found\n",
      "split_cesar_jobs: TOGA will create 0 paralogous projections (PG class); their IDs are saved to /mnt/f/temp_folder/toga_out/temp/paralogs.txt\n",
      "split_cesar_jobs: splitting jobs done in 0:00:00.191211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Command finished with exit code 0.\n",
      "\n",
      "\n",
      "#### STEP 6: Create processed pseudogenes track\n",
      "\n",
      "Creating processed pseudogenes track.\n",
      "make_pr_pseudogenes_anno: loading chain index...\n",
      "make_pr_pseudogenes anno: 0 transcripts have processed pseudogenes\n",
      "make_pr_pseudogenes_anno: no processed pseudogenes found, skip\n",
      "\n",
      "\n",
      "### STEP 7: Execute CESAR jobs: parallel step\n",
      "\n",
      "Pushing 1 CESAR job lists\n",
      "Pushing memory bucket 0Gb to the executor\n",
      "Selected parallelization strategy: nextflow\n",
      "Parallel manager: pushing job nextflow /mnt/f/TOGA/execute_joblist.nf --joblist /mnt/f/temp_folder/toga_out/temp/cesar_combined\n",
      "## Stated polling cluster jobs until they done\n",
      "Polling iteration 0; already waiting 0 seconds.\n",
      "### CESAR jobs done ###\n",
      "\n",
      "Checking whether all CESAR results are complete\n",
      "No CESAR jobs crashed\n",
      "Logs from individual CESAR jobs are show below\n",
      "\n",
      "\n",
      "#### STEP 8: Merge STEP 7 output\n",
      "\n",
      "Merging CESAR output to make fasta and bed files.\n",
      "merge_cesar_jobs: module called with arguments:\n",
      "* input_dir: /mnt/f/temp_folder/toga_out/temp/cesar_results\n",
      "* output_bed: /mnt/f/temp_folder/toga_out/temp/intermediate.bed\n",
      "* output_fasta: /mnt/f/temp_folder/toga_out/nucleotide.fasta\n",
      "* meta_data_arg: /mnt/f/temp_folder/toga_out/temp/exons_meta_data.tsv\n",
      "* skipped_arg: /mnt/f/temp_folder/toga_out/temp/rejected/CESAR_MERGE.txt\n",
      "* prot_arg: /mnt/f/temp_folder/toga_out/prot.fasta\n",
      "* codon_arg: /mnt/f/temp_folder/toga_out/codon.fasta\n",
      "* output_trash: /mnt/f/temp_folder/toga_out/temp/trash_exons.bed\n",
      "* fragm_data: /mnt/f/temp_folder/toga_out/temp/bed_fragments_to_exons.tsv\n",
      "* exclude: None\n",
      "merge_cesar_jobs: merging CESAR results from 1 output files\n",
      " * processing file cesar_job_1_0.txt 1/1\n",
      "merge_cesar_jobs: parsing file /mnt/f/temp_folder/toga_out/temp/cesar_results/cesar_job_1_0.txt with 1 reference transcript(s)\n",
      "merge_cesar_jobs: Added raw bed line for Period.1: FR989951\t100022\t135723\tPeriod.1\t1000\t-\t100022\t135723\t0,0,0\t22\t80,143,101,170,140,241,74,95,192,113,133,152,113,108,228,237,84,131,151,74,111,21,\t0,1378,1615,3573,5782,9645,10495,11422,14404,15423,17443,18064,19145,19367,19967,20695,23543,24350,26923,29374,30221,35680,\n",
      "merge_cesar_jobs: arranging fasta file\n",
      "merge_cesar_jobs: added 5 exons that are actually deleted or missing but annotated by CESAR\n",
      "merge_cesar_jobs: saving 1 bed lines from this part\n",
      "merge_cesar_jobs: Saving the output\n",
      "merge_cesar_jobs: writing 1 bed records to /mnt/f/temp_folder/toga_out/temp/intermediate.bed\n",
      "CESAR results merged\n",
      "\n",
      "\n",
      "#### STEP 9: Gene loss pipeline classification\n",
      "\n",
      "Calling gene loss summary\n",
      "Classification for 0 query transcripts was already computed\n",
      "Added 0 query transcripts classified as missing\n",
      "gene_loss_summary: called module with the following arguments:\n",
      "* loss_data_arg: /mnt/f/temp_folder/toga_out/temp/inact_mut_data\n",
      "* ref_bed: /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed\n",
      "* pre_final_bed_arg: /mnt/f/temp_folder/toga_out/temp/intermediate.bed\n",
      "* bed_out: /mnt/f/temp_folder/toga_out/query_annotation.bed\n",
      "* summary_arg: /mnt/f/temp_folder/toga_out/loss_summ_data.tsv\n",
      "* trace_arg: None\n",
      "* iforms_file: None\n",
      "* paral: /mnt/f/temp_folder/toga_out/temp/paralogs.txt\n",
      "* exclude_arg: None\n",
      "* predefined_class: []\n",
      "* t0: 2024-04-08 15:23:01.138416\n",
      "gene_loss_summary: 0 projections are annotated as paralogs\n",
      "gene_loss_summary: 0 projections are excluded from classification\n",
      "gene_loss_summary: extracted length data for 1 reference exons\n",
      "gene_loss_summary: reading inactivating mutations data...\n",
      "* reading data from cesar_job_1_0.inact_mut.txt...\n",
      "gene_loss_summary inactivating mutations output sizes:\n",
      "* projection_to_mutations: 1\n",
      "* projection_to_p_intact_M_ignore: 1\n",
      "* projection_to_p_intact_M_intact: 1\n",
      "* projection_to_i_codon_prop: 1\n",
      "* proj_to_prop_oub: 1\n",
      "* proj_to_80_p_intact: 1\n",
      "* proj_to_80_p_present: 1\n",
      "gene_loss_summary: loaded predefined classifications for 0 query projections and 0 reference transcripts\n",
      "gene_loss_summary: in total, 1 query projections are to be classified\n",
      "gene_loss_summary: classifying query projections: decision tree part\n",
      "* Period.1 classified as L: % intact 0.16857899382171226 < 0.2\n",
      "gene_loss_summary: Assigning colors to the bed file\n",
      "* Period.1 class L assigned color in the bed file: 255,50,50\n",
      "gene_loss_summary: assigning classes to reference transcripts based on the classifications of child query transcripts (projections)\n",
      "* transcript: Period classified as L :: child projections classes: ['L']\n",
      "gene_loss_summary: classifying reference genes based on transcript classifications\n",
      "gene_loss_summary: no isoforms data provided: treating reference transcripts as individual genes\n",
      "gene_loss_summary: writing summary to /mnt/f/temp_folder/toga_out/loss_summ_data.tsv\n",
      "Elapsed: 0:00:00.092887\n",
      "\n",
      "\n",
      "#### STEP 10: Create orthology relationships table\n",
      "\n",
      "make_query_isoforms: inferring genes from annotated isoforms in the query\n",
      "make_query_isoforms: called with the following arguments:\n",
      "* query_bed: /mnt/f/temp_folder/toga_out/query_annotation.bed\n",
      "* query_isoforms: /mnt/f/temp_folder/toga_out/query_isoforms.tsv\n",
      "* save_genes_track: /mnt/f/temp_folder/toga_out/query_gene_spans.bed\n",
      "* ignore_color: False\n",
      "* gene_prefix: TOGA\n",
      "make_query_isoforms: reading query annotation file /mnt/f/temp_folder/toga_out/query_annotation.bed...\n",
      "make_query_isoforms: got 0 unique transcripts annotated in query\n",
      "make_query_isoforms: got data for 0 exons in these trancscripts\n",
      "make_query_isoforms: splitting 0 into buckets based on their chromosome/scaffold and strand\n",
      "make_query_isoforms: got 0 unique chromosome/scaffold combinations\n",
      "make_query_isoforms: Building a graph where nodes are query exons, and edges indicate the fact that their coordinates intersect. Needed to identify which annotated transcripts intersect.\n",
      "make_query_isoforms: identified 0 connected components in the graph\n",
      "make_query_isoforms: parsing components data to identify query genes\n",
      "make_query_isoforms: saving query isoforms data to /mnt/f/temp_folder/toga_out/query_isoforms.tsv\n",
      "make_query_isoforms: saving coordinates of inferred genes to /mnt/f/temp_folder/toga_out/query_gene_spans.bed\n",
      "Calling orthology types mapping step...\n",
      "orthology_mapping: called with the following parameters:\n",
      "* ref_bed: /mnt/f/temp_folder/toga_out/temp/toga_filt_ref_annot.bed\n",
      "* que_bed: /mnt/f/temp_folder/toga_out/query_annotation.bed\n",
      "* out: /mnt/f/temp_folder/toga_out/orthology_classification.tsv\n",
      "* ref_iso: None\n",
      "* que_iso: /mnt/f/temp_folder/toga_out/query_isoforms.tsv\n",
      "* paralogs_arg: /mnt/f/temp_folder/toga_out/temp/paralogs.txt\n",
      "* loss_data: /mnt/f/temp_folder/toga_out/loss_summ_data.tsv\n",
      "* save_skipped: /mnt/f/temp_folder/toga_out/ref_orphan_transcripts.txt\n",
      "* orth_scores_arg: /mnt/f/temp_folder/toga_out/orthology_scores.tsv\n",
      "orthology_mapping: extracted 0 paralogous projections IDs from /mnt/f/temp_folder/toga_out/temp/paralogs.txt\n",
      "orthology_mapping: extracted orthology scores for 1 projections\n",
      "orthology_mapping: got data for 1 reference transcripts\n",
      "orthology_mapping: got data for 1 transcripts annotated in query\n",
      "orthology_mapping: got gene loss classifications for 1 projections in query\n",
      "orthology_mapping: filtered out query transcripts that have loss class not in {'PI', 'I', 'UL'}; resulted in 0 query transcripts to consider\n",
      "orthology_mapping: processed reference transcripts, got data for 1 genes and 1 transcripts\n",
      "orthology_mapping: processed query transcripts, got data for 0 genes and 0 transcripts\n",
      "orthology_mapping: mapped 0 reference transcripts to respective 0 query transcripts\n",
      "orthology_mapping: creating a mapping between reference and query genes...\n",
      "orthology_mapping: added 0 query genes to the orthology graph\n",
      "orthology_mapping: orthology graph contains 1 connected components\n",
      "* assigned class one2zero to node containing reference genes: ['#R#Period'] and query genes: []\n",
      "orthology_mapping: Extracted 1 orthology components in total\n",
      "orthology_mapping: Orthology class sizes:\n",
      "* one2zero: 1\n",
      "orthology_mapping: saving the results to /mnt/f/temp_folder/toga_out/orthology_classification.tsv\n",
      "\n",
      "\n",
      "#### STEP 11: Cleanup: merge parallel steps output files\n",
      "TOGA pipeline is done in 0:02:00.622084\n",
      "# Make Lastz Chains #\n",
      "Version 2.0.8\n",
      "Commit: 187e313afc10382fe44c96e47f27c4466d63e114\n",
      "Branch: main\n",
      "\n",
      "* found run_lastz.py at /mnt/f/make_lastz_chains/standalone_scripts/run_lastz.py\n",
      "* found run_lastz_intermediate_layer.py at /mnt/f/make_lastz_chains/standalone_scripts/run_lastz_intermediate_layer.py\n",
      "* found chain_gap_filler.py at /mnt/f/make_lastz_chains/standalone_scripts/chain_gap_filler.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* found faToTwoBit at /mnt/f/make_lastz_chains/HL_kent_binaries/faToTwoBit\n",
      "* found twoBitToFa at /mnt/f/make_lastz_chains/HL_kent_binaries/twoBitToFa\n",
      "* found pslSortAcc at /mnt/f/make_lastz_chains/HL_kent_binaries/pslSortAcc\n",
      "* found axtChain at /mnt/f/make_lastz_chains/HL_kent_binaries/axtChain\n",
      "* found axtToPsl at /mnt/f/make_lastz_chains/HL_kent_binaries/axtToPsl\n",
      "* found chainAntiRepeat at /mnt/f/make_lastz_chains/HL_kent_binaries/chainAntiRepeat\n",
      "* found chainMergeSort at /mnt/f/make_lastz_chains/HL_kent_binaries/chainMergeSort\n",
      "* found chainCleaner at /mnt/f/make_lastz_chains/HL_kent_binaries/chainCleaner\n",
      "* found chainSort at /mnt/f/make_lastz_chains/HL_kent_binaries/chainSort\n",
      "* found chainScore at /mnt/f/make_lastz_chains/HL_kent_binaries/chainScore\n",
      "* found chainNet at /mnt/f/make_lastz_chains/HL_kent_binaries/chainNet\n",
      "* found chainFilter at /mnt/f/make_lastz_chains/HL_kent_binaries/chainFilter\n",
      "* found lastz at /home/saurav/miniconda3/envs/ncbi_datasets/bin/lastz\n",
      "* found nextflow at /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow\n",
      "All necessary executables found.\n",
      "Making chains for /mnt/f/temp_folder/query_genome.fa and /mnt/f/temp_folder/target_genome.fa files, saving results to /mnt/f/temp_folder/out\n",
      "Pipeline started at 2024-04-08 15:23:04.385410\n",
      "* Setting up genome sequences for target\n",
      "genomeID: target\n",
      "input sequence file: /mnt/f/temp_folder/query_genome.fa\n",
      "is 2bit: False\n",
      "planned genome dir location: /mnt/f/temp_folder/out/target.2bit\n",
      "Initial fasta file /mnt/f/temp_folder/query_genome.fa saved to /mnt/f/temp_folder/out/target.2bit\n",
      "For target (target) sequence file: /mnt/f/temp_folder/out/target.2bit; chrom sizes saved to: /mnt/f/temp_folder/out/target.chrom.sizes\n",
      "* Setting up genome sequences for query\n",
      "genomeID: query\n",
      "input sequence file: /mnt/f/temp_folder/target_genome.fa\n",
      "is 2bit: False\n",
      "planned genome dir location: /mnt/f/temp_folder/out/query.2bit\n",
      "Initial fasta file /mnt/f/temp_folder/target_genome.fa saved to /mnt/f/temp_folder/out/query.2bit\n",
      "For query (query) sequence file: /mnt/f/temp_folder/out/query.2bit; chrom sizes saved to: /mnt/f/temp_folder/out/query.chrom.sizes\n",
      "\n",
      "### Partition Step ###\n",
      "\n",
      "# Partitioning for target\n",
      "Saving partitions and creating 1 buckets for lastz output\n",
      "In particular, 0 partitions for bigger chromosomes\n",
      "And 1 buckets for smaller scaffolds\n",
      "Saving target partitions to: /mnt/f/temp_folder/out/target_partitions.txt\n",
      "# Partitioning for query\n",
      "Saving partitions and creating 1 buckets for lastz output\n",
      "In particular, 0 partitions for bigger chromosomes\n",
      "And 1 buckets for smaller scaffolds\n",
      "Saving query partitions to: /mnt/f/temp_folder/out/query_partitions.txt\n",
      "Num. target partitions: 0\n",
      "Num. query partitions: 0\n",
      "Num. lastz jobs: 0\n",
      "\n",
      "### Lastz Alignment Step ###\n",
      "\n",
      "LASTZ: making jobs\n",
      "LASTZ: saved 1 jobs to /mnt/f/temp_folder/out/temp_lastz_run/lastz_joblist.txt\n",
      "Parallel manager: pushing job /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow /mnt/f/make_lastz_chains/parallelization/execute_joblist.nf --joblist /mnt/f/temp_folder/out/temp_lastz_run/lastz_joblist.txt -c /mnt/f/temp_folder/out/temp_lastz_run/lastz_config.nf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 23.10.1\n",
      "Launching `/mnt/f/make_lastz_chains/parallelization/execute_joblist.nf` [agitated_babbage] DSL2 - revision: 0483b29723\n",
      "[-        ] process > execute_jobs -\n",
      "\n",
      "executor >  local (1)\n",
      "[92/42dbe5] process > execute_jobs (1) [  0%] 0 of 1\n",
      "\n",
      "executor >  local (1)\n",
      "[92/42dbe5] process > execute_jobs (1) [  0%] 0 of 1\n",
      "\n",
      "executor >  local (1)\n",
      "[92/42dbe5] process > execute_jobs (1) [100%] 1 of 1 ✔\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "### Nextflow process lastz finished successfully\n",
      "Found 1 output files from the LASTZ step\n",
      "Please note that lastz_step.py does not produce output in case LASTZ could not find any alignment\n",
      "\n",
      "### Concatenating Lastz Results (Cat) Step ###\n",
      "\n",
      "Concatenating LASTZ output from 1 buckets\n",
      "* concatenated bucket bucket_ref_bulk_1 to /mnt/f/temp_folder/out/temp_concat_lastz_output/concat_0.psl.gz\n",
      "Concatenated 1 files in total into 1 files\n",
      "\n",
      "### Build Chains Step ###\n",
      "\n",
      "Sorting PSL files, saving the results to /mnt/f/temp_folder/out/temp_chain_run/sorted_psl\n",
      "/mnt/f/make_lastz_chains/HL_kent_binaries/pslSortAcc nohead /mnt/f/temp_folder/out/temp_chain_run/sorted_psl /mnt/f/temp_folder/out/temp_kent /mnt/f/temp_folder/out/temp_concat_lastz_output/concat_0.psl.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /mnt/f/temp_folder/out/temp_concat_lastz_output/concat_0.psl.gz\n",
      "Processed 109 lines into 1 temp files\n",
      "writing /mnt/f/temp_folder/out/temp_chain_run/sorted_psl\n",
      "Cleaning up temp files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bundling psl files with the following arguments:\n",
      "* input_dir: /mnt/f/temp_folder/out/temp_chain_run/sorted_psl\n",
      "* chrom_sizes: /mnt/f/temp_folder/out/target.chrom.sizes\n",
      "* output_dir: /mnt/f/temp_folder/out/temp_chain_run/split_psl\n",
      "* max_bases: 1000000\n",
      "* warning_only: False\n",
      "* verbose: False\n",
      "Saving results to: /mnt/f/temp_folder/out/temp_chain_run/split_psl\n",
      "Bundling 1 psl files in total\n",
      "Written to /mnt/f/temp_folder/out/temp_chain_run/split_psl/bundle.0.psl\n",
      "DONE. Produced 1 files\n",
      "PSL bundle sub-step done\n",
      "Building axtChain joblist for 1 bundled psl files\n",
      "Saving 1 axtChain jobs to /mnt/f/temp_folder/out/temp_chain_run/chains_joblist\n",
      "Parallel manager: pushing job /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow /mnt/f/make_lastz_chains/parallelization/execute_joblist.nf --joblist /mnt/f/temp_folder/out/temp_chain_run/chains_joblist -c /mnt/f/temp_folder/out/temp_chain_run/chain_run_config.nf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 23.10.1\n",
      "Launching `/mnt/f/make_lastz_chains/parallelization/execute_joblist.nf` [thirsty_picasso] DSL2 - revision: 0483b29723\n",
      "[-        ] process > execute_jobs -\n",
      "\n",
      "executor >  local (1)\n",
      "[1c/7a6d71] process > execute_jobs (1) [  0%] 0 of 1\n",
      "\n",
      "executor >  local (1)\n",
      "[1c/7a6d71] process > execute_jobs (1) [100%] 1 of 1 ✔\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "### Nextflow process chain_run finished successfully\n",
      "Chain run output files saved to /mnt/f/temp_folder/out/temp_chain_run/chain\n",
      "\n",
      "### Merge Chains Step ###\n",
      "\n",
      "Executing the following sequence of piped commands:\n",
      "['find', '/mnt/f/temp_folder/out/temp_chain_run/chain', '-name', '*chain']\n",
      "['/mnt/f/make_lastz_chains/HL_kent_binaries/chainMergeSort', '-inputList=stdin', '-tempDir=/mnt/f/temp_folder/out/temp_kent']\n",
      "['gzip', '-c']\n",
      "\n",
      "Saved merged results to: /mnt/f/temp_folder/out/temp_chain_run/target.query.all.chain.gz\n",
      "\n",
      "### Fill Chains Step ###\n",
      "\n",
      "Preparing fill jobs\n",
      "gunzip -c /mnt/f/temp_folder/out/temp_chain_run/target.query.all.chain.gz > /mnt/f/temp_folder/out/temp_fill_chain/temp.all.chain\n",
      "Found 7 chain IDs\n",
      "Wrote output to 7 files starting with '/mnt/f/temp_folder/out/temp_fill_chain/fill_chain_chunks/infill_chain_'.\n",
      "Creating repeat filler jobs list\n",
      "fGot 7 chain files to fill\n",
      "Adding --unmask flag\n",
      "Saved 7 chain fill jobs to /mnt/f/temp_folder/out/temp_fill_chain/repeat_filler_joblist.txt\n",
      "Parallel manager: pushing job /home/saurav/miniconda3/envs/ncbi_datasets/bin/nextflow /mnt/f/make_lastz_chains/parallelization/execute_joblist.nf --joblist /mnt/f/temp_folder/out/temp_fill_chain/repeat_filler_joblist.txt -c /mnt/f/temp_folder/out/temp_fill_chain/fill_chain_config.nf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N E X T F L O W  ~  version 23.10.1\n",
      "Launching `/mnt/f/make_lastz_chains/parallelization/execute_joblist.nf` [big_brown] DSL2 - revision: 0483b29723\n",
      "[-        ] process > execute_jobs -\n",
      "\n",
      "executor >  local (1)\n",
      "[84/af4565] process > execute_jobs (4) [  0%] 0 of 7\n",
      "\n",
      "executor >  local (2)\n",
      "[84/af4565] process > execute_jobs (4) [ 14%] 1 of 7\n",
      "\n",
      "executor >  local (2)\n",
      "[e1/e3bc66] process > execute_jobs (3) [ 28%] 2 of 7\n",
      "\n",
      "executor >  local (3)\n",
      "[ca/0ca802] process > execute_jobs (2) [ 28%] 2 of 7\n",
      "\n",
      "executor >  local (4)\n",
      "[5a/1fe828] process > execute_jobs (1) [ 42%] 3 of 7\n",
      "\n",
      "executor >  local (5)\n",
      "[91/e9e65e] process > execute_jobs (6) [ 57%] 4 of 7\n",
      "\n",
      "executor >  local (6)\n",
      "[03/fbabfd] process > execute_jobs (5) [ 71%] 5 of 7\n",
      "\n",
      "executor >  local (7)\n",
      "[bd/7d59b6] process > execute_jobs (7) [ 85%] 6 of 7\n",
      "\n",
      "executor >  local (7)\n",
      "[bd/7d59b6] process > execute_jobs (7) [100%] 7 of 7 ✔\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "### Nextflow process fill_chain finished successfully\n",
      "Merging filled chains\n",
      "Executing the following sequence of commands in a pipe:\n",
      "['find', '/mnt/f/temp_folder/out/temp_fill_chain/filled_chain_files', '-type', 'f', '-name', '*.chain', '-print']\n",
      "['/mnt/f/make_lastz_chains/HL_kent_binaries/chainMergeSort', '-inputList=stdin', '-tempDir=/mnt/f/temp_folder/out/temp_kent']\n",
      "['gzip', '-c']\n",
      "\n",
      "Merging filled chains done\n",
      "Fill chains step complete\n",
      "\n",
      "### Clean Chains Step ###\n",
      "\n",
      "Chains were filled: using /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain.gz as input\n",
      "Chain to be cleaned saved to: /mnt/f/temp_folder/out/temp_chain_run/target.query.before_cleaning.chain.gz\n",
      "Executing the following chain cleaner command:\n",
      "/mnt/f/make_lastz_chains/HL_kent_binaries/chainCleaner /mnt/f/temp_folder/out/temp_chain_run/target.query.before_cleaning.chain.gz /mnt/f/temp_folder/out/target.2bit /mnt/f/temp_folder/out/query.2bit /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain__temp /mnt/f/temp_folder/out/temp_chain_run/removed_suspects.bed -linearGap=loose -tSizes=/mnt/f/temp_folder/out/target.chrom.sizes -qSizes=/mnt/f/temp_folder/out/query.chrom.sizes -LRfoldThreshold=2.5 -doPairs -LRfoldThresholdPairs=10 -maxPairDistance=10000 -maxSuspectScore=100000 -minBrokenChainScore=75000\n",
      "Not filtered by score chains temporary saved to /mnt/f/temp_folder/out/temp_chain_run/target.query.filled.chain__temp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from Bio import SeqIO\n",
    "\n",
    "location_of_raw_files = \"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/\"\n",
    "\n",
    "list_of_queries_species = os.listdir(f\"{location_of_raw_files}/4.Pierinae/2.TOGA/1.Query_genomes\")\n",
    "if \"desktop.ini\" in list_of_queries_species:\n",
    "    list_of_queries_species.remove(\"desktop.ini\")\n",
    "list_of_target_species = os.listdir(f\"{location_of_raw_files}/4.Pierinae/2.TOGA/2.Target_genomes\")\n",
    "if \"desktop.ini\" in list_of_target_species:\n",
    "    list_of_target_species.remove(\"desktop.ini\")\n",
    "    \n",
    "for query_species in list_of_queries_species:\n",
    "    for target_species in list_of_target_species:\n",
    "\n",
    "        list_of_folders_in_f  = os.listdir(\"/mnt/f\")\n",
    "        # print(list_of_folders_in_f)\n",
    "        if \"temp_folder\" in list_of_folders_in_f:\n",
    "            subprocess.run(\"rm -r /mnt/f/temp_folder/\", shell = True)\n",
    "            os.mkdir(\"/mnt/f/temp_folder\")\n",
    "\n",
    "        # #copy target genome\n",
    "        subprocess.run(f\"cp '{location_of_raw_files}/4.Pierinae/2.TOGA/1.Query_genomes/{query_species}/query_genome.fa' '/mnt/f/temp_folder'\", shell = True)\n",
    "        subprocess.run(f\"cp '{location_of_raw_files}/4.Pierinae/2.TOGA/2.Target_genomes/{target_species}/target_genome.fa' '/mnt/f/temp_folder'\", shell = True)\n",
    "\n",
    "        Process_genome_name(\"/mnt/f/temp_folder/query_genome.fa\")\n",
    "        Process_genome_name(\"/mnt/f/temp_folder/target_genome.fa\")\n",
    "\n",
    "\n",
    "        subprocess.run(\"python3.11 /mnt/f/make_lastz_chains/make_chains.py target query /mnt/f/temp_folder/query_genome.fa /mnt/f/temp_folder/target_genome.fa --pd /mnt/f/temp_folder/out -f\", shell = True)\n",
    "\n",
    "        subprocess.run(\"gzip -d /mnt/f/temp_folder/out/target.query.final.chain.gz\", shell = True)\n",
    "\n",
    "        # # subprocess.run(f\"cp /mnt/f/temp_folder/out/target.query.final.chain '{location_of_raw_files}/4.Pierinae/2.TOGA/2.Target_genomes/Anthocharis_cardamines/'\", shell = True)\n",
    "\n",
    "        subprocess.run(f'/mnt/f/make_lastz_chains/HL_kent_binaries/faToTwoBit /mnt/f/temp_folder/query_genome.fa  /mnt/f/temp_folder/query_genome.2bit', shell = True)\n",
    "        subprocess.run(f'/mnt/f/make_lastz_chains/HL_kent_binaries/faToTwoBit /mnt/f/temp_folder/target_genome.fa  /mnt/f/temp_folder/target_genome.2bit', shell = True)\n",
    "\n",
    "\n",
    "        subprocess.run(f'cp \"{location_of_raw_files}/4.Pierinae/2.TOGA/1.Query_genomes/{query_species}/gff_fragment.bed\"  \"/mnt/f/temp_folder\"', shell = True)\n",
    "\n",
    "        subprocess.run(f\"cd /mnt/f/temp_folder/ \\n python3.11 /mnt/f/TOGA/toga.py /mnt/f/temp_folder/out/target.query.final.chain /mnt/f/temp_folder/gff_fragment.bed /mnt/f/temp_folder/query_genome.2bit  /mnt/f/temp_folder/target_genome.2bit --pn /mnt/f/temp_folder/toga_out --ms\", shell = True)\n",
    "\n",
    "        subprocess.run(f'cp \"/mnt/f/temp_folder/toga_out/query_annotation.bed\" \"{location_of_raw_files}/4.Pierinae/2.TOGA/2.Target_genomes/{target_species}/{query_species}_query_annotation.bed\"', shell = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419df6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80675c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
