{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d321c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder_error_exon(output_location,species, error_exon):\n",
    "    import subprocess\n",
    "    list_of_folders = os.listdir(f\"{output_location}/1.Blast_result/{species}\")\n",
    "    if \"Error_exon_processing\" not in list_of_folders:\n",
    "        os.mkdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing\")\n",
    "        \n",
    "    list_of_folder_2 = os.listdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing\")\n",
    "    if error_exon in list_of_folder_2:\n",
    "        subprocess.run(f'rm -r \"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "    os.mkdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\")\n",
    "    \n",
    "    list_of_folders_3 = os.listdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\")\n",
    "    if \"Temp_query\" not in list_of_folders_3:\n",
    "        os.mkdir(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}/Temp_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8456dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_query(output_location,error_exon,species):\n",
    "    from Bio import SeqIO\n",
    "    import random\n",
    "    exon = error_exon.split(\"Error\")[1][1:]\n",
    "\n",
    "    list_of_species = os.listdir(f\"{output_location}/2.Final_output\")\n",
    "    try:\n",
    "        list_of_species.remove(\"desktop.ini\")\n",
    "    except:\n",
    "        pass\n",
    "    if len(list_of_species) > 6:\n",
    "        list_of_species = random.sample(list_of_species, 5)\n",
    "    add_species = input(\"Preferred Species?\")\n",
    "    if add_species.lower() != \"n\":\n",
    "        if add_species not in list_of_species:\n",
    "            list_of_species.append(add_species)\n",
    "        \n",
    "    for query_species in list_of_species:\n",
    "        list_of_exons = os.listdir(f\"{output_location}/2.Final_output/{query_species}\")\n",
    "        try:\n",
    "            list_of_exons.remove(\"desktop.ini\")\n",
    "        except:\n",
    "            pass\n",
    "#         print(query_species,list_of_exons)\n",
    "        if f\"{exon}.fa\" in list_of_exons:\n",
    "            print (f\"{exon}.fa\")\n",
    "            exon_file = SeqIO.parse(f\"{output_location}/2.Final_output/{query_species}/{exon}.fa\", 'fasta')\n",
    "            for records in exon_file:\n",
    "                print(records.id)\n",
    "                print(records.seq[int(records.id.split(\"_\")[-3]):].translate())\n",
    "                left_oh = records.id.split(\"_\")[-3]\n",
    "                right_oh = records.id.split(\"_\")[-1]\n",
    "    #             print(left_oh)\n",
    "                query_sequence = records.seq[int(records.id.split(\"_\")[-3]):].translate()\n",
    "            with open(f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}/Temp_query/{query_species}_{exon}.fa\", \"w\") as out_file:\n",
    "                output = f\">{records.id}\\n{query_sequence}\"\n",
    "                out_file.write(output)\n",
    "    return(left_oh,right_oh)\n",
    "# left_oh,right_oh = make_query(output_location,error_exon,species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7aff1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genomic_coordinates(output_location,error_exon,species):\n",
    "    error_exon_number = error_exon.split(\"_\")[-1]\n",
    "#     print(error_exon_number)\n",
    "#     return\n",
    "    with open(f\"{output_location}/1.Blast_result/{species}/final_coordinates.csv\", 'r') as final_coordinate_file:\n",
    "        final_coordinate_file_lines = final_coordinate_file.readlines()\n",
    "    for i in range(1, len(final_coordinate_file_lines)):\n",
    "#         print(final_coordinate_file_lines[i])\n",
    "        current_position = i\n",
    "        next_position = i\n",
    "#         print(final_coordinate_file_lines[i].split(\",\")[6].split(\"Exon\")[1][1:].strip())\n",
    "#         print(error_exon_number)\n",
    "        scaffold = final_coordinate_file_lines[current_position-1].split(\",\")[1]\n",
    "\n",
    "        original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position-1].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "        \n",
    "        \n",
    "        if final_coordinate_file_lines[i].split(\",\")[6].split(\"Exon\")[1][1:].strip() == error_exon_number:\n",
    "#             print(current_position, next_position)\n",
    "    \n",
    "            if error_exon_number == \"1\":\n",
    "                current_position = current_position\n",
    "                while final_coordinate_file_lines[next_position+1].split(\",\")[5] == \"Y\":\n",
    "                        next_position += 1\n",
    "                complement = final_coordinate_file_lines[current_position].split(\",\")[4]\n",
    "                \n",
    "                if complement == \"0\":\n",
    "                    fragment_start = int(final_coordinate_file_lines[current_position].split(\",\")[3])-1000\n",
    "                    fragment_end = final_coordinate_file_lines[next_position+1].split(\",\")[2]\n",
    "                if complement == \"1\":\n",
    "                    fragment_start = final_coordinate_file_lines[next_position+1].split(\",\")[3]\n",
    "                    fragment_end = int(final_coordinate_file_lines[current_position].split(\",\")[2]) + 1000\n",
    "\n",
    "                scaffold = final_coordinate_file_lines[current_position].split(\",\")[1]\n",
    "                \n",
    "                \n",
    "                \n",
    "            elif error_exon_number == \"24\":\n",
    "                next_position = next_position\n",
    "                while final_coordinate_file_lines[current_position-1].split(\",\")[5] == \"Y\":\n",
    "                    current_position = current_position-1\n",
    "                complement = final_coordinate_file_lines[current_position].split(\",\")[4]\n",
    "                \n",
    "                if complement == \"0\":\n",
    "                    fragment_start = int(final_coordinate_file_lines[current_position-1].split(\",\")[3])\n",
    "                    fragment_end = int(final_coordinate_file_lines[next_position].split(\",\")[2])+1000\n",
    "                if complement == \"1\":\n",
    "                    fragment_start = int(final_coordinate_file_lines[next_position].split(\",\")[3])-1000\n",
    "                    fragment_end = final_coordinate_file_lines[current_position-1].split(\",\")[2] \n",
    "                \n",
    "                scaffold = final_coordinate_file_lines[current_position].split(\",\")[1]\n",
    "                original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "                \n",
    "            else: \n",
    "                while final_coordinate_file_lines[current_position-1].split(\",\")[5] == \"Y\":\n",
    "                    current_position = current_position-1\n",
    "                while final_coordinate_file_lines[next_position+1].split(\",\")[5] == \"Y\":\n",
    "                    next_position += 1\n",
    "\n",
    "                complement = final_coordinate_file_lines[current_position-1].split(\",\")[4]\n",
    "                original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position-1].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "\n",
    "                if complement == \"0\":\n",
    "                    fragment_start = final_coordinate_file_lines[current_position-1].split(\",\")[3]\n",
    "                    fragment_end = final_coordinate_file_lines[next_position+1].split(\",\")[2]\n",
    "                if complement == \"1\":\n",
    "                    fragment_start = final_coordinate_file_lines[next_position+1].split(\",\")[3]\n",
    "                    fragment_end = final_coordinate_file_lines[current_position-1].split(\",\")[2]\n",
    "            \n",
    "                scaffold = final_coordinate_file_lines[current_position-1].split(\",\")[1]\n",
    "\n",
    "                original_query_name =f\"{'_'.join(final_coordinate_file_lines[current_position-1].split(',')[6].split('_')[:-1])}_{current_position}\"\n",
    "                \n",
    "    #             query_name =f\"{''.join(final_coordinate_file_lines[current_position-1].split(''))}\"\n",
    "    #             print(query_name)                       \n",
    "                                   \n",
    "            return(fragment_start, fragment_end, scaffold,complement,original_query_name)\n",
    "# print(get_genomic_coordinates(output_location,error_exon,species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09eaa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genome_file(genome_location,species):\n",
    "    list_of_files_in_genome_folder = os.listdir(f\"{genome_location}/{species}\")\n",
    "    for file in list_of_files_in_genome_folder:\n",
    "        if file.endswith(\"_genomic.fna\"):\n",
    "            genome_file = file\n",
    "    return(genome_file) \n",
    "\n",
    "def get_gene_sequence(genome_location, \n",
    "                      species,                       \n",
    "                      scaffold,\n",
    "                      gene_start,\n",
    "                      gene_end,\n",
    "                      complement,\n",
    "                      output_location):\n",
    "\n",
    "    \n",
    "    print(\"Getting Gene\")\n",
    "    \n",
    "    genome_file = get_genome_file(genome_location,species)\n",
    "    print(genome_file)\n",
    "    list_of_folders = os.listdir(output_location)\n",
    "    print(list_of_folders)\n",
    "    if f\"0.Temp\" not in list_of_folders:\n",
    "        os.mkdir(f\"{output_location}/0.Temp\")\n",
    "\n",
    "#     subprocess.run(f'samtools faidx \"{genome_location}/{species}/{genome_file}\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "#     print(f'samtools faidx \"{genome_location}/{species}/{genome_file}\" {scaffold}:{gene_start}-{gene_end}')\n",
    "    subprocess.run(f'samtools faidx \"{genome_location}/{species}/{genome_file}\" {scaffold}:{gene_start}-{gene_end} > \"{output_location}/0.Temp/temp_genome.fa\"', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "    genome = SeqIO.parse(f\"{output_location}/0.Temp/temp_genome.fa\", \"fasta\")\n",
    "    for entries in genome:\n",
    "        gene_sequence = entries.seq\n",
    "        if complement == \"1\":\n",
    "            gene_sequence = gene_sequence.reverse_complement()\n",
    "        break\n",
    "    # print(gene_sequence)\n",
    "    return (gene_sequence)\n",
    "# get_gene_sequence(genome_location, \n",
    "#                           species,                       \n",
    "#                           scaffold,\n",
    "#                           fragment_start,\n",
    "#                           fragment_end,\n",
    "#                           complement,\n",
    "#                           output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f36f8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_files_for_alignment(gene_sequence,output_location,species,error_exon):\n",
    "    \n",
    "    \n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    list_of_folders = os.listdir(error_exon_location)\n",
    "    if \"for_alignment\" not in list_of_folders:\n",
    "        \n",
    "        os.mkdir(f\"{error_exon_location}/for_alignment\")\n",
    "    \n",
    "    list_of_files = os.listdir(f\"{error_exon_location}/for_alignment\")\n",
    "    for file in list_of_files:\n",
    "        os.remove(f\"{error_exon_location}/for_alignment/{file}\")\n",
    "\n",
    "    \n",
    "    query_location = f\"{error_exon_location}/Temp_query/\"\n",
    "    list_of_queries = os.listdir(query_location)\n",
    "    print(list_of_queries)\n",
    "#     return\n",
    "    query_fasta_sequence = ''\n",
    "    query_length = 0\n",
    "    \n",
    "    for query in list_of_queries:\n",
    "        \n",
    "        query_fasta_file = SeqIO.parse(f\"{query_location}/{query}\", 'fasta')\n",
    "        for records in query_fasta_file:\n",
    "            \n",
    "            query_fasta_sequence = f\">{records.id}\\n{records.seq}\\n\\n\"\n",
    "            query_length_new = len(records.seq)\n",
    "            if query_length == 0:\n",
    "                query_length = len(records.seq)\n",
    "            if query_length_new < query_length:\n",
    "                query_length = query_length_new\n",
    "                \n",
    "            query_species = \"_\".join(records.id.split(\"_\")[:2])\n",
    "#             print(query_species)\n",
    "#             return\n",
    "            print(error_exon)\n",
    "        #     return\n",
    "\n",
    "        #     query_length = query_length/3\n",
    "            for offset in range(3):\n",
    "                translated_sequence = str(gene_sequence[offset:].translate()).split(\"*\")\n",
    "                for i in range(len(translated_sequence)):\n",
    "\n",
    "                    if len(translated_sequence[i])> 0.8*query_length and  str(translated_sequence[i]).count(\"X\") < 5:\n",
    "                        sequence_set = f\">set{i+1}_frame{offset}_{query_species}\\n{translated_sequence[i]}\\n\\n\"\n",
    "        #                 print(i+1, offset)\n",
    "\n",
    "                        with open(f\"{error_exon_location}/for_alignment/{error_exon}_query_{query_species}_translated_genomic_sequence_{i+1}_frame{offset}.fa\",'w') as out_file:\n",
    "                            output = f\"{query_fasta_sequence}\\n\\n{sequence_set}\"\n",
    "                            out_file.write(output)\n",
    "\n",
    "# make_raw_files_for_alignment(gene_sequence,output_location,species,error_exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "730727e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mafft(output_location,species,error_exon):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    location = f'{error_exon_location}/for_alignment/'\n",
    "    list_of_files_to_run_mafft_on = os.listdir(location)\n",
    "    for file in list_of_files_to_run_mafft_on:\n",
    "        if file.endswith(\".fa\"):\n",
    "            command = f'\"mafft\" --localpair --maxiterate 16 --reorder --distout \"{location}/{file}\" > \"{location}/alignment_{file}.txt\"'\n",
    "            # print(command)\n",
    "            subprocess.run(f'{command}', shell=True, stderr = subprocess.DEVNULL) \n",
    "            # os.system(f'{command}')\n",
    "            command = f'\"mafft\" --localpair --clustalout --maxiterate 16 --reorder \"{location}/{file}\" > \"{location}/alignment_clustal_{file}.txt\"'\n",
    "            subprocess.run(f'{command}', shell=True, stderr = subprocess.DEVNULL) \n",
    "            \n",
    "            # os.system(f'{command}')\n",
    "    return(location)\n",
    "# run_mafft(output_location,species,error_exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78e0d08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_mafft_output(mafft_run_location, error_exon):\n",
    "    error_exon = error_exon.split(\"Error\")[1][1:]\n",
    "    list_of_files_in_mafft_run_folder = os.listdir(mafft_run_location)\n",
    "    score_output = []\n",
    "    score = 99\n",
    "    min_score_sequence = ''\n",
    "    alignment_file = ''\n",
    "    for file in list_of_files_in_mafft_run_folder:\n",
    "        if file.endswith(\".fa.hat2\"):\n",
    "            with open(f\"{mafft_run_location}/{file}\", 'r') as dist_matrix_file:\n",
    "                dist_matrix_list = dist_matrix_file.readlines()\n",
    "            \n",
    "            sequence_name = f'set{file.split(\"_\")[-2]}_{file.split(\"_\")[-1].split(\".\")[0]}'\n",
    "            query_species_name =f'{file.split(\"_\")[4]}_{file.split(\"_\")[5]}'\n",
    "            distance_score = float(dist_matrix_list[2].strip())\n",
    "            if len(score_output) < 10:\n",
    "                alignment_file_now = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "                score_output.append( [sequence_name,distance_score,alignment_file_now])\n",
    "            else:\n",
    "                for i in range(len(score_output)):\n",
    "                    score_at_this_index = score_output[i][1]\n",
    "                    if distance_score < score_at_this_index:\n",
    "                        alignment_file_now = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "                        score_output[i] = [sequence_name,distance_score,alignment_file_now]\n",
    "                        break\n",
    "            if distance_score < score:\n",
    "                score = distance_score\n",
    "                min_score_sequence = sequence_name\n",
    "                alignment_file = f'alignment_{file.replace(\".hat2\",\".txt\")}'\n",
    "#     print(score_output)\n",
    "    print(f\"min = {min_score_sequence}, {score}\" )\n",
    "    \n",
    "    # score_out_merged = '\\n'.join(score_output)\n",
    "    print(f\"5 top scores:\\n{score_output}\")\n",
    "    \n",
    "    for i in range(len(score_output)):\n",
    "        temp_align_file = score_output[i][2]\n",
    "        clustal_alignment_file = temp_align_file.replace(\"alignment_\",\"alignment_clustal_\")\n",
    "        with open(f\"{mafft_run_location}{clustal_alignment_file}\", 'r') as clustal_file_open:\n",
    "            print(\"\".join(clustal_file_open.readlines()))\n",
    "    \n",
    "    print(f\"{mafft_run_location}/{alignment_file}\")\n",
    "#     return\n",
    "    \n",
    "    print(f\"Alignmnet file: {alignment_file}\")\n",
    "    clustal_alignment_file = alignment_file.replace(\"alignment_\",\"alignment_clustal_\")\n",
    "    print(clustal_alignment_file)\n",
    "    alignment_file = SeqIO.parse(f\"{mafft_run_location}/{alignment_file}\", 'fasta')\n",
    "    # print (records.id)\n",
    "    fasta_start_position = 0\n",
    "    fasta_end_position = 0\n",
    "    start_switch = 0\n",
    "    end_switch = 0\n",
    "    alignment_name = ''\n",
    "    for records in alignment_file:\n",
    "        \n",
    "        if start_switch == 0 and end_switch == 0:\n",
    "            print(error_exon)\n",
    "            if error_exon in records.id:\n",
    "                print(records.id)\n",
    "                gap_counter = 0\n",
    "                base_counter = 0\n",
    "                for current_position in range(len(records.seq)):\n",
    "                    sequence_length = len(records.seq) - records.seq.count('-')\n",
    "#                     print(f\"fasta_end_position {fasta_end_position} fasta_start_position {fasta_start_position}\")\n",
    "                    # print(f\"current_position = {current_position}, {len(records.seq)}\")\n",
    "                    # print(records.seq[current_position])\n",
    "                    # print(\"fasta_start_position\",fasta_start_position)\n",
    "#                     print(\"start_switch\",start_switch)\n",
    "\n",
    "                    # print(gap_counter, base_counter)\n",
    "                    # print(5,0.2*sequence_length)\n",
    "#                     print((len(records.seq[:current_position]) - records.seq[:current_position].count('-')), 0.1*sequence_length)\n",
    "                    if start_switch == 1 and records.seq[current_position] == \"-\" and gap_counter > 3 and (len(records.seq[:current_position]) - records.seq[:current_position].count('-')) < 0.1*sequence_length:\n",
    "                        # print(\"\\n\\nhere\\n\\n\")\n",
    "                        start_switch = 0\n",
    "                        gap_counter = 0\n",
    "                    \n",
    "                    if \"-\" not in records.seq[current_position] and start_switch == 0 :\n",
    "                        \n",
    "                        fasta_start_position = current_position\n",
    "                        start_switch = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    if end_switch == 1 and \"-\" not in records.seq[current_position] :\n",
    "                        end_switch = 0\n",
    "                        gap_counter = 0\n",
    "\n",
    "#                     print((len(records.seq[current_position:]) - records.seq[current_position:].count('-')), 0.1*sequence_length) \n",
    "#                     print((start_switch == 1),records.seq[current_position],(len(records.seq[current_position:]) - records.seq[current_position:].count('-')) < 0.1*sequence_length)\n",
    "                    if start_switch == 1 and records.seq[current_position] == \"-\" and end_switch == 0 and (len(records.seq[current_position:]) - records.seq[current_position:].count('-')) < 0.1*sequence_length:\n",
    "                        # print(f\"base_counter {base_counter}\")\n",
    "                        # print(f\"fasta_end_position {fasta_end_position}\")\n",
    "\n",
    "                        # print(f\"fasta_end_position {fasta_end_position}\")\n",
    "\n",
    "                        fasta_end_position = current_position\n",
    "                        end_switch = 1\n",
    "                    if \"-\" in records.seq[current_position]:\n",
    "                        gap_counter += 1\n",
    "                    else:\n",
    "                        gap_counter = 0\n",
    "                        base_counter += 1\n",
    "        else:\n",
    "            if end_switch == 0:\n",
    "                end_switch = 1\n",
    "                fasta_end_position = current_position\n",
    "            start_switch = 1\n",
    "    #         break\n",
    "        print(\"here here\", start_switch,end_switch,min_score_sequence,records.id,fasta_start_position, fasta_end_position )\n",
    "        if start_switch == 1 and end_switch == 1 and min_score_sequence in records.id :\n",
    "            alignment_name = records.id\n",
    "#             print(fasta_start_position, fasta_end_position)\n",
    "            gene_sequence = records.seq[fasta_start_position:fasta_end_position]\n",
    "            print(f\"{records.id}\\n{gene_sequence}\")\n",
    "#     print(\"_\".join(alignment_name.split(\"_\")[:2]).replace(\"set\", \"sequence\"))\n",
    "#     clustal_alignment_file = f'alignment_clustal_Error_{error_exon}_translated_genomic_{(\"_\".join(alignment_name.split(\"_\")[:2]).replace(\"set\", \"sequence_\"))}.fa.txt'\n",
    "    print(clustal_alignment_file)\n",
    "    with open(f\"{mafft_run_location}{clustal_alignment_file}\", 'r') as clustal_file_open:\n",
    "        return(gene_sequence, alignment_name,clustal_file_open.readlines() )\n",
    "\n",
    "# query_sequence, alignment_name, alignment_file = process_mafft_output(mafft_run_location, error_exon)\n",
    "# print(query_sequence, alignment_name)\n",
    "# print(\"\".join(alignment_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78ed650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_blast(gene_sequence,query_sequence,alignment_name,output_location,species, error_exon):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    list_of_folders = os.listdir(error_exon_location)\n",
    "    if \"Run_Blast\" not in list_of_folders:\n",
    "        os.mkdir(f\"{error_exon_location}/Run_Blast\")\n",
    "    \n",
    "    with open(f\"{error_exon_location}/Run_Blast/local_db.txt\",'w') as db_file:\n",
    "        output = f\">genome_fragment\\n{gene_sequence}\"\n",
    "        db_file.write(output)\n",
    "        \n",
    "    with open(f\"{error_exon_location}/Run_Blast/query.txt\",'w') as query_file:\n",
    "        output = f\">{alignment_name}\\n{query_sequence}\"\n",
    "        query_file.write(output)\n",
    "    \n",
    "    makeblast_command = f'cd \"{error_exon_location}/Run_Blast/\"\\nmakeblastdb -in local_db.txt -dbtype nucl'\n",
    "    subprocess.run(f'{makeblast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "    blast_command = f'cd \"{error_exon_location}/Run_Blast/\"\\ntblastn -seg no -query query.txt -db local_db.txt -num_alignments 3 -out blast_out_genome_fragment.htm -html\\ntblastn -seg no -query query.txt -db local_db.txt -num_alignments 3 -out blast_out_genome_fragment.txt'\n",
    "    subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "# run_blast(gene_sequence,query_sequence,alignment_name,output_location,species, error_exon)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae0d3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_genome_fragment_blast_file(output_location,\n",
    "#                                         annotated_genome_location, \n",
    "#                                        species_name,\n",
    "#                                        error_exon,\n",
    "#                                        left_oh,right_oh,\n",
    "                                                                                                                                      \n",
    "#                                        original_query_name,\n",
    "# #                                       query_species_original ):\n",
    "    \n",
    "def process_genome_fragment_blast_file(output_location,left_oh,right_oh,species,genome_location):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    blast_location = f\"{error_exon_location}/Run_Blast\"\n",
    "    \n",
    "    with open(f\"{blast_location}/query.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_oh),int(right_oh)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "#     species_name = annotated_species_name\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        print(query_name)\n",
    "#         return\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out_genome_fragment.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "        print(start_coor,stop_coor)\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "        genome_file = SeqIO.parse(f\"{blast_location}/local_db.txt\", 'fasta')\n",
    "        print(\"reached here\")\n",
    "        \n",
    "        for records in genome_file:\n",
    "            old_start = start\n",
    "            old_stop = stop\n",
    "            ag = \"N\"\n",
    "            gt = \"N\"\n",
    "            stop_counter = 0\n",
    "            while True:\n",
    "                print(f\"sequence:\\n{records.seq[start+start_modifier-1:stop]}\")\n",
    "                translated_sequence = records.seq[start+start_modifier-1:stop].translate()\n",
    "                print(f\"sequence:\\n{translated_sequence}\")\n",
    "                if \"*\" in translated_sequence:\n",
    "                    stop_counter +=1\n",
    "                    if ag == \"N\":\n",
    "                        start = old_start + 3*stop_counter\n",
    "                    if gt ==\"N\":\n",
    "                        stop = old_stop - 3*stop_counter\n",
    "                if stop_counter > 30:\n",
    "                    return (\"Error!! Too many stops\")\n",
    "                print(f\"left = {records.seq[start-3:start-1]}, right ={(records.seq[stop:stop + 2])}\"  ), \n",
    "                if (records.seq[start-3:start-1]).lower() == \"ag\" and ag != \"Y\":\n",
    "                    \n",
    "                    ag = \"Y\"\n",
    "                    \n",
    "                elif ag != \"Y\":\n",
    "                    start -= 3\n",
    "                    \n",
    "                if (records.seq[stop:stop + 2]).lower() == \"gt\" and gt != \"Y\":\n",
    "                    gt = \"Y\"\n",
    "                elif gt != \"Y\":\n",
    "                    stop +=3\n",
    "                if old_start - start > 1000 or stop - old_stop > 1000:\n",
    "                    break\n",
    "                if gt == \"Y\" and ag == \"Y\":\n",
    "                    gt_ag = \"Y\"\n",
    "                    break\n",
    "        \n",
    "        query_location = f\"{blast_location}/new_query_spliced.txt\"\n",
    "        with open(query_location , 'w') as query_file_new:\n",
    "\n",
    "            sequence_translated = records.seq[start+start_modifier-1:stop].translate()\n",
    "            print(sequence_translated)\n",
    "            # proceed_test = input(\"Proceed with this?\")\n",
    "            # while True:\n",
    "            #     if proceed_test.lower()[0] == \"n\":\n",
    "            #         assert False\n",
    "            #     elif proceed_test.lower()[0] == \"y\":\n",
    "            #         break\n",
    "            if \"*\" in sequence_translated:\n",
    "                print(\"Errror in Spliced query\")\n",
    "                assert False\n",
    "            \n",
    "            output = f\">{query_name}\\n{sequence_translated}\"\n",
    "            query_file_new.write(output)\n",
    "\n",
    "        genome_file = get_genome_file(genome_location,species)\n",
    "        genome = f\"{genome_location}/{species}/{genome_file}\"\n",
    "        out_location = f\"{blast_location}\"\n",
    "    \n",
    "        \n",
    "        blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.htm\" -html'\n",
    "        # print(blast_command)\n",
    "        # subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "        subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "        blast_command = f'tblastn -seg no -query \"{query_location}\" -db \"{genome}\" -num_alignments 3 -out \"{out_location}/blast_out.txt\"'\n",
    "        subprocess.run(f'{blast_command}', shell = True, stderr = subprocess.DEVNULL)\n",
    "    \n",
    "\n",
    "                \n",
    "        # acceptor, donor, don_line, acc_line = process_spiceator_result(start, stop,annotated_genome_location,annotated_species_name)\n",
    "\n",
    "#         if acceptor == \"Y\" and donor  == \"Y\":\n",
    "#             splice_prediction = \"Y\"\n",
    "#         else:\n",
    "#             splice_prediction = \"N\"\n",
    "            \n",
    "        return(gt_ag) \n",
    "        # output_format = str(species_name.split(\"\\n\")[0])+\",\" + str(scaffold) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        # print(output_format)\n",
    "\n",
    "# ag_gt = process_genome_fragment_blast_file(output_location,left_oh,right_oh,species,genome_location)\n",
    "# print(ag_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbf3f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_genome_blast_file(annotated_genome_location, annotated_species_name,error_exon,left_overhang,right_overhang, ag_gt, splice_prediction,original_query_name, query_species ): ):\n",
    "def process_genome_blast_file(output_location,left_oh,right_oh,species,genome_location,ag_gt,query_name_original):\n",
    "    error_exon_location = f\"{output_location}/1.Blast_result/{species}/Error_exon_processing/{error_exon}\"\n",
    "    blast_location = f\"{error_exon_location}/Run_Blast\"\n",
    "\n",
    "    with open(f\"{blast_location}/new_query_spliced.txt\", 'r') as query_file:\n",
    "        query_name_list = [query_file.readlines()[0][1:].rstrip()]\n",
    "        seq_modi = [[int(left_oh),int(right_oh)]]\n",
    "        print(seq_modi)\n",
    "\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length,\" +  \"AG_GT,\" + \"Spliceator_prediction\\n\"\n",
    "    \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    species_name = species\n",
    "\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "        Length_switch = \"0\"\n",
    "        \n",
    "        with open(f\"{blast_location}/blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "        gt_ag = \"N\"\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "            # print(lines)\n",
    "            # print(query_name)\n",
    "            if query_name in lines:\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "                query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "                query_species = str(query_species_split[1]+\"_\"+query_species_split[2].rstrip())\n",
    "\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "        \n",
    "        print(f\"start_coordinate : {start_coor},stop_coordinate : {stop_coor}\")\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            error = \"Y\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        seq_length = query_length\n",
    "        if (start != 0 or stop != 0):\n",
    "            start_modifier = seq_modi[i][0]\n",
    "            stop_modifier = seq_modi[i][1]\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0  \n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "\n",
    "        splice_prediction = \"Y\"   \n",
    "        output_format = str(species_name)+\",\" + str(scaff) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name_original)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \",\" + ag_gt + \",\" + splice_prediction +\"\\n\"  \n",
    "        # print(Output_Sequence)\n",
    "        return(output_format)\n",
    "# process_genome_blast_file(output_location,left_oh,right_oh,species,genome_location,ag_gt,query_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b80792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b515e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aporia_crataegi,OU538732.1,000,000,0,Y,Error_Exon_22,00,00,00\n",
      "\n",
      "Preferred Species?Leptophobia_aripa\n",
      "Exon_22.fa\n",
      "Pieris_brassicae_Exon_22_NC_059680.1_4575221_4575358_left_0_right_0\n",
      "ACKLTFPTESKSIPTAKQKEKDGGHLIQSNNNGNGASSSSAAVSQL\n",
      "Exon_22.fa\n",
      "Pieris_mannii_Exon_22_CM054800.1_4454241_4454378_left_0_right_0\n",
      "ACKLTFPTEGKSIPTAVLKKKQEDHIIESKKKGSGASHSSAAVSQL\n",
      "Exon_22.fa\n",
      "Leptophobia_aripa_Exon_22_OX637275.1_6792026_6792160_left_0_right_0\n",
      "ACKLTFPTRNKPTPSTWNEKKAEQPEASVNNGSAAIHSSAGVTKP\n",
      "Exon_22.fa\n",
      "Pieris_melete_Exon_22_CAVNZK010000320.1_2750934_2751071_left_0_right_0\n",
      "ACKLTFPTESKSITTAVWKEQREVPLNQSKKEGSGASRSSAAVSLL\n",
      "Exon_22.fa\n",
      "Pieris_rapae_Exon_22_NC_059534.1_3915544_3915681_left_0_right_0\n",
      "ACKLTFPTESKSIPTAVPKKKQEEHIVESKKKGSGATHPSVAVSQV\n",
      "Gene_start = 3362177, Gene_end = 3363187\n",
      "Getting Gene\n",
      "GCA_912999735.1_ilApoCrat1.1_genomic.fna\n",
      "['0.Temp', '1.Blast_result', '~$Pierine_species_exons.xlsx', 'Pierine_species_exons.xlsx', '1.Query', 'List_of_speceis_pierinae.xlsx', '~$List_of_speceis_pierinae.xlsx', 'tblastn.sh', '2.TOGA', 'error_exons.txt', '3.Test_alignment', '5.For Email_padded', '4.Bed File', '2.Final_output', 'desktop.ini']\n",
      "['Pieris_brassicae_Exon_22.fa', 'Pieris_mannii_Exon_22.fa', 'Leptophobia_aripa_Exon_22.fa', 'Pieris_melete_Exon_22.fa', 'Pieris_rapae_Exon_22.fa']\n",
      "Error_Exon_22\n",
      "Error_Exon_22\n",
      "Error_Exon_22\n",
      "Error_Exon_22\n",
      "Error_Exon_22\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import subprocess\n",
    "\n",
    "family_group = \"4.Pierinae\"\n",
    "\n",
    "output_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/{family_group}\"\n",
    "genome_location = \"/mnt/f/Genomes_2023-12-26\"\n",
    "\n",
    "with open(f\"{output_location}/error_exons.txt\",'r') as error_file:\n",
    "    error_file_lines = error_file.readlines()\n",
    "final_output = ''\n",
    "for line in error_file_lines:\n",
    "    if len(line) != 1:\n",
    "        print(line)\n",
    "        line_split = line.split(\",\")\n",
    "        species = line_split[0]\n",
    "        error_exon = line_split[6]\n",
    "        \n",
    "        make_folder_error_exon(output_location,species,error_exon)\n",
    "        left_oh,right_oh = make_query(output_location,error_exon,species)\n",
    "        fragment_start, fragment_end, scaffold, complement,query_name = get_genomic_coordinates(output_location,error_exon,species)\n",
    "        print(f\"Gene_start = {fragment_start}, Gene_end = {fragment_end}\")\n",
    "        gene_sequence = get_gene_sequence(genome_location, \n",
    "                          species,                       \n",
    "                          scaffold,\n",
    "                          fragment_start,\n",
    "                          fragment_end,\n",
    "                          complement,\n",
    "                          output_location)\n",
    "        \n",
    "        make_raw_files_for_alignment(gene_sequence,output_location,species,error_exon)\n",
    "        mafft_run_location = run_mafft(output_location,species,error_exon)\n",
    "        \n",
    "        query_sequence, alignment_name,alignment_file = process_mafft_output(mafft_run_location, error_exon)\n",
    "        \n",
    "        print(f'Alignment File: {\"\".join(alignment_file)}')\n",
    "        query_check = input(\"Query OK?\")\n",
    "        if query_check[0].lower() == 'n':\n",
    "            query_sequence = input(\"Add new query :\")\n",
    "            if query_sequence == '':\n",
    "                print(species, error_exon)\n",
    "                assert False\n",
    "        run_blast(gene_sequence,query_sequence,alignment_name,output_location,species, error_exon)\n",
    "        ag_gt = process_genome_fragment_blast_file(output_location,left_oh,right_oh,species,genome_location)\n",
    "        if ag_gt != \"Error!! Too many stops\":\n",
    "            coordinate_output = process_genome_blast_file(output_location,left_oh,right_oh,species,genome_location,ag_gt,query_name)\n",
    "            print(coordinate_output)\n",
    "            final_output += coordinate_output + \"\\n\\n\"\n",
    "        else:\n",
    "            print(ag_gt)\n",
    "        \n",
    "        input(\"Fix Overhang!! Proceed?\")\n",
    "#         print(gene_sequence)\n",
    "with open(f\"{output_location}/error_exons_fixed.txt\",'w') as out_file:\n",
    "    out_file.write(final_output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0698f5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/3.Satyrine/1.Blast_result/Coenonympha_glycerion/Error_exon_processing/Error_Exon_22/for_alignment/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mafft_run_location \u001b[38;5;241m=\u001b[39m \u001b[43mrun_mafft\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43mspecies\u001b[49m\u001b[43m,\u001b[49m\u001b[43merror_exon\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mrun_mafft\u001b[0;34m(output_location, species, error_exon)\u001b[0m\n\u001b[1;32m      2\u001b[0m error_exon_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/1.Blast_result/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/Error_exon_processing/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_exon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_exon_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/for_alignment/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m list_of_files_to_run_mafft_on \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m list_of_files_to_run_mafft_on:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.fa\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/h/My Drive/Circadian Rhythm Genes Project/6.Period Exon Analysis/3.Satyrine/1.Blast_result/Coenonympha_glycerion/Error_exon_processing/Error_Exon_22/for_alignment/'"
     ]
    }
   ],
   "source": [
    "mafft_run_location = run_mafft(output_location,species,error_exon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1cb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#         print()\n",
    "        \n",
    "get_genomic_coordinates(output_location,error_exon,species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12854358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_files_for_alignment(gene_sequence,annotated_genome_location,annotated_species_name,error_exon,query_fasta_sequence,query_length):\n",
    "    for offset in range(3):\n",
    "        translated_sequence = str(gene_sequence[offset:].translate()).split(\"*\")\n",
    "        for i in range(len(translated_sequence)):\n",
    "            if len(translated_sequence[i])> 0.8*query_length:\n",
    "                sequence_set = f\">set{i+1}_frame{offset}\\n{translated_sequence[i]}\\n\\n\"\n",
    "                # print(i+1, offset)\n",
    "                \n",
    "                with open(f\"{annotated_genome_location}/{annotated_species_name}/Period_gene_genomic_sequence_individual_exon_{query_species}/{error_exon}/for_alignment/{error_exon}_translated_genomic_sequence_{i+1}_frame{offset}.fa\",'w') as out_file:\n",
    "                    output = f\"{query_fasta_sequence}\\n\\n{sequence_set}\"\n",
    "                    out_file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba374ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
