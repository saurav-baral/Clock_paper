{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12f98d0a-daf2-4ad6-aef0-7eb1394a8a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50aa19f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hestina_assimilis\n",
      "Exon_1 Match\n",
      "[['Danaus_plexippus', ['8131918', '8132014']], ['Vanessa_tameamea', ['8131918', '8132014']], ['Nymphalis_io', ['8131918', '8132014']]]\n",
      "Exon_2 Match\n",
      "[['Danaus_plexippus', ['8132083', '8132636']], ['Vanessa_tameamea', ['8132083', '8132636']], ['Nymphalis_io', ['8132083', '8132636']]]\n",
      "Exon_3 Match\n",
      "[['Danaus_plexippus', ['8132971', '8133124']], ['Vanessa_tameamea', ['8132971', '8133124']], ['Nymphalis_io', ['8132971', '8133124']]]\n",
      "Exon_4 mismatch\n",
      "[['Danaus_plexippus', ['8133212', '8133522']], ['Vanessa_tameamea', ['8133212', '8133468']], ['Nymphalis_io', ['8133212', '8133441']]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "family_group = \"6.Heliconiinae_Danainae_Nymphalinae\"\n",
    "annotated_genome_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/7.Timeless Exon Analysis/{family_group}/1.Blast_result\"\n",
    "species_list = os.listdir(annotated_genome_location)\n",
    "if \"desktop.ini\" in species_list:\n",
    "    species_list.remove(\"desktop.ini\")\n",
    "# species_list = [\"Boloria_euphrosyne\",\"Boloria_selene\",\"Brenthis_daphne\",\"Brenthis_hecate\",\"Brenthis_ino\",\"Dryadula_phaetusa\",\"Dryas_iulia_moderata\",\"Eueides_isabella\",\"Fabriciana_adippe\",\"Heliconius_charithonia\",\"Heliconius_nattereri\",\"Heliconius_sara\",\"Philaethria_dido\",\"Hestina_assimilis\"]\n",
    "# species_list = [\"Limenitis_camilla\"]\n",
    "# species_list = [\"Argynnis_bischoffii_washingtonia\",\"Boloria_euphrosyne\",\"Boloria_selene\",\"Brenthis_daphne\",\"Brenthis_hecate\",\"Brenthis_ino\",\"Dryadula_phaetusa\",\"Dryas_iulia_moderata\",\"Eueides_isabella\",\"Fabriciana_adippe\",\"Heliconius_charithonia\",\"Heliconius_nattereri\",\"Heliconius_sara\",\"Philaethria_dido\",\"Hestina_assimilis\"]\n",
    "# species_list = [\"Bicyclus_anynana\",\"Coenonympha_glycerion\",\"Elymnias_hypermnestra\",\"Erebia_aethiops\",\"Erebia_ligea\",\"Hipparchia_semele\",\"Lasiommata_megera\",\"Maniola_hyperantus\",\"Maniola_jurtina\",\"Melanargia_galathea\",\"Oeneis_ivallda\",\"Pararge_aegeria\"]\n",
    "# species_list = [\"Erebia_ligea\",\"Hipparchia_semele\",\"Lasiommata_megera\",\"Maniola_hyperantus\",\"Maniola_jurtina\",\"Melanargia_galathea\",\"Oeneis_ivallda\",\"Pararge_aegeria\"]\n",
    "# species_list = [\"Vanessa_tameamea\"]\n",
    "for species in species_list:\n",
    "    print(species)\n",
    "    blast_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/7.Timeless Exon Analysis/{family_group}/1.Blast_result\"\n",
    "    \n",
    "    list_of_files = os.listdir(f\"{blast_location}/{species}\")\n",
    "    query_species_list = []\n",
    "    coordinate_detail_dictionary = {}\n",
    "    coordinate_info_dictionary = {}\n",
    "    scaffold = ''\n",
    "    for file in list_of_files:\n",
    "        if file.endswith(\".csv\") and len(file.split(\"_\")) >= 5 and not(file.endswith(\"_old.csv\")):\n",
    "#             print(file)\n",
    "            if \".\" in file[:-4]:\n",
    "                query_species = f\"{file.split('_')[-2].split('.')[1]}_{file.split('_')[-1].split('.')[0]}\"\n",
    "            else:\n",
    "                query_species = f\"{file.split('_')[-2]}_{file.split('_')[-1].split('.')[0]}\"\n",
    "            query_species_list.append(query_species)\n",
    "            coordinate_detail_dictionary[query_species] = {}\n",
    "            with open(f\"{blast_location}/{species}/{file}\", 'r') as coordinate_file_open:\n",
    "                coordinate_file_lines_list  =  coordinate_file_open.readlines()\n",
    "            if scaffold == '':\n",
    "                scaffold = coordinate_file_lines_list[1].split(\",\")[1]\n",
    "    \n",
    "            for i in range(1,len(coordinate_file_lines_list)):\n",
    "                \n",
    "                coordinate_file_lines_split = coordinate_file_lines_list[i].split(\",\")\n",
    "                start,stop = coordinate_file_lines_split[2],coordinate_file_lines_split[3]\n",
    "                exon = f\"Exon_{i}\"\n",
    "                if exon not in coordinate_info_dictionary:\n",
    "                    coordinate_info_dictionary[exon] = {}\n",
    "                coordinate_info_dictionary[exon][query_species] = [start,stop]\n",
    "                coordinate_detail_dictionary[query_species][exon] = coordinate_file_lines_list[i]\n",
    "            \n",
    "            # break\n",
    "            # print(query_species)\n",
    "            # print(file)\n",
    "    # print(coordinate_info_dictionary)\n",
    "    # assert False\n",
    "    output = coordinate_file_lines_list[0]\n",
    "    for exon,species_specific_coordinates in coordinate_info_dictionary.items():\n",
    "        # print(exon,species_specific_coordinates)\n",
    "        coordinates_list = []\n",
    "        previous_coordinates = \"\"\n",
    "        match = 1\n",
    "        for query_species, coordinates in coordinate_info_dictionary[exon].items():\n",
    "            coordinates_list.append([query_species,coordinates])\n",
    "            if previous_coordinates != '':\n",
    "                if coordinates != previous_coordinates:\n",
    "                    match = 0\n",
    "                    \n",
    "            previous_coordinates = coordinates\n",
    "       \n",
    "        \n",
    "        \n",
    "        if match == 0:\n",
    "            print(exon,\"mismatch\")\n",
    "            print(coordinates_list)\n",
    "                \n",
    "            while True:\n",
    "                choice = input(\"Proceed?\")\n",
    "                if choice[0].lower() == \"y\" or choice[0].lower() == \"n\":\n",
    "                    break\n",
    "            \n",
    "            while True:\n",
    "                if choice[0].lower() == \"y\":\n",
    "                    alignment_detail_dictionary = {}\n",
    "                    for query_species_name in query_species_list:\n",
    "                        list_of_folders  = os.listdir(f\"{blast_location}/{species}\")\n",
    "                        for folders in list_of_folders:\n",
    "                            if folders.endswith(query_species_name):\n",
    "                                # print()\n",
    "                                \n",
    "                                with open(f\"{blast_location}/{species}/{folders}/{exon}/for_blast/new_query.txt\", 'r') as query_file_open:\n",
    "                                    # alignment_detail = query_file_open.readlines()[0]\n",
    "                                    alignment_detail = query_file_open.readlines()[0].split(\"set\")[1][:-1]\n",
    "                                    alignment_detail_dictionary[query_species_name] = alignment_detail\n",
    "                                with open (f\"{blast_location}/{species}/{folders}/{exon}/for_alignment/{exon}_translated_genomic_sequence_{alignment_detail}.fa.hat2\", 'r') as alignment_score_file:\n",
    "                                    distance_score = float(alignment_score_file.readlines()[-1].rstrip())\n",
    "                                try:\n",
    "                                    with open (f\"{blast_location}/{species}/{folders}/{exon}/for_blast/new_query_spliced.txt\", 'r') as new_query_file:\n",
    "                                        new_query = (new_query_file.readlines()[-1].rstrip())\n",
    "                                except:\n",
    "                                    new_query = \"Issue with query\"\n",
    "                                print(query_species_name,exon, alignment_detail, distance_score,f\"\\n{new_query}\")\n",
    "                    while True:            \n",
    "                        check_alignment = input(\"Check Alignment??\")\n",
    "                        if check_alignment[0].lower() == \"y\" or check_alignment[0].lower() == \"n\":\n",
    "                            break\n",
    "                    if check_alignment[0].lower() == \"y\":\n",
    "                        for query_species_name in query_species_list:\n",
    "                            list_of_folders  = os.listdir(f\"{blast_location}/{species}\")\n",
    "                            for folders in list_of_folders:\n",
    "                                if folders.endswith(query_species_name):\n",
    "                                    with open (f\"{blast_location}/{species}/{folders}/{exon}/for_alignment/alignment_clustal_{exon}_translated_genomic_sequence_{alignment_detail_dictionary[query_species_name]}.fa.txt\", 'r') as clustal_alignment_file:\n",
    "                                        clustal_alignment = clustal_alignment_file.readlines()\n",
    "                                    print(\"\".join(clustal_alignment))\n",
    "                                    \n",
    "                                # assert False\n",
    "                    while True:\n",
    "                        try:\n",
    "                            species_number = (input(f\"Choose Species 1 - {len(query_species_list)}\"))\n",
    "                            \n",
    "                            \n",
    "                            if species_number[0].lower() == 'n':\n",
    "                                output +=  f'{species},{scaffold},000,000,0,Y,Error_{exon},00,00,00\\n'\n",
    "                                break \n",
    "                            output += coordinate_detail_dictionary[query_species_list[int(species_number)-1]][exon]\n",
    "                            break\n",
    "                        except:\n",
    "                            print(\"Retry\")\n",
    "                    break\n",
    "                elif choice[0].lower() == \"n\":\n",
    "                    output +=  f'{species},{scaffold},000,000,0,Y,Error_{exon},00,00,00\\n'\n",
    "                    break\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            print(exon, \"Match\")\n",
    "            print(coordinates_list)\n",
    "            output += coordinate_detail_dictionary[query_species_list[0]][exon]\n",
    "        \n",
    "       \n",
    "\n",
    "        # assert False\n",
    "    # print(coordinate_detail_dictionary)\n",
    "    print(output)\n",
    "    with open(f\"{blast_location}/{species}/final_coordinates.csv\", \"w\") as out_file:\n",
    "        out_file.write(output)\n",
    "    \n",
    "    # 'Coenonympha_glycerion,OY979626.1,7015875,7015963,0,N,5.Bicyclus_anynana_XM_024088150.2_Frame_0_rightoh_2_query_Exon_1,1,29,29\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892a6a6-9400-414d-bbaa-cf893036e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
