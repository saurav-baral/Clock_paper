{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f27d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_extractor(Species, Scaff, reverse_c, start, end, frame = 1, trans = 1 ):\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    import os\n",
    "    \n",
    "    out_Seq = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Genome folder\n",
    "    entries = os.listdir(\"/mnt/f/Genomes_2023-12-26/\"+Species)\n",
    "    \n",
    "    #Get genome file from Genome folder\n",
    "    for file_names  in entries:\n",
    "        if \".nhr\" in file_names:\n",
    "            Genome_name = file_names[:-4]\n",
    "            break\n",
    "    \n",
    "    #Read the genome file\n",
    "    fasta_file = open((\"/mnt/f/Genomes_2023-12-26/\"+Species+\"/\"+Genome_name),'r')\n",
    "    \n",
    "    #Extract the sequence \n",
    "    for record in SeqIO.parse(fasta_file,\"fasta\"):\n",
    "        if record.id == Scaff:\n",
    "            sequence = str(record.seq)\n",
    "            out_Seq = Seq(sequence[start-1:end])\n",
    "            if reverse_c == 1:\n",
    "                out_Seq = out_Seq.reverse_complement()\n",
    "                \n",
    "    if len(out_Seq) < 10000: #fixing error due to mistake in typing the coordinate, change this for longer sequence\n",
    "#        print (out_Seq)\n",
    "        if frame == 1 :\n",
    "            out_trans = out_Seq[0:]\n",
    "        if frame == 2 :\n",
    "            out_trans = out_Seq[1:]\n",
    "        if frame == 3 :\n",
    "            out_trans = out_Seq[2:]\n",
    "    else:\n",
    "        print (\"too long\")\n",
    "        assert(False)\n",
    "        \n",
    "        \n",
    "    #    break\n",
    "    fasta_file.close()\n",
    "    if trans == 1:\n",
    "        return (out_trans.translate())\n",
    "    else:\n",
    "        return(out_Seq)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4900aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d454c091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aricia_agestis\n",
      "RKSGVGNSALSYLCSNIQSNR\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 167\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (query_name \u001b[38;5;241m==\u001b[39m query_name_list[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m query_name \u001b[38;5;241m==\u001b[39m query_name_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    166\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 167\u001b[0m     translated_sequence \u001b[38;5;241m=\u001b[39m (\u001b[43msequence_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomplement\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m translated_sequence \u001b[38;5;241m==\u001b[39m old_trans:\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m, in \u001b[0;36msequence_extractor\u001b[0;34m(Species, Scaff, reverse_c, start, end, frame, trans)\u001b[0m\n\u001b[1;32m     20\u001b[0m fasta_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/f/Genomes_2023-12-26/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mSpecies\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mGenome_name),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#Extract the sequence \u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m SeqIO\u001b[38;5;241m.\u001b[39mparse(fasta_file,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m==\u001b[39m Scaff:\n\u001b[1;32m     25\u001b[0m         sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(record\u001b[38;5;241m.\u001b[39mseq)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/Bio/SeqIO/Interfaces.py:85\u001b[0m, in \u001b[0;36mSequenceIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the next entry.\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_close_stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/Bio/SeqIO/FastaIO.py:199\u001b[0m, in \u001b[0;36mFastaIterator.iterate\u001b[0;34m(self, handle)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21miterate\u001b[39m(\u001b[38;5;28mself\u001b[39m, handle):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse the file and generate SeqRecord objects.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m title, sequence \u001b[38;5;129;01min\u001b[39;00m SimpleFastaParser(handle):\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m             first_word \u001b[38;5;241m=\u001b[39m title\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/Bio/SeqIO/FastaIO.py:65\u001b[0m, in \u001b[0;36mSimpleFastaParser\u001b[0;34m(handle)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Main logic\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Note, remove trailing whitespace, and any internal spaces\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# (and any embedded \\r which are possible in mangled files\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# when not opened in universal read lines mode)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m handle:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m line[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m title, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lines)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "family_group = \"4.Pierinae\"\n",
    "blast_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/7.Timeless Exon Analysis/{family_group}\"\n",
    "query_location = f\"{blast_location}/1.Query\"\n",
    "query_species = \"Pieris_brassicae\"\n",
    "query_transcript_list = os.listdir(f\"{query_location}/{query_species}\")\n",
    "if \"desktop.ini\" in query_transcript_list:\n",
    "    query_transcript_list.remove(\"desktop.ini\")\n",
    "\n",
    "query_transcript = query_transcript_list[0]\n",
    "#Get Species list, the list may be a list of files or a single species\n",
    "# query_species = \"22.Pieris_brassicae\"\n",
    "# phylo_species = open(\"C:/Users/sauba/Desktop/Work_Stuff/MRJP/0.for_automation_temp_files/phylo_species.txt\",'r')\n",
    "# species_list = phylo_species.readlines()\n",
    "# species_list = [\"10.Plutella_xylostella\",\"11.Bombyx_mori\",\"12.Manduca_sexta\",\"13.Danaus_plexippus\",\"14.Zerene_cesonia\",\"15.Hyposmocoma_kahamanoa\",\"16.Papilio_xuthus\",\"17.Papilio_polytes\",\"18.Bombyx_mandarina\",\"19.Trichoplusia_ni\",\"2.Galleria_mellonella\",\"20.Vanessa_tameamea\",\"21.Amyelois_transitella\",\"22.Pieris_brassicae\",\"23.Vanessa_atalanta\",\"24.Spodoptera_frugiperda\",\"25.Pieris_napi\",\"26.Vanessa_cardui\",\"27.Maniola_hyperantus\",\"28.Maniola_jurtina\",\"29.Nymphalis_io\",\"3.Spodoptera_litura\",\"30.Leptidea_sinapis\",\"31.Leguminivora_glycinivorella\",\"32.Colias_croceus\",\"33.Pararge_aegeria\",\"36.Melitaea_cinxia\",\"37.Aricia_agestis\",\"38.Papilio_machaon\",\"39.Leptidea_sinapis\",\"4.Helicoverpa_armigera\",\"40.Colias_croceus\",\"41.Manduca_sexta\",\"42.Spodoptera_frugiperda\",\"43.Ostrinia_furnacalis\",\"5.Bicyclus_anynana\",\"6.Pectinophora_gossypiella\",\"7.Helicoverpa_zea\",\"8.Plodia_interpunctella\",\"9.Pieris_rapae\"]\n",
    "species_list = os.listdir(f\"{blast_location}/1.Blast_result\")\n",
    "# species_list = [\"Calephelis_nemesis\",\"Calephelis_virginiensis\"]\n",
    "if \"desktop.ini\" in species_list:\n",
    "    species_list.remove('desktop.ini')\n",
    "# species_list = [\"5.Bicyclus_anynana\"]\n",
    "# species_list = [\"29.Nymphalis_io\",\"3.Spodoptera_litura\",\"30.Leptidea_sinapis\",\"31.Leguminivora_glycinivorella\",\"32.Colias_croceus\",\"33.Pararge_aegeria\",\"36.Melitaea_cinxia\",\"37.Aricia_agestis\",\"38.Papilio_machaon\",\"39.Leptidea_sinapis\",\"4.Helicoverpa_armigera\",\"40.Colias_croceus\",\"41.Manduca_sexta\",\"42.Spodoptera_frugiperda\",\"43.Ostrinia_furnacalis\",\"5.Bicyclus_anynana\",\"6.Pectinophora_gossypiella\",\"7.Helicoverpa_zea\",\"8.Plodia_interpunctella\",\"9.Pieris_rapae\"]\n",
    "# species_list = [\"36.Melitaea_cinxia\",\"37.Aricia_agestis\",\"38.Papilio_machaon\",\"39.Leptidea_sinapis\",\"4.Helicoverpa_armigera\",\"40.Colias_croceus\",\"41.Manduca_sexta\",\"42.Spodoptera_frugiperda\",\"43.Ostrinia_furnacalis\",\"5.Bicyclus_anynana\",\"6.Pectinophora_gossypiella\",\"7.Helicoverpa_zea\",\"8.Plodia_interpunctella\",\"9.Pieris_rapae\"]\n",
    "#print(species_list)\n",
    "# species_list = [\"3.Spodoptera_litura\"]\n",
    "#get list of query names\n",
    "\n",
    "query_file = SeqIO.parse(f\"{blast_location}/1.Query/{query_species}/{query_transcript}/query_protein.fa\", 'fasta')\n",
    "query_name_list = []\n",
    "\n",
    "for records in query_file:\n",
    "    query_name_list.append(records.id)\n",
    "\n",
    "\n",
    "\n",
    "for species in species_list:\n",
    "    # print(species_name)\n",
    "    # species = species_name.split(\".\")[1]\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    \n",
    "#Run for each query in the query list\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "#         print(f\"Query name = {query_name}\")\n",
    "        Length_switch = \"0\"\n",
    "        with open(f\"{blast_location}/1.Blast_result/{species}/{species}_blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "        #print(lines_in_file)\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "#                 print(lines)\n",
    "#                 assert False\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "#                 query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "#                 query_species = str(query_species_split[0].split(\".\")[1]+\"_\"+query_species_split[1].rstrip())\n",
    "                print(query_species)\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            length = 0\n",
    "            start = 000\n",
    "            stop = 000\n",
    "            query_start_coor = 000\n",
    "            query_stop_coor = 000\n",
    "            error = \"Y\"\n",
    "            complement  = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "#             print(start, stop)\n",
    "\n",
    "\n",
    "#Check for Met or STOP at the start and end\n",
    "        while True and (start != 0 or stop != 0):\n",
    "            if (query_name == query_name_list[0] or query_name == query_name_list[-1]):\n",
    "                frame = 1\n",
    "                translated_sequence = (sequence_extractor(species, scaff, int(complement), start, stop,frame ))\n",
    "\n",
    "                if translated_sequence == old_trans:\n",
    "                    break\n",
    "                    \n",
    "#Check for Met at the beginning of first exon\n",
    "\n",
    "                if query_name == query_name_list[0] :\n",
    "                    if translated_sequence[0] != \"M\":\n",
    "                        print(translated_sequence)\n",
    "#                             print(start, stop)\n",
    "                        if complement == \"0\":\n",
    "                            start = int(start) - 3\n",
    "                        if complement == \"1\":\n",
    "                            stop = int(stop) + 3\n",
    "                        old_trans = translated_sequence\n",
    "                    if \"*\" in translated_sequence:\n",
    "                        error = \"Y\"\n",
    "                        break\n",
    "                    if translated_sequence[0] == \"M\":\n",
    "                        break\n",
    "\n",
    "#Check for stop at the end of last exon\n",
    "\n",
    "                if query_name == query_name_list[-1]:\n",
    "                    if translated_sequence[-1] != \"*\":\n",
    "                        print(translated_sequence)\n",
    "#                             print(start, stop)\n",
    "                        if complement == \"0\":\n",
    "                            stop = int(stop) + 3\n",
    "                        if complement == \"1\":\n",
    "                            start = int(start) - 3\n",
    "                        old_trans = translated_sequence\n",
    "                    if translated_sequence[-1] == \"*\":\n",
    "\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "#Add offset at the beginning and end of each exon\n",
    "        if (start != 0 or stop != 0):\n",
    "            \n",
    "            start_modifier = int(query_name.split(\"Frame\")[1][1])\n",
    "            stop_modifier = int(query_name.split(\"rightoh\")[1][1])\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0            \n",
    "\n",
    "        seq_length = query_length\n",
    "        \n",
    "        \n",
    "#Get exon start and end by adding or removing codons\n",
    "        \n",
    "    #if not the beginning\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "            \n",
    "           \n",
    "        output_format = str(species.split(\"\\n\")[0])+\",\" + str(scaff) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        print(output_format)\n",
    "#         assert False\n",
    "        Output_Sequence = Output_Sequence + output_format\n",
    "\n",
    "    print(Output_Sequence)\n",
    "   \n",
    "    output_file = open(f\"{blast_location}/1.Blast_result/{species}/{species}_coordinates_old.csv\",'w')\n",
    "    output_file.write(Output_Sequence)\n",
    "    output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa07f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fa823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
