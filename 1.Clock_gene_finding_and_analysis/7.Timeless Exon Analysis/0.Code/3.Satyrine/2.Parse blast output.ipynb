{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f27d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_extractor(Species, Scaff, reverse_c, start, end, frame = 1, trans = 1 ):\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    import os\n",
    "    \n",
    "    out_Seq = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Genome folder\n",
    "    entries = os.listdir(\"/mnt/f/Genomes_2023-12-26/\"+Species)\n",
    "    \n",
    "    #Get genome file from Genome folder\n",
    "    for file_names  in entries:\n",
    "        if \".nhr\" in file_names:\n",
    "            Genome_name = file_names[:-4]\n",
    "            break\n",
    "    \n",
    "    #Read the genome file\n",
    "    fasta_file = open((\"/mnt/f/Genomes_2023-12-26/\"+Species+\"/\"+Genome_name),'r')\n",
    "    \n",
    "    #Extract the sequence \n",
    "    for record in SeqIO.parse(fasta_file,\"fasta\"):\n",
    "        if record.id == Scaff:\n",
    "            sequence = str(record.seq)\n",
    "            out_Seq = Seq(sequence[start-1:end])\n",
    "            if reverse_c == 1:\n",
    "                out_Seq = out_Seq.reverse_complement()\n",
    "                \n",
    "    if len(out_Seq) < 10000: #fixing error due to mistake in typing the coordinate, change this for longer sequence\n",
    "#        print (out_Seq)\n",
    "        if frame == 1 :\n",
    "            out_trans = out_Seq[0:]\n",
    "        if frame == 2 :\n",
    "            out_trans = out_Seq[1:]\n",
    "        if frame == 3 :\n",
    "            out_trans = out_Seq[2:]\n",
    "    else:\n",
    "        print (\"too long\")\n",
    "        assert(False)\n",
    "        \n",
    "        \n",
    "    #    break\n",
    "    fasta_file.close()\n",
    "    if trans == 1:\n",
    "        return (out_trans.translate())\n",
    "    else:\n",
    "        return(out_Seq)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4900aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d454c091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10745526,10745622,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_1_query_Exon_1,1,32,32\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10744587,10745137,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_0_query_Exon_2,1,183,183\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10744039,10744192,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_1_query_Exon_3,1,51,51\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10743632,10743870,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_0_query_Exon_4,1,79,79\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10742699,10742982,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_2_query_Exon_5,1,94,94\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10741832,10742192,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_0_query_Exon_6,1,120,120\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10741252,10741443,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_0_query_Exon_7,1,64,64\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10740266,10740366,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_2_query_Exon_8,1,33,33\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10738565,10738763,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_0_query_Exon_9,1,66,66\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10737371,10737585,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_2_query_Exon_10,1,71,71\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10736202,10736662,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_1_query_Exon_11,1,153,153\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10735925,10736125,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_1_query_Exon_12,1,66,66\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10735262,10735445,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_2_query_Exon_13,1,60,60\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10734095,10734199,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_2_query_Exon_14,1,34,34\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10733110,10733307,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_2_query_Exon_15,1,65,65\n",
      "\n",
      "Bicyclus_anynana\n",
      "Bicyclus_anynana,NC_069085.1,10730856,10731039,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_0_query_Exon_16,1,61,61\n",
      "\n",
      "Species,Scaffold,Start,Stop,Complement,Error,Gene,Query_start,Query_stop,Query_Length\n",
      "Bicyclus_anynana,NC_069085.1,10745526,10745622,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_1_query_Exon_1,1,32,32\n",
      "Bicyclus_anynana,NC_069085.1,10744587,10745137,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_0_query_Exon_2,1,183,183\n",
      "Bicyclus_anynana,NC_069085.1,10744039,10744192,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_1_query_Exon_3,1,51,51\n",
      "Bicyclus_anynana,NC_069085.1,10743632,10743870,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_0_query_Exon_4,1,79,79\n",
      "Bicyclus_anynana,NC_069085.1,10742699,10742982,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_2_query_Exon_5,1,94,94\n",
      "Bicyclus_anynana,NC_069085.1,10741832,10742192,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_0_query_Exon_6,1,120,120\n",
      "Bicyclus_anynana,NC_069085.1,10741252,10741443,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_0_query_Exon_7,1,64,64\n",
      "Bicyclus_anynana,NC_069085.1,10740266,10740366,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_2_query_Exon_8,1,33,33\n",
      "Bicyclus_anynana,NC_069085.1,10738565,10738763,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_0_query_Exon_9,1,66,66\n",
      "Bicyclus_anynana,NC_069085.1,10737371,10737585,1,N,Bicyclus_anynana_XM_052891332.1_Frame_0_rightoh_2_query_Exon_10,1,71,71\n",
      "Bicyclus_anynana,NC_069085.1,10736202,10736662,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_1_query_Exon_11,1,153,153\n",
      "Bicyclus_anynana,NC_069085.1,10735925,10736125,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_1_query_Exon_12,1,66,66\n",
      "Bicyclus_anynana,NC_069085.1,10735262,10735445,1,N,Bicyclus_anynana_XM_052891332.1_Frame_2_rightoh_2_query_Exon_13,1,60,60\n",
      "Bicyclus_anynana,NC_069085.1,10734095,10734199,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_2_query_Exon_14,1,34,34\n",
      "Bicyclus_anynana,NC_069085.1,10733110,10733307,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_2_query_Exon_15,1,65,65\n",
      "Bicyclus_anynana,NC_069085.1,10730856,10731039,1,N,Bicyclus_anynana_XM_052891332.1_Frame_1_rightoh_0_query_Exon_16,1,61,61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "family_group = \"3.Satyrine\"\n",
    "blast_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/7.Timeless Exon Analysis/{family_group}\"\n",
    "query_location = f\"{blast_location}/1.Query\"\n",
    "query_species = \"Bicyclus_anynana\"\n",
    "query_transcript_list = os.listdir(f\"{query_location}/{query_species}\")\n",
    "if \"desktop.ini\" in query_transcript_list:\n",
    "    query_transcript_list.remove(\"desktop.ini\")\n",
    "\n",
    "query_transcript = query_transcript_list[0]\n",
    "#Get Species list, the list may be a list of files or a single species\n",
    "# query_species = \"22.Pieris_brassicae\"\n",
    "# phylo_species = open(\"C:/Users/sauba/Desktop/Work_Stuff/MRJP/0.for_automation_temp_files/phylo_species.txt\",'r')\n",
    "# species_list = phylo_species.readlines()\n",
    "# species_list = [\"10.Plutella_xylostella\",\"11.Bombyx_mori\",\"12.Manduca_sexta\",\"13.Danaus_plexippus\",\"14.Zerene_cesonia\",\"15.Hyposmocoma_kahamanoa\",\"16.Papilio_xuthus\",\"17.Papilio_polytes\",\"18.Bombyx_mandarina\",\"19.Trichoplusia_ni\",\"2.Galleria_mellonella\",\"20.Vanessa_tameamea\",\"21.Amyelois_transitella\",\"22.Pieris_brassicae\",\"23.Vanessa_atalanta\",\"24.Spodoptera_frugiperda\",\"25.Pieris_napi\",\"26.Vanessa_cardui\",\"27.Maniola_hyperantus\",\"28.Maniola_jurtina\",\"29.Nymphalis_io\",\"3.Spodoptera_litura\",\"30.Leptidea_sinapis\",\"31.Leguminivora_glycinivorella\",\"32.Colias_croceus\",\"33.Pararge_aegeria\",\"36.Melitaea_cinxia\",\"37.Aricia_agestis\",\"38.Papilio_machaon\",\"39.Leptidea_sinapis\",\"4.Helicoverpa_armigera\",\"40.Colias_croceus\",\"41.Manduca_sexta\",\"42.Spodoptera_frugiperda\",\"43.Ostrinia_furnacalis\",\"5.Bicyclus_anynana\",\"6.Pectinophora_gossypiella\",\"7.Helicoverpa_zea\",\"8.Plodia_interpunctella\",\"9.Pieris_rapae\"]\n",
    "species_list = os.listdir(f\"{blast_location}/1.Blast_result\")\n",
    "species_list = [\"Bicyclus_anynana\"]\n",
    "if \"desktop.ini\" in species_list:\n",
    "    species_list.remove('desktop.ini')\n",
    "# species_list = [\"5.Bicyclus_anynana\"]\n",
    "# species_list = [\"29.Nymphalis_io\",\"3.Spodoptera_litura\",\"30.Leptidea_sinapis\",\"31.Leguminivora_glycinivorella\",\"32.Colias_croceus\",\"33.Pararge_aegeria\",\"36.Melitaea_cinxia\",\"37.Aricia_agestis\",\"38.Papilio_machaon\",\"39.Leptidea_sinapis\",\"4.Helicoverpa_armigera\",\"40.Colias_croceus\",\"41.Manduca_sexta\",\"42.Spodoptera_frugiperda\",\"43.Ostrinia_furnacalis\",\"5.Bicyclus_anynana\",\"6.Pectinophora_gossypiella\",\"7.Helicoverpa_zea\",\"8.Plodia_interpunctella\",\"9.Pieris_rapae\"]\n",
    "# species_list = [\"36.Melitaea_cinxia\",\"37.Aricia_agestis\",\"38.Papilio_machaon\",\"39.Leptidea_sinapis\",\"4.Helicoverpa_armigera\",\"40.Colias_croceus\",\"41.Manduca_sexta\",\"42.Spodoptera_frugiperda\",\"43.Ostrinia_furnacalis\",\"5.Bicyclus_anynana\",\"6.Pectinophora_gossypiella\",\"7.Helicoverpa_zea\",\"8.Plodia_interpunctella\",\"9.Pieris_rapae\"]\n",
    "#print(species_list)\n",
    "# species_list = [\"3.Spodoptera_litura\"]\n",
    "#get list of query names\n",
    "\n",
    "query_file = SeqIO.parse(f\"{blast_location}/1.Query/{query_species}/{query_transcript}/query_protein.fa\", 'fasta')\n",
    "query_name_list = []\n",
    "\n",
    "for records in query_file:\n",
    "    query_name_list.append(records.id)\n",
    "\n",
    "\n",
    "\n",
    "for species in species_list:\n",
    "    # print(species_name)\n",
    "    # species = species_name.split(\".\")[1]\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    \n",
    "#Run for each query in the query list\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "#         print(f\"Query name = {query_name}\")\n",
    "        Length_switch = \"0\"\n",
    "        with open(f\"{blast_location}/1.Blast_result/{species}/{species}_blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "        #print(lines_in_file)\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "#                 print(lines)\n",
    "#                 assert False\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "#                 query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "#                 query_species = str(query_species_split[0].split(\".\")[1]+\"_\"+query_species_split[1].rstrip())\n",
    "                print(query_species)\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            length = 0\n",
    "            start = 000\n",
    "            stop = 000\n",
    "            query_start_coor = 000\n",
    "            query_stop_coor = 000\n",
    "            error = \"Y\"\n",
    "            complement  = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "#             print(start, stop)\n",
    "\n",
    "\n",
    "#Check for Met or STOP at the start and end\n",
    "        while True and (start != 0 or stop != 0):\n",
    "            if (query_name == query_name_list[0] or query_name == query_name_list[-1]):\n",
    "                frame = 1\n",
    "                translated_sequence = (sequence_extractor(species, scaff, int(complement), start, stop,frame ))\n",
    "\n",
    "                if translated_sequence == old_trans:\n",
    "                    break\n",
    "                    \n",
    "#Check for Met at the beginning of first exon\n",
    "\n",
    "                if query_name == query_name_list[0] :\n",
    "                    if translated_sequence[0] != \"M\":\n",
    "                        print(translated_sequence)\n",
    "#                             print(start, stop)\n",
    "                        if complement == \"0\":\n",
    "                            start = int(start) - 3\n",
    "                        if complement == \"1\":\n",
    "                            stop = int(stop) + 3\n",
    "                        old_trans = translated_sequence\n",
    "                    if \"*\" in translated_sequence:\n",
    "                        error = \"Y\"\n",
    "                        break\n",
    "                    if translated_sequence[0] == \"M\":\n",
    "                        break\n",
    "\n",
    "#Check for stop at the end of last exon\n",
    "\n",
    "                if query_name == query_name_list[-1]:\n",
    "                    if translated_sequence[-1] != \"*\":\n",
    "                        print(translated_sequence)\n",
    "#                             print(start, stop)\n",
    "                        if complement == \"0\":\n",
    "                            stop = int(stop) + 3\n",
    "                        if complement == \"1\":\n",
    "                            start = int(start) - 3\n",
    "                        old_trans = translated_sequence\n",
    "                    if translated_sequence[-1] == \"*\":\n",
    "\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "#Add offset at the beginning and end of each exon\n",
    "        if (start != 0 or stop != 0):\n",
    "            \n",
    "            start_modifier = int(query_name.split(\"Frame\")[1][1])\n",
    "            stop_modifier = int(query_name.split(\"rightoh\")[1][1])\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0            \n",
    "\n",
    "        seq_length = query_length\n",
    "        \n",
    "        \n",
    "#Get exon start and end by adding or removing codons\n",
    "        \n",
    "    #if not the beginning\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "            \n",
    "           \n",
    "        output_format = str(species.split(\"\\n\")[0])+\",\" + str(scaff) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        print(output_format)\n",
    "#         assert False\n",
    "        Output_Sequence = Output_Sequence + output_format\n",
    "\n",
    "    print(Output_Sequence)\n",
    "   \n",
    "    output_file = open(f\"{blast_location}/1.Blast_result/{species}/{species}_coordinates_old.csv\",'w')\n",
    "    output_file.write(Output_Sequence)\n",
    "    output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa07f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fa823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
