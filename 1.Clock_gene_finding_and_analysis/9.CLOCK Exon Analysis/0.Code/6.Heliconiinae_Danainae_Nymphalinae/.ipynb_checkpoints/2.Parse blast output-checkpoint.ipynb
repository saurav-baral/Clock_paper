{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f27d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_extractor(Species, Scaff, reverse_c, start, end, frame = 1, trans = 1 ):\n",
    "    from Bio import SeqIO\n",
    "    from Bio.Seq import Seq\n",
    "    import os\n",
    "    \n",
    "    out_Seq = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Genome folder\n",
    "    entries = os.listdir(\"/mnt/f/Genomes_2023-12-26/\"+Species)\n",
    "    \n",
    "    #Get genome file from Genome folder\n",
    "    for file_names  in entries:\n",
    "        if \".nhr\" in file_names:\n",
    "            Genome_name = file_names[:-4]\n",
    "            break\n",
    "    \n",
    "    #Read the genome file\n",
    "    fasta_file = open((\"/mnt/f/Genomes_2023-12-26/\"+Species+\"/\"+Genome_name),'r')\n",
    "    \n",
    "    #Extract the sequence \n",
    "    for record in SeqIO.parse(fasta_file,\"fasta\"):\n",
    "        if record.id == Scaff:\n",
    "            sequence = str(record.seq)\n",
    "            out_Seq = Seq(sequence[start-1:end])\n",
    "            if reverse_c == 1:\n",
    "                out_Seq = out_Seq.reverse_complement()\n",
    "                \n",
    "    if len(out_Seq) < 10000: #fixing error due to mistake in typing the coordinate, change this for longer sequence\n",
    "#        print (out_Seq)\n",
    "        if frame == 1 :\n",
    "            out_trans = out_Seq[0:]\n",
    "        if frame == 2 :\n",
    "            out_trans = out_Seq[1:]\n",
    "        if frame == 3 :\n",
    "            out_trans = out_Seq[2:]\n",
    "    else:\n",
    "        print (\"too long\")\n",
    "        assert(False)\n",
    "        \n",
    "        \n",
    "    #    break\n",
    "    fasta_file.close()\n",
    "    if trans == 1:\n",
    "        return (out_trans.translate())\n",
    "    else:\n",
    "        return(out_Seq)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4900aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d454c091",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danaus_plexippus\n",
      "Hestina_assimilis,Intial_value,0,0,0,Y,Danaus_plexippus_XM_032670980.2_Frame_0_rightoh_2_query_Exon_1,0,0,12\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30882230,30882378,0,N,Danaus_plexippus_XM_032670980.2_Frame_1_rightoh_1_query_Exon_2,1,49,49\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30882451,30882632,0,N,Danaus_plexippus_XM_032670980.2_Frame_2_rightoh_0_query_Exon_3,1,60,60\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30882712,30882826,0,Y,Danaus_plexippus_XM_032670980.2_Frame_0_rightoh_1_query_Exon_4,2,26,38\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30885911,30886006,0,N,Danaus_plexippus_XM_032670980.2_Frame_2_rightoh_1_query_Exon_5,1,31,31\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,0,0,0,Y,Danaus_plexippus_XM_032670980.2_Frame_2_rightoh_2_query_Exon_6,0,0,19\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30888218,30888456,0,N,Danaus_plexippus_XM_032670980.2_Frame_1_rightoh_1_query_Exon_7,1,79,79\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30888687,30888834,0,N,Danaus_plexippus_XM_032670980.2_Frame_2_rightoh_2_query_Exon_8,1,48,48\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30888835,30889012,0,N,Danaus_plexippus_XM_032670980.2_Frame_1_rightoh_0_query_Exon_9,3,62,62\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30889470,30889658,0,Y,Danaus_plexippus_XM_032670980.2_Frame_0_rightoh_0_query_Exon_10,29,63,63\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30891327,30891488,0,Y,Danaus_plexippus_XM_032670980.2_Frame_0_rightoh_0_query_Exon_11,5,25,54\n",
      "\n",
      "Danaus_plexippus\n",
      "Hestina_assimilis,CM041759.1,30891695,30891817,0,N,Danaus_plexippus_XM_032670980.2_Frame_0_rightoh_0_query_Exon_12,1,41,41\n",
      "\n",
      "Danaus_plexippus\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/f/Genomes_2023-12-26/Hestina_assimilis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 160\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (query_name \u001b[38;5;241m==\u001b[39m query_name_list[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m query_name \u001b[38;5;241m==\u001b[39m query_name_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n\u001b[1;32m    159\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 160\u001b[0m     translated_sequence \u001b[38;5;241m=\u001b[39m (\u001b[43msequence_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomplement\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m translated_sequence \u001b[38;5;241m==\u001b[39m old_trans:\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m, in \u001b[0;36msequence_extractor\u001b[0;34m(Species, Scaff, reverse_c, start, end, frame, trans)\u001b[0m\n\u001b[1;32m      6\u001b[0m out_Seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#Genome folder\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/f/Genomes_2023-12-26/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mSpecies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#Get genome file from Genome folder\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_names  \u001b[38;5;129;01min\u001b[39;00m entries:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/f/Genomes_2023-12-26/Hestina_assimilis'"
     ]
    }
   ],
   "source": [
    "#%reset -f\n",
    "family_group = \"6.Heliconiinae_Danainae_Nymphalinae\"\n",
    "blast_location = f\"/mnt/h/My Drive/Circadian Rhythm Genes Project/9.CLOCK Exon Analysis/{family_group}\"\n",
    "query_location = f\"{blast_location}/1.Query\"\n",
    "query_species = \"Danaus_plexippus\"\n",
    "query_transcript_list = os.listdir(f\"{query_location}/{query_species}\")\n",
    "if \"desktop.ini\" in query_transcript_list:\n",
    "    query_transcript_list.remove(\"desktop.ini\")\n",
    "\n",
    "query_transcript = query_transcript_list[0]\n",
    "#Get Species list, the list may be a list of files or a single species\n",
    "\n",
    "species_list = os.listdir(f\"{blast_location}/1.Blast_result\")\n",
    "\n",
    "if \"desktop.ini\" in species_list:\n",
    "    species_list.remove('desktop.ini')\n",
    "\n",
    "#get list of query names\n",
    "\n",
    "query_file = SeqIO.parse(f\"{blast_location}/1.Query/{query_species}/{query_transcript}/query_protein.fa\", 'fasta')\n",
    "query_name_list = []\n",
    "\n",
    "for records in query_file:\n",
    "    query_name_list.append(records.id)\n",
    "\n",
    "\n",
    "\n",
    "for species in species_list:\n",
    "    # print(species_name)\n",
    "    # species = species_name.split(\".\")[1]\n",
    "    header = \"Species,\" + \"Scaffold,\" + \"Start,\" + \"Stop,\" + \"Complement,\" + \"Error,\" + \"Gene,\"+ \"Query_start,\" + \"Query_stop,\"+ \"Query_Length\\n\" \n",
    "    Output_Sequence = header\n",
    "    scaff = \"Intial_value\"\n",
    "    scaff_old = \"Intial_value\"\n",
    "    old_end = 0\n",
    "    \n",
    "#Run for each query in the query list\n",
    "    for i in range(len(query_name_list)):\n",
    "        query_name = query_name_list[i]\n",
    "#         print(f\"Query name = {query_name}\")\n",
    "        Length_switch = \"0\"\n",
    "        with open(f\"{blast_location}/1.Blast_result/{species}/{species}_blast_out.txt\",'r') as tblast_out:\n",
    "            lines_in_file = tblast_out.readlines()\n",
    "        #print(lines_in_file)\n",
    "\n",
    "        result_section_switch = 0\n",
    "        start_coor_switch = 0\n",
    "        query_start_coor_switch = 0\n",
    "        stop_coor_switch = 0\n",
    "        error = \"N\"\n",
    "        break_switch = 0\n",
    "\n",
    "        start = 0\n",
    "        stop = 0\n",
    "        start_coor = 0\n",
    "        stop_coor = 0\n",
    "        query_length = 0\n",
    "\n",
    "        for lines in lines_in_file:\n",
    "\n",
    "#             print(lines)\n",
    "            if query_name in lines:\n",
    "#                 print(lines)\n",
    "#                 assert False\n",
    "            #Initialize that results can now be checked\n",
    "                result_section_switch = 1\n",
    "#                 query_species_split = lines.split(\" \")[1].split(\"_\")\n",
    "#                 query_species = str(query_species_split[0].split(\".\")[1]+\"_\"+query_species_split[1].rstrip())\n",
    "                print(query_species)\n",
    "            if result_section_switch == 1 and \"Lambda\" in lines:\n",
    "            #This block indicates end of the results block in blast output\n",
    "                result_section_switch == 0\n",
    "                \n",
    "                break\n",
    "\n",
    "            if result_section_switch == 1:\n",
    "            #While checking the result\n",
    "                if \"Length=\" in lines and Length_switch == \"0\":\n",
    "                #Get query length from the blast output\n",
    "                    \n",
    "                    query_length = int(lines.split(\"=\")[1].rstrip())\n",
    "                    \n",
    "                    Length_switch = 1 #Indicated length has been acquired\n",
    "                    \n",
    "                if (\"Score\" in lines or \">\" in lines) and (start_coor_switch == 1):\n",
    "    #                print (lines)\n",
    "                    break\n",
    "        \n",
    "                if \">\" in lines:\n",
    "                #Start of the first result\n",
    "                    scaff = lines.split(\" \")[0][1:] #Scaffold from the result\n",
    "                    if scaff_old != \"Intial_value\" and scaff_old != scaff:\n",
    "                        error = \"Y\"\n",
    "                    scaff_old = scaff\n",
    "                    \n",
    "                if \"Query\" in lines and \"=\" not in lines:\n",
    "                #Read the query line in output\n",
    "                    if query_start_coor_switch == 0:\n",
    "#                        print(lines)\n",
    "                        query_start_coor = int(lines.split(\" \")[2])\n",
    "                        query_start_coor_switch = 1\n",
    "                        #Query start coordinate fixed\n",
    "            \n",
    "                    query_stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting query stop coordinates for multiline result\n",
    "    #                print (stop_coor)\n",
    "                    \n",
    "                if \"Sbjct\" in lines:\n",
    "                #Read the blast target line\n",
    "                    if start_coor_switch == 0:\n",
    "                        start_coor = int(lines.split(\" \")[2])\n",
    "                        start_coor_switch = 1\n",
    "                    stop_coor =int(lines.split(\" \")[-1][:-1])\n",
    "                    #Keep getting target stop coordinates for multiline result\n",
    "                \n",
    "                \n",
    "\n",
    "        \n",
    "        if break_switch == 1:\n",
    "            break\n",
    "\n",
    "        if start_coor < stop_coor:\n",
    "            complement = \"0\" #Forward complement\n",
    "            \n",
    "            length = (stop_coor-start_coor)/3\n",
    "            start = start_coor\n",
    "            stop = stop_coor\n",
    "\n",
    "        elif start_coor > stop_coor:\n",
    "            complement = \"1\" #Reverse complement\n",
    "            length = (-stop_coor+start_coor)/3\n",
    "            start = stop_coor\n",
    "            stop = start_coor\n",
    "\n",
    "        else:\n",
    "            length = 0\n",
    "            start = 000\n",
    "            stop = 000\n",
    "            query_start_coor = 000\n",
    "            query_stop_coor = 000\n",
    "            error = \"Y\"\n",
    "            complement  = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #Check if the length of target (blast hit) is significantly smaller than query\n",
    "        if length < query_length - 0.2*query_length:\n",
    "            error = \"Y\"\n",
    "\n",
    "        old_trans = ''\n",
    "#             print(start, stop)\n",
    "\n",
    "\n",
    "#Check for Met or STOP at the start and end\n",
    "        while True and (start != 0 or stop != 0):\n",
    "            if (query_name == query_name_list[0] or query_name == query_name_list[-1]):\n",
    "                frame = 1\n",
    "                translated_sequence = (sequence_extractor(species, scaff, int(complement), start, stop,frame ))\n",
    "\n",
    "                if translated_sequence == old_trans:\n",
    "                    break\n",
    "                    \n",
    "#Check for Met at the beginning of first exon\n",
    "\n",
    "                if query_name == query_name_list[0] :\n",
    "                    if translated_sequence[0] != \"M\":\n",
    "                        print(translated_sequence)\n",
    "#                             print(start, stop)\n",
    "                        if complement == \"0\":\n",
    "                            start = int(start) - 3\n",
    "                        if complement == \"1\":\n",
    "                            stop = int(stop) + 3\n",
    "                        old_trans = translated_sequence\n",
    "                    if \"*\" in translated_sequence:\n",
    "                        error = \"Y\"\n",
    "                        break\n",
    "                    if translated_sequence[0] == \"M\":\n",
    "                        break\n",
    "\n",
    "#Check for stop at the end of last exon\n",
    "\n",
    "                if query_name == query_name_list[-1]:\n",
    "                    if translated_sequence[-1] != \"*\":\n",
    "                        print(translated_sequence)\n",
    "#                             print(start, stop)\n",
    "                        if complement == \"0\":\n",
    "                            stop = int(stop) + 3\n",
    "                        if complement == \"1\":\n",
    "                            start = int(start) - 3\n",
    "                        old_trans = translated_sequence\n",
    "                    if translated_sequence[-1] == \"*\":\n",
    "\n",
    "                        break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        \n",
    "#Add offset at the beginning and end of each exon\n",
    "        if (start != 0 or stop != 0):\n",
    "            \n",
    "            start_modifier = int(query_name.split(\"Frame\")[1][1])\n",
    "            stop_modifier = int(query_name.split(\"rightoh\")[1][1])\n",
    "        else:\n",
    "            start_modifier = 0\n",
    "            stop_modifier = 0            \n",
    "\n",
    "        seq_length = query_length\n",
    "        \n",
    "        \n",
    "#Get exon start and end by adding or removing codons\n",
    "        \n",
    "    #if not the beginning\n",
    "        if query_start_coor != \"1\" and query_name != query_name_list[0]:\n",
    "            if complement == \"0\":\n",
    "                start = int(start) - 3*(int(query_start_coor)-1)                \n",
    "            if complement == \"1\":\n",
    "                stop = int(stop) + 3*(int(query_start_coor)-1)\n",
    "    \n",
    "    #For the end\n",
    "        if query_stop_coor != str(seq_length) and query_name != query_name_list[-1]:\n",
    "            if complement == \"0\":\n",
    "                stop = int(stop) + 3*(int(seq_length)-int(query_stop_coor))\n",
    "            if complement == \"1\":\n",
    "                \n",
    "\n",
    "                start = int(start) - 3*(int(seq_length)-int(query_stop_coor))\n",
    " \n",
    "        \n",
    "        \n",
    "        \n",
    "#Adding or removing 3' and 5' overhangs for forward and reverse complement\n",
    "    #For forward complement\n",
    "        if complement == \"0\":\n",
    "            start = int(start) - int(start_modifier)\n",
    "            stop = int(stop) +  int(stop_modifier)\n",
    "            if old_end != 0 and old_end > stop:\n",
    "\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #For reverse complement\n",
    "        if complement == \"1\":\n",
    "            start = int(start) - int(stop_modifier)\n",
    "            stop = int(stop) +  int(start_modifier)\n",
    "            if old_end != 0 and old_end < stop:\n",
    "                error = \"Y\"\n",
    "            old_end = stop\n",
    "\n",
    "    #Simple check for lenghth\n",
    "        if start == 0 or stop == 0:\n",
    "            error = \"Y\"\n",
    "            \n",
    "           \n",
    "        output_format = str(species.split(\"\\n\")[0])+\",\" + str(scaff) +\",\" + str(start)+\",\" + str(stop)+\",\" + str(complement)+\",\" + str(error)+  \",\"+ str(query_name)+\",\"+ str(query_start_coor)+\",\"+str(query_stop_coor)+\",\"+str(query_length)+ \"\\n\"  \n",
    "        print(output_format)\n",
    "#         assert False\n",
    "        Output_Sequence = Output_Sequence + output_format\n",
    "\n",
    "    print(Output_Sequence)\n",
    "   \n",
    "    output_file = open(f\"{blast_location}/1.Blast_result/{species}/{species}_coordinates_old.csv\",'w')\n",
    "    output_file.write(Output_Sequence)\n",
    "    output_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa07f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fa823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
